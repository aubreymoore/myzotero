<!DOCTYPE html>
<!--[if IE 9]><html class="ie9" lang="en"><![endif]-->
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><iframe src="javascript:false" title="" style="width: 0px; height: 0px; border: 0px none; display: none;"></iframe><script type="text/javascript" async="" src="geo2.js"></script>
      <meta name="citation_pii" content="S2214317317301774">
<meta name="citation_issn" content="2214-3173">
<meta name="citation_publisher" content="Elsevier">
<meta name="citation_fulltext_world_readable" content="">
<meta name="citation_journal_title" content="Information Processing in Agriculture">
<meta name="citation_type" content="JOUR">
<meta name="citation_doi" content="10.1016/j.inpa.2018.05.002">
<meta name="dc.identifier" content="10.1016/j.inpa.2018.05.002">
<meta name="citation_article_type" content="Review article">
<meta property="og:image" content="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-fx1.jpg">
<meta property="og:description" content="This paper reviews advanced Neural Network (NN) techniques available to process hyperspectral data, with a special emphasis on plant disease detection…">
<meta name="citation_title" content="A review of neural networks in plant disease detection using hyperspectral data">
<meta property="og:title" content="A review of neural networks in plant disease detection using hyperspectral data">
<meta name="citation_publication_date" content="2018/05/09">
<meta name="citation_online_date" content="2018/05/09">
<meta name="citation_pdf_url" content="https://www.sciencedirect.com/science/article/pii/S2214317317301774/pdfft?md5=a65a106233555127a7633d17d131e1e7&amp;pid=1-s2.0-S2214317317301774-main.pdf">
<meta name="robots" content="INDEX,FOLLOW,NOARCHIVE,NOODP,NOYDIR">
      <title>A review of neural networks in plant disease detection using hyperspectral data - ScienceDirect</title>
      <link rel="canonical" href="https://www.sciencedirect.com/science/article/pii/S2214317317301774">
      <meta name="viewport" content="initial-scale=1">
      <meta name="SDTech" content="Proudly brought to you by the SD Technology team in London, Dayton, and Amsterdam">
      <link rel="shortcut icon" href="https://cdn.els-cdn.com/sd/favSD.ico" type="image/x-icon">
      <link rel="icon" href="https://cdn.els-cdn.com/sd/favSD.ico" type="image/x-icon">
      <link rel="stylesheet" href="arp.css">
      <link rel="dns-prefetch" href="https://w.usabilla.com/">
      <link rel="dns-prefetch" href="https://www.deepdyve.com/">
      <link rel="dns-prefetch" href="https://smetrics.elsevier.com/">
      <script>
        window.pageTargeting = {"region":"us-west-2","platform":"sdtech","entitled":true,"crawler":"","journal":"Information Processing in Agriculture"};
        window.pageData = {"content":[{"entitlementType":"openaccess","format":"MIME-XHTML","id":"sd:article:pii:S2214317317301774","type":"sd:article:JL:scope-full","detail":"sd:article:subtype:rev","publicationType":"journal","issn":"2214-3173"}],"page":{"businessUnit":"ELS:RP:ST","language":"en","name":"product:journal:article","noTracking":"false","productName":"SD","type":"CP-CA","environment":"prod","loadTimestamp":1532740937018,"loadTime":""},"visitor":{"accessType":"ae:ANON_GUEST","accountId":"ae:228598","accountName":"ae:ScienceDirect Guests","loginStatus":"anonymous","userId":"ae:12975512","ipAddress":"101.99.173.208","appSessionId":"0027ab9c2f5e314bfc788e32697bad43659dgxrqa"}};
        window.arp = {
          config: {"reduxLogging":false,"assetsBaseUrl":"https://sdfestaticassets-us-west-2.sciencedirectassets.com/prod/a963bd60d852030eb0bf15b8f82a4da3ae7a70c9","mediaBaseUrl":"https://ars.els-cdn.com/content/image/","googleMapsApiKey":"AIzaSyAV0ZB1XWtRlzJ06pJAW74Oan87lQVgBHY","enableSignInFromEmailModal":false,"bosUrl":"https://feedback.recs.d.elsevier.com/raw/events","bosTimeOut":60000,"strictMode":false,"enableIhubService":false},
          subscriptions: [],
          subscribe: function(cb) {
            var self = this;
            var i = this.subscriptions.push(cb) - 1;
            return function unsubscribe() {
              self.subscriptions.splice(i, 1);
            }
          },
        };
      </script>
      <script type="text/javascript" src="204774041.js"></script>
      <!-- begin mPulse embed code -->
      <script>
        (function(){
          if(window.BOOMR && window.BOOMR.version){return;}
          var dom,doc,where,iframe = document.createElement('iframe'),win = window;

          function boomerangSaveLoadTime(e) {
            win.BOOMR_onload=(e && e.timeStamp) || new Date().getTime();
          }
          if (win.addEventListener) {
            win.addEventListener("load", boomerangSaveLoadTime, false);
          } else if (win.attachEvent) {
            win.attachEvent("onload", boomerangSaveLoadTime);
          }

          iframe.src = "javascript:false";
          iframe.title = ""; iframe.role="presentation";
          (iframe.frameElement || iframe).style.cssText = "width:0;height:0;border:0;display:none;";
          where = document.getElementsByTagName('script')[0];
          where.parentNode.insertBefore(iframe, where);

          try {
            doc = iframe.contentWindow.document;
          } catch(e) {
            dom = document.domain;
            iframe.src="javascript:var d=document.open();d.domain='"+dom+"';void(0);";
            doc = iframe.contentWindow.document;
          }
          doc.open()._l = function() {
            var js = this.createElement("script");
            if(dom) this.domain = dom;
            js.id = "boomr-if-as";
            js.src = 'https://c.go-mpulse.net/boomerang/2FBN2-NKMGU-EJKY8-ZANKZ-SUJZF';
            BOOMR_lstart=new Date().getTime();
            this.body.appendChild(js);
          };
          doc.write('<body onload="document._l();">');
          doc.close();
        })();
      </script>
      <!-- end mPulse embed code -->
    <script src="satellite-5b3b560664746d57b70018c6.js"></script><script src="s-code-contents-9c0358adbc3b5986e210099b3bf1d427fc5bd286.js"></script><link rel="preload" href="integrator.js"><script type="text/javascript" src="integrator.js"></script><script src="pubads_impl_235.js" async=""></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1px; bottom: 2px; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
</style><link id="plx-css-summary" type="text/css" rel="stylesheet" href="https://d39af2mgp1pqhg.cloudfront.net/summary.css"><script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><script type="text/javascript" src="//d39af2mgp1pqhg.cloudfront.net/extjs/xss.js"></script></head>
    <body><div id="MathJax_Message" style="display: none;"></div><div style="display: none;" id="lightningjs-usabilla_live"><div><iframe id="lightningjs-frame-usabilla_live" frameborder="0"></iframe></div></div>
      <a class="sr-only sr-only-focusable" href="#app">Skip to main content</a>
      <!--[if lt IE 9]>
      <div id="ie8Warning" class="warning">
        <script>function ie8click() {
  const node = document.getElementById('ie8Warning');
  document.cookie = 'ie_warning_state=1';
  node.parentNode.removeChild(node);
}</script>
        <p>Please note that Internet Explorer version 8.x is not supported as of January 1, 2016.
        Please refer to <a href="https://service.elsevier.com/app/answers/detail/a_id/9831">this support page</a> for more information.</p>
        <a class="warning-close" onclick="ie8click()" title="Close IE warning">&times;</a>
      </div>
    <![endif]-->
      <div data-iso-key="_0"><div class="App" id="app" role="application" data-reactroot=""><div class="page"><section><div id="header"><div class="u-bg-white" style="overflow:visible" role="banner"><div class="els-header" style="min-height:80px"><a id="els-main-title-link" href="https://www.sciencedirect.com/"><svg id="els-header-wordmark" class="u-fill-orange u-margin-l-top u-margin-s-left u-margin-l-left-from-sm" viewBox="-3334 3439.4 163 26" style="width:163px;height:24px"><title>ScienceDirect</title><g transform="scale(.8125,.8125)"><path d="M-4099.8,4240.4c0-1.8,1-3.6,4.4-3.6c1.7,0,3.7,0.5,5.5,1.6l0.2-3.1c-1.7-0.7-3.5-1.1-5.6-1.1 c-5.5,0-7.8,2.9-7.8,6.4c0,6.6,10.4,7.2,10.4,11.7c0,1.8-1.4,3.6-4.6,3.6c-2,0-4-0.7-5.6-1.6l-0.4,3.1c1.8,0.9,4.2,1.2,6.1,1.2 c5,0,7.9-2.9,7.9-6.5C-4089.4,4245.8-4099.8,4244.9-4099.8,4240.4"></path><path id="c" d="M-4080.3,4242.9c0.3-0.1,0.8-0.3,2-0.3c2,0,2.9,0.4,2.9,1.9h2.8c0-0.4,0-0.9,0-1.3 c-0.3-2.3-2.5-3.2-5.8-3.2c-3.6,0-7.9,2.7-7.9,9.2c0,6.2,3.3,9.4,7.8,9.4c2,0,4.1-0.4,5.9-1.6l-0.2-2.7c-1.2,1-3.4,1.8-4.8,1.8 c-2.5,0-5.4-2-5.4-7C-4083.1,4244.3-4080.6,4243.1-4080.3,4242.9"></path><path id="i" d="M-4068,4233.1c-1.1,0-1.9,1.1-1.9,2.1c0,1.1,0.9,2.2,1.9,2.2s2-1.1,2-2.2 C-4066,4234.1-4067,4233.1-4068,4233.1 M-4069.5,4258.1h3v-17.7h-3V4258.1z"></path><path id="e" d="M-4057.1,4243.1c0.2-0.2,1.5-0.5,2.3-0.5c2.9,0,4.4,0.6,4.6,4.1h-8.8 C-4058.7,4244.4-4057.4,4243.3-4057.1,4243.1z M-4047.5,4248.9c0-6.1-1.7-8.9-7.1-8.9c-4.6,0-7.9,3.3-7.9,9.4 c0,5.8,3.5,9.2,7.9,9.2c3.3,0,5.1-0.7,6.7-1.7l-0.2-2.7c-1.1,0.9-3.5,1.8-5.5,1.8c-3.7,0-5.8-2.3-5.8-6.5v-0.6L-4047.5,4248.9"></path><path d="M-4034.8,4240c-2.6,0-4.3,1.3-5.7,3.1l-0.5-2.6h-2.8l0.2,1.4c0.1,0.9,0.2,2.1,0.2,3.5v12.8h3v-11.9 c0.8-1.1,2.5-2.9,2.9-3.1c0.3-0.2,1.5-0.5,2.5-0.5c2.7,0,2.9,1.4,3,4c0,1.4,0,3.7,0,3.7c0,3.5-0.1,7.6-0.1,7.6h3 c0,0,0.1-5.3,0.1-8.2c0-1.8,0-3.5-0.1-5.3C-4029.5,4241-4031.6,4240-4034.8,4240"></path><path d="M-3982.5,4255.6h-4.4v-18.6h4.8c6.4,0,8.2,5.2,8.2,9.2C-3973.8,4252.2-3976.5,4255.6-3982.5,4255.6z M-3981.6,4234.6h-8.4v23.5h8.1c8.6,0,11.5-6.7,11.5-11.9C-3970.4,4240.9-3973.2,4234.6-3981.6,4234.6"></path><path d="M-3950.5,4240c-1.9,0-3.4,1.7-4,3.2l-0.5-2.8h-2.8l0.2,1.4c0.1,0.9,0.2,2.1,0.2,3.4v12.8h3v-11.2 c0.6-1.5,2-4.4,3.7-4.4c1.1,0,1.2,1.2,1.2,1.4l2.5-0.7v-0.2c0,0,0-0.2-0.1-0.5C-3947.4,4240.9-3948.5,4240-3950.5,4240"></path><path d="M-3903.5,4255.2c-1.1,0.4-2,0.8-3,0.8c-1.4,0-1.9-0.8-1.9-2.8v-10.4h4.6v-2.3h-4.6v-4.7h-2.9v4.7h-3.2v2.3h3.2 v11.4c0,3.1,1.6,4.4,3.9,4.4c1.4,0,3-0.5,4.1-0.9L-3903.5,4255.2"></path><g><path d="M-3923.3,4242.9c0.3-0.1,0.8-0.3,2-0.3c2,0,2.9,0.4,2.9,1.9h2.8c0-0.4,0-0.9,0-1.3 c-0.3-2.3-2.5-3.2-5.8-3.2c-3.6,0-7.9,2.7-7.9,9.2c0,6.2,3.3,9.4,7.8,9.4c2,0,4.1-0.4,5.9-1.6l-0.2-2.7c-1.2,1-3.4,1.8-4.8,1.8 c-2.5,0-5.4-2-5.4-7C-3926.1,4244.3-3923.6,4243.1-3923.3,4242.9"></path></g><g><path d="M-3941.6,4243.1c0.2-0.2,1.5-0.5,2.3-0.5c2.9,0,4.4,0.6,4.6,4.1h-8.8 C-3943.2,4244.4-3941.8,4243.3-3941.6,4243.1z M-3932,4248.9c0-6.1-1.7-8.9-7.1-8.9c-4.6,0-7.9,3.3-7.9,9.4c0,5.8,3.5,9.2,7.9,9.2 c3.3,0,5.1-0.7,6.7-1.7l-0.2-2.7c-1.1,0.9-3.5,1.8-5.5,1.8c-3.7,0-5.8-2.3-5.8-6.5v-0.6L-3932,4248.9"></path></g><g><path d="M-3964.5,4233.1c-1.1,0-1.9,1.1-1.9,2.1c0,1.1,0.9,2.2,1.9,2.2s2-1.1,2-2.2 C-3962.5,4234.1-3963.4,4233.1-3964.5,4233.1 M-3965.9,4258.1h3v-17.7h-3V4258.1z"></path></g><g><path d="M-4004.4,4243.1c0.2-0.2,1.5-0.5,2.3-0.5c2.9,0,4.4,0.6,4.6,4.1h-8.8 C-4006,4244.4-4004.6,4243.3-4004.4,4243.1z M-3994.7,4248.9c0-6.1-1.7-8.9-7.1-8.9c-4.6,0-7.9,3.3-7.9,9.4c0,5.8,3.5,9.2,7.9,9.2 c3.3,0,5.1-0.7,6.7-1.7l-0.2-2.7c-1.1,0.9-3.5,1.8-5.5,1.8c-3.7,0-5.8-2.3-5.8-6.5v-0.6L-3994.7,4248.9"></path></g><g><path d="M-4019.1,4242.9c0.3-0.1,0.8-0.3,2-0.3c2,0,2.9,0.4,2.9,1.9h2.8c0-0.4,0-0.9,0-1.3 c-0.3-2.3-2.5-3.2-5.8-3.2c-3.6,0-7.9,2.7-7.9,9.2c0,6.2,3.3,9.4,7.8,9.4c2,0,4.1-0.4,5.9-1.6l-0.2-2.7c-1.2,1-3.4,1.8-4.8,1.8 c-2.5,0-5.4-2-5.4-7C-4021.8,4244.3-4019.4,4243.1-4019.1,4242.9"></path></g></g></svg></a><div class="move-right u-display-inline-block"><nav class="u-clr-grey8 u-show-from-md"><div class="u-display-inline-block" style="margin-top:29px"><span><span class="u-margin-l-right"><a class="anchor qa-journals-and-books u-margin-l-right anchor-has-inherit-color" href="https://www.sciencedirect.com/science/journals" id="els-header-navigation-section-journal" style="border-bottom:"><span class="anchor-text">Journals</span></a><a class="anchor qa-journals-and-books u-margin-l-right anchor-has-inherit-color" href="https://www.sciencedirect.com/science/bookbshsrw" id="els-header-navigation-section-book" style="border-bottom:"><span class="anchor-text">Books</span></a></span><a class="anchor qa-journals-and-books u-margin-l-right anchor-has-inherit-color" href="https://www.sciencedirect.com/user/register?returnURL=%2Fscience%2Farticle%2Fpii%2FS2214317317301774" id="els-header-navigation-section-register"><span class="anchor-text">Register</span></a></span><a class="anchor qa-no-js-fallback-link anchor-has-inherit-color" href="https://www.sciencedirect.com/user/login?returnURL=%2Fscience%2Farticle%2Fpii%2FS2214317317301774" id="els-header-user-sign-in"><span class="anchor-text">Sign in</span><svg focusable="false" viewBox="0 0 54 128" width="10.125" height="24" class="icon icon-navigate-right"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg></a><li style="list-style:none;display:inline"><a class="anchor u-margin-l-hor help-link anchor-has-inherit-color" href="https://service.elsevier.com/app/home/supporthub/sciencedirect/" id="help" title="Help" target="_blank"><span class="anchor-text"><svg focusable="false" viewBox="0 0 114 128" style="margin-top:-10px" width="21.375" height="24" class="icon icon-help"><path d="m57 8c-14.7 0-28.5 5.72-38.9 16.1-10.38 10.4-16.1 24.22-16.1 38.9 0 30.32 24.68 55 55 55 14.68 0 28.5-5.72 38.88-16.1 10.4-10.4 16.12-24.2 16.12-38.9 0-30.32-24.68-55-55-55zm0 1e1c24.82 0 45 20.18 45 45 0 12.02-4.68 23.32-13.18 31.82s-19.8 13.18-31.82 13.18c-24.82 0-45-20.18-45-45 0-12.02 4.68-23.32 13.18-31.82s19.8-13.18 31.82-13.18zm-0.14 14c-11.55 0.26-16.86 8.43-16.86 18v2h1e1v-2c0-4.22 2.22-9.66 8-9.24 5.5 0.4 6.32 5.14 5.78 8.14-1.1 6.16-11.78 9.5-11.78 20.5v6.6h1e1v-5.56c0-8.16 11.22-11.52 12-21.7 0.74-9.86-5.56-16.52-16-16.74-0.39-0.01-0.76-0.01-1.14 0zm-4.86 5e1v1e1h1e1v-1e1h-1e1z"></path></svg></span></a></li></div></nav></div><div class="u-hide-from-md move-right"><ul><li style="list-style:none;display:inline-block;margin-top:32px" class="u-margin-s-hor u-margin-l-hor-from-sm"><div class="hamburger-button"><button class="button-link button-link-primary" aria-label="Mobile menu" aria-expanded="false" type="button"><svg viewBox="0 0 40 18" width="40" height="18" y="52"><path d="M0 16h40v2H0zm0-8h40v2H0zm0-8h40v2H0z"></path></svg><span class="button-link-text"></span></button></div></li></ul><div style="bottom:0;left:0;position:fixed;top:0;width:100%;z-index:70;opacity:.8" class="u-bg-grey1 u-display-none"></div><div id="mobile-menu" style="overflow:auto;position:fixed;width:288px;right:0;top:0;z-index:1000;height:100%" aria-label="Mobile menu" class="u-bg-grey7 u-clr-grey1 u-display-none" role="navigation"><div class="u-bg-black panel-s"></div><div class="u-bg-grey8 panel-s"><ul><li style="list-style:none"><a class="anchor journals-link u-padding-xs-top anchor-has-inherit-color" href="https://www.sciencedirect.com/science/journals" style="border-bottom:" id="mobile-journals-link"><span class="anchor-text">Journals</span></a></li><li style="list-style:none"><a class="anchor books-link u-padding-xs-top anchor-has-inherit-color" href="https://www.sciencedirect.com/science/bookbshsrw" style="border-bottom:" id="mobile-books-link"><span class="anchor-text">Books</span></a></li><li style="list-style:none"><a class="anchor u-padding-xs-top anchor-has-inherit-color" href="https://www.sciencedirect.com/user/register?returnURL=%2Fscience%2Farticle%2Fpii%2FS2214317317301774" id="mobile-register-link"><span class="anchor-text">Register</span></a></li></ul></div><div class="panel-s u-bg-grey7"><ul class="text-xs"></ul><ul class="u-margin-s-top text-s"><li style="list-style:none"><a class="anchor anchor-has-inherit-color" href="https://www.sciencedirect.com/user/login?returnURL=%2Fscience%2Farticle%2Fpii%2FS2214317317301774" id="mobile-sign-in-out-link" rel="nofollow"><span class="anchor-text">Sign In</span></a></li><li style="list-style:none;display:inline"><a class="anchor u-padding-xs-top text-s help-link anchor-has-inherit-color" href="https://service.elsevier.com/app/home/supporthub/sciencedirect/" id="mobile-help" title="Help" target="_blank"><span class="anchor-text">Help</span></a></li></ul></div></div><div class="move-bottom move-center"></div></div></div></div></div><div class="Article" id="mathjax-container"><div class="sticky-outer-wrapper"><div class="sticky-inner-wrapper" style="position: relative; z-index: 1; transform: translate3d(0px, 0px, 0px);"><div class="Toolbar" role="region" aria-label="download options and search"><div class="toolbar-container"><div class="u-show-from-lg col-lg-6">&nbsp;</div><div class="buttons pull-left pad-left"><button class="show-toc-button u-hide-from-lg"><svg focusable="false" viewBox="0 0 104 128" width="19.5" height="24" class="icon icon-list"><path d="m2e1 95a9 9 0 0 1 -9 9 9 9 0 0 1 -9 -9 9 9 0 0 1 9 -9 9 9 0 0 1 9 9zm0-3e1a9 9 0 0 1 -9 9 9 9 0 0 1 -9 -9 9 9 0 0 1 9 -9 9 9 0 0 1 9 9zm0-3e1a9 9 0 0 1 -9 9 9 9 0 0 1 -9 -9 9 9 0 0 1 9 -9 9 9 0 0 1 9 9zm14 55h68v1e1h-68zm0-3e1h68v1e1h-68zm0-3e1h68v1e1h-68z"></path></svg><span class="label">Outline</span></button><a class="anchor PdfDownloadButton" href="https://www.sciencedirect.com/science/article/pii/S2214317317301774/pdfft?md5=a65a106233555127a7633d17d131e1e7&amp;pid=1-s2.0-S2214317317301774-main.pdf" target="_blank" rel="nofollow"><svg focusable="false" viewBox="0 0 32 32" width="24" height="24" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" stroke="#aaa" stroke-width=".315" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text"><span class="pdf-download-label u-show-inline-from-lg">Download PDF</span><span class="pdf-download-label-short u-hide-from-lg">Download</span></span></a><div class="ExportCitation" role="region" id="export-citation"><button class="button ExportCitationButton button-anchor" type="button"><span class="button-text">Export</span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div></div><div class="pull-right pad-right u-show-from-md"><form id="quick-search" class="QuickSearch" action="/search/advanced" method="get"><input class="query" aria-label="Search ScienceDirect" name="qs" placeholder="Search ScienceDirect" type="text"><button class="button button-primary" type="submit" aria-label="Submit search"><span class="button-text"><svg focusable="false" viewBox="0 0 100 128" height="20" width="18.75" class="icon icon-search"><path d="m19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6l-26.32-26.32c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96s-21.17 4.25-28.88 11.96c-7.72 7.71-11.97 17.97-11.97 28.88s4.25 21.17 11.97 28.88c7.71 7.71 17.97 11.96 28.88 11.96 9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></span></button><a class="advanced-search-link" href="https://www.sciencedirect.com/search/advanced">Advanced</a><input name="origin" value="article" type="hidden"><input name="zone" value="qSearch" type="hidden"></form></div></div></div></div></div><div class="article-wrapper grid row"><div class="u-show-from-lg col-lg-6"><div class="TableOfContents u-margin-l-bottom" lang="en"><div class="Outline" id="toc-outline"><h2>Outline</h2><ol class="u-padding-s-bottom"><li><a href="#ab010" title="Abstract">Abstract</a></li><li><a href="#ab005" title="Graphical abstract">Graphical abstract</a></li><li><a href="#nc005" title="Nomenclature">Nomenclature</a></li><li><a href="#s0005" title="1. Introduction">1. Introduction</a></li><li><a href="#s0010" title="2. Mechanism of neural networks">2. Mechanism of neural networks</a></li><li><a href="#s0015" title="3. Major types of NNs">3. Major types of NNs</a></li><li><a href="#s0050" title="4. NN models">4. NN models</a></li><li><a href="#s0070" title="5. The NN classifiers">5. The NN classifiers</a></li><li><a href="#s0075" title="6. Early disease detection">6. Early disease detection</a></li><li><a href="#s0090" title="7">7. An overview of two studies on rice (<em>Oryza sativa</em> L.) disease detection using NN-hyperspectral approach</a></li><li><a href="#s0105" title="8. Challenges of NN">8. Challenges of NN</a></li><li><a href="#s0110" title="9. SDi">9. SDi</a></li><li><a href="#s0115" title="10. Future trends: deep learning of hyperspectral data">10. Future trends: deep learning of hyperspectral data</a></li><li><a href="#s0120" title="11. Conclusion">11. Conclusion</a></li><li><a href="#s0125" title="Acknowledgement">Acknowledgement</a></li><li><a href="#s0130" title="Conflict of interest">Conflict of interest</a></li><li><a href="#bi005" title="References">References</a></li></ol><button class="button button-anchor" type="button"><span class="button-text">Show full outline</span><svg focusable="false" viewBox="0 0 92 128" height="20" width="17.25" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="PageDivider"></div></div><div class="Figures" id="toc-figures"><h2>Figures (3)</h2><ol><li><a href="#f0015"><div><img alt="Unlabelled figure" src="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-fx1.sml" style="max-width: 219px; max-height: 92px;"></div></a></li><li><a href="#f0005"><div><img alt="Fig. 1. The multi-layer NN consisting input layer, hidden layer, and output layer" src="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-gr1.sml" style="max-width: 219px; max-height: 83px;"></div></a></li><li><a href="#f0010"><div><img alt="Fig. 2. A GRNN that process the time series data for disease diagnosis" src="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-gr2.sml" style="max-width: 216px; max-height: 164px;"></div></a></li></ol><div class="PageDivider"></div></div><div class="Tables" id="toc-tables"><h2>Tables (3)</h2><ol class="u-padding-s-bottom"><li><a href="#t0005" title="List of major contributions according to different types of NNs for plant disease detection."><svg focusable="false" viewBox="0 0 98 128" width="18.375" height="24" class="icon icon-table"><path d="m54 68h32v32h-32v-32zm-42 0h32v32h-32v-32zm0-42h32v32h-32v-32zm42 0h32v32h-32v-32zm-52 84h94v-94h-94v94z"></path></svg>Table 1</a></li><li><a href="#t0010" title="Use of hyperspectral sensor in detecting and diagnosing crop disease at an early stage."><svg focusable="false" viewBox="0 0 98 128" width="18.375" height="24" class="icon icon-table"><path d="m54 68h32v32h-32v-32zm-42 0h32v32h-32v-32zm0-42h32v32h-32v-32zm42 0h32v32h-32v-32zm-52 84h94v-94h-94v94z"></path></svg>Table 2</a></li><li><a href="#t0015" title="Well-established SDIs for early disease detection using hyperspectral data."><svg focusable="false" viewBox="0 0 98 128" width="18.375" height="24" class="icon icon-table"><path d="m54 68h32v32h-32v-32zm-42 0h32v32h-32v-32zm0-42h32v32h-32v-32zm42 0h32v32h-32v-32zm-52 84h94v-94h-94v94z"></path></svg>Table 3</a></li></ol><div class="PageDivider"></div></div></div></div><article class="col-lg-12 col-md-16 pad-left pad-right" role="main" lang="en"><noscript>JavaScript is disabled on your browser. Please enable JavaScript to use all the features on this page.</noscript><div class="Publication" id="publication"><div class="publication-brand u-show-from-sm"><a href="https://www.sciencedirect.com/science/journal/22143173"><img class="publication-brand-image" src="D22143173.gif" alt="Information Processing in Agriculture"></a></div><div class="publication-volume u-text-center"><h2 class="publication-title" id="publication-title"><a class="publication-title-link" title="Go to Information Processing in Agriculture on ScienceDirect" href="https://www.sciencedirect.com/science/journal/22143173">Information Processing in Agriculture</a></h2><div class="text-xs">Available online 9 May 2018</div><div class="OpenAccessLabel">open access</div><div><span class="size-m publication-aip-text"><a class="publication-aip-link" href="https://www.sciencedirect.com/science/journal/aip/22143173"><span>In Press, Corrected Proof</span></a></span><a class="anchor" href="https://service.elsevier.com/app/answers/detail/a_id/22801/supporthub/sciencedirect/" target="_blank" title="What are Corrected Proof articles?"><svg focusable="false" viewBox="0 0 114 128" width="16" height="16" class="icon icon-help"><path d="m57 8c-14.7 0-28.5 5.72-38.9 16.1-10.38 10.4-16.1 24.22-16.1 38.9 0 30.32 24.68 55 55 55 14.68 0 28.5-5.72 38.88-16.1 10.4-10.4 16.12-24.2 16.12-38.9 0-30.32-24.68-55-55-55zm0 1e1c24.82 0 45 20.18 45 45 0 12.02-4.68 23.32-13.18 31.82s-19.8 13.18-31.82 13.18c-24.82 0-45-20.18-45-45 0-12.02 4.68-23.32 13.18-31.82s19.8-13.18 31.82-13.18zm-0.14 14c-11.55 0.26-16.86 8.43-16.86 18v2h1e1v-2c0-4.22 2.22-9.66 8-9.24 5.5 0.4 6.32 5.14 5.78 8.14-1.1 6.16-11.78 9.5-11.78 20.5v6.6h1e1v-5.56c0-8.16 11.22-11.52 12-21.7 0.74-9.86-5.56-16.52-16-16.74-0.39-0.01-0.76-0.01-1.14 0zm-4.86 5e1v1e1h1e1v-1e1h-1e1z"></path></svg><span class="anchor-text"><span class="sr-only">What are Corrected Proof articles?</span></span></a></div></div><div class="publication-cover u-show-from-sm"><a href="https://www.sciencedirect.com/science/journal/22143173"><img class="publication-cover-image" src="S22143173.gif" alt="Information Processing in Agriculture"></a></div></div><h1 class="Head"><span class="title-text">A review of neural networks in plant disease detection using hyperspectral data</span></h1><div class="Banner" id="banner"><div class="wrapper truncated"><div class="AuthorGroups"><div class="author-group" id="author-group"><span class="sr-only">Author links open overlay panel</span><a class="author size-m workspace-trigger" name="bau005" href="#%21"><span class="content"><span class="text given-name">Kamlesh</span><span class="text surname">Golhani</span><span class="author-ref" id="baf005"><sup>a</sup></span></span></a><a class="author size-m workspace-trigger" name="bau010" href="#%21"><span class="content"><span class="text given-name">Siva K.</span><span class="text surname">Balasundram</span><span class="author-ref" id="baf005"><sup>a</sup></span><svg focusable="false" viewBox="0 0 106 128" width="19.875" height="24" class="icon icon-person"><path d="m11.07 1.2e2l0.84-9.29c1.97-18.79 23.34-22.93 41.09-22.93 17.74 0 39.11 4.13 41.08 22.84l0.84 9.38h10.04l-0.93-10.34c-2.15-20.43-20.14-31.66-51.03-31.66s-48.89 11.22-51.05 31.73l-0.91 10.27h10.03m41.93-102.29c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98s18.24-10.31 18.24-23.98c0-9.9-8.52-18.59-18.24-18.59zm0 52.29c-15.96 0-28-14.48-28-33.67 0-15.36 12.82-28.33 28-28.33s28 12.97 28 28.33c0 19.19-12.04 33.67-28 33.67"></path></svg><svg focusable="false" viewBox="0 0 102 128" width="19.125" height="24" class="icon icon-envelope"><path d="m55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0l-31.32-23.2h69.54l-31.32 23.19zm-55.8-24.78l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-0.98 9.42-2.93l40.24-30.7v-10.34h-102zm92 56.48l-18.06-22.74-8.04 5.95 17.38 21.89h-64.54l18.38-23.12-8.04-5.96-19.08 24.02v-37.58l-1e1 -8.46v61.1h102v-59.18l-1e1 8.46v35.62"></path></svg></span></a><a class="author size-m workspace-trigger" name="bau015" href="#%21"><span class="content"><span class="text given-name">Ganesan</span><span class="text surname">Vadamalai</span><span class="author-ref" id="baf010"><sup>b</sup></span></span></a><a class="author size-m workspace-trigger" name="bau020" href="#%21"><span class="content"><span class="text given-name">Biswajeet</span><span class="text surname">Pradhan</span><span class="author-ref" id="baf015"><sup>c</sup></span></span></a></div></div></div><button class="show-hide-details"><svg viewBox="0 0 9 9" class="icon-expand"><path d="M5 7H4V5H2V4h2V2h1v2h2v1H5z"></path><path d="M0 0v9h9V0zm1 1h7v7H1z"></path></svg>Show more</button></div><div class="DoiLink" id="doi-link"><a class="doi" href="https://doi.org/10.1016/j.inpa.2018.05.002" target="_blank" aria-label="Persistent link using digital object identifier" title="Persistent link using digital object identifier">https://doi.org/10.1016/j.inpa.2018.05.002</a><a class="rights-and-content" target="_blank" href="https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S2214317317301774&amp;orderBeanReset=true">Get rights and content</a></div><div class="LicenseInfo"><div class="Funding">Open Access funded by China Agricultural University</div><div class="License">Under a Creative Commons <a target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">license</a></div></div><section class="ReferencedArticles"></section><section class="ReferencedArticles"></section><div class="PageDivider"></div><div class="Abstracts" id="abstracts"><div class="abstract author" id="ab010" lang="en"><h2 class="section-title">Abstract</h2><div id="as010"><p id="sp0010">This
 paper reviews advanced Neural Network (NN) techniques available to 
process hyperspectral data, with a special emphasis on plant disease 
detection. Firstly, we provide a review on NN mechanism, types, models, 
and classifiers that use different algorithms to process hyperspectral 
data. Then we highlight the current state of imaging and non-imaging 
hyperspectral data for early disease detection. The hybridization of 
NN-hyperspectral approach has emerged as a powerful tool for disease 
detection and diagnosis. Spectral Disease Index (SDI) is the ratio of 
different spectral bands of pure disease spectra. Subsequently, we 
introduce NN techniques for rapid development of SDI. We also highlight 
current challenges and future trends of hyperspectral data.</p></div></div><div class="abstract graphical" id="ab005" lang="en"><h2 class="section-title">Graphical abstract</h2><div id="as005"><p id="sp0005"><span class="display"><figure class="figure" id="f0015"><span id="download-image"><img src="1-s2.jpg" alt="" height="200"><ol class="links-for-figure"><li><a href="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-fx1_lrg.jpg" target="__blank">Download high-res image (109KB)</a></li><li><a href="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-fx1.jpg" target="__blank">Download full-size image</a></li></ol></span></figure></span></p></div></div></div><div class="Body" id="body"><section id="nc005"><h2 class="section-title">Nomenclature</h2><dl id="a0005"><dt>AIS</dt><dd class="u-margin-xxl-left"><p id="p0005">Airborne Imaging Spectrometer</p></dd><dt>AISA</dt><dd class="u-margin-xxl-left"><p id="p0010">Airborne Imaging Spectrometer for Applications</p></dd><dt>AVIRIS</dt><dd class="u-margin-xxl-left"><p id="p0015">Airborne Visible/infrared Imaging Spectrometer</p></dd><dt>ANN</dt><dd class="u-margin-xxl-left"><p id="p0020">Artificial Neural Network</p></dd><dt>BP</dt><dd class="u-margin-xxl-left"><p id="p0025">Back-Propagation</p></dd><dt>BPNN</dt><dd class="u-margin-xxl-left"><p id="p0030">Back-Propagation Neural Network</p></dd><dt>CLSI</dt><dd class="u-margin-xxl-left"><p id="p0035">Cersopora Leaf Spot- Index</p></dd><dt>CA</dt><dd class="u-margin-xxl-left"><p id="p0040">Cluster Analysis</p></dd><dt>CNN</dt><dd class="u-margin-xxl-left"><p id="p0045">Convolutional Neural Network</p></dd><dt>CP</dt><dd class="u-margin-xxl-left"><p id="p0050">Counter-Propagation</p></dd><dt>DSWI</dt><dd class="u-margin-xxl-left"><p id="p0055">Disease-Water stress Index</p></dd><dt>ELISA</dt><dd class="u-margin-xxl-left"><p id="p0060">Enzyme-Linked Immune Sorbent Assay</p></dd><dt>ELM</dt><dd class="u-margin-xxl-left"><p id="p0065">Extreme Learning Machine</p></dd><dt>FFNN</dt><dd class="u-margin-xxl-left"><p id="p0070">Feed-Forward Neural Network</p></dd><dt>GLD</dt><dd class="u-margin-xxl-left"><p id="p0075">Generalized Linear Discriminants</p></dd><dt>GRNN</dt><dd class="u-margin-xxl-left"><p id="p0080">Generalized Regression Neural Network</p></dd><dt>GA</dt><dd class="u-margin-xxl-left"><p id="p0085">Genetic Algorithm</p></dd><dt>HI</dt><dd class="u-margin-xxl-left"><p id="p0090">Healthy- Index</p></dd><dt>HPLC</dt><dd class="u-margin-xxl-left"><p id="p0095">High Performance Liquid Chromatography</p></dd><dt>HIS</dt><dd class="u-margin-xxl-left"><p id="p0100">Hyperspectral imaging</p></dd><dt>HyMap</dt><dd class="u-margin-xxl-left"><p id="p0105">Hyperspectral Mapping Imaging Spectrometer</p></dd><dt>Lw</dt><dd class="u-margin-xxl-left"><p id="p0110">Laurel wilt</p></dd><dt>LRDSI</dt><dd class="u-margin-xxl-left"><p id="p0115">Leaf Rust Disease Severity Index</p></dd><dt>LVQ</dt><dd class="u-margin-xxl-left"><p id="p0120">Learning Vector Quantization</p></dd><dt>LS-SVM</dt><dd class="u-margin-xxl-left"><p id="p0125">Least Squares Support Vector Machine</p></dd><dt>LDF</dt><dd class="u-margin-xxl-left"><p id="p0130">Linear Discriminant Function</p></dd><dt>LDA</dt><dd class="u-margin-xxl-left"><p id="p0135">Linear Discriminant Analysis</p></dd><dt>LVQ</dt><dd class="u-margin-xxl-left"><p id="p0140">Learning Vector Quantization</p></dd><dt>MLP</dt><dd class="u-margin-xxl-left"><p id="p0145">Multi-Layer Perceptron</p></dd><dt>NASA/JPL</dt><dd class="u-margin-xxl-left"><p id="p0150">National Aeronautics and Space Administration Jet Propulsion Laboratory</p></dd><dt>NIR</dt><dd class="u-margin-xxl-left"><p id="p0155">Near Infra-Red</p></dd><dt>NN</dt><dd class="u-margin-xxl-left"><p id="p0160">Neural Network</p></dd><dt>NDVI</dt><dd class="u-margin-xxl-left"><p id="p0165">Normalized Difference Vegetation Index</p></dd><dt>NLRHI</dt><dd class="u-margin-xxl-left"><p id="p0170">Normalized Leaf Rust Healthy Index</p></dd><dt>PLS-DA</dt><dd class="u-margin-xxl-left"><p id="p0175">Partial Least Squares-Discrimination Analysis</p></dd><dt>PLS</dt><dd class="u-margin-xxl-left"><p id="p0180">Partial Least-Square Regression</p></dd><dt>PMI</dt><dd class="u-margin-xxl-left"><p id="p0185">Powdery Mildew-Index</p></dd><dt>PCA</dt><dd class="u-margin-xxl-left"><p id="p0190">Principal Component Analysis</p></dd><dt>PCS</dt><dd class="u-margin-xxl-left"><p id="p0195">Principal Component Spectra</p></dd><dt>PCs</dt><dd class="u-margin-xxl-left"><p id="p0200">Principle Components</p></dd><dt>PNN</dt><dd class="u-margin-xxl-left"><p id="p0205">Probabilistic Neural Network</p></dd><dt>RBF</dt><dd class="u-margin-xxl-left"><p id="p0210">Radial-Basis Function</p></dd><dt>RF</dt><dd class="u-margin-xxl-left"><p id="p0215">Random Forest</p></dd><dt>ROSIS</dt><dd class="u-margin-xxl-left"><p id="p0220">Reflective Optics System Imaging Spectrometer</p></dd><dt>RT-PCR</dt><dd class="u-margin-xxl-left"><p id="p0225">Real-Time Polymerase Chain Reaction</p></dd><dt>RT-LAMP</dt><dd class="u-margin-xxl-left"><p id="p0230">Reverse Transcription Loop-Mediated Isothermal Amplification</p></dd><dt>RPA</dt><dd class="u-margin-xxl-left"><p id="p0235">Ribonuclease Protection Assay</p></dd><dt>SWIR</dt><dd class="u-margin-xxl-left"><p id="p0240">Shortwave Infrared</p></dd><dt>SLP</dt><dd class="u-margin-xxl-left"><p id="p0245">Single-Layer Perceptron</p></dd><dt>SPAD</dt><dd class="u-margin-xxl-left"><p id="p0250">Soil and Plant Analysis Development</p></dd><dt>SOM</dt><dd class="u-margin-xxl-left"><p id="p0255">Self-Organising Map</p></dd><dt>SDI</dt><dd class="u-margin-xxl-left"><p id="p0260">Spectral Disease Index</p></dd><dt>SMA</dt><dd class="u-margin-xxl-left"><p id="p0265">Spectral Mixture Analysis</p></dd><dt>SBRI</dt><dd class="u-margin-xxl-left"><p id="p0270">Sugar Beet Rust-Index</p></dd><dt>SVM</dt><dd class="u-margin-xxl-left"><p id="p0275">Support Vector Machine</p></dd><dt>TMV</dt><dd class="u-margin-xxl-left"><p id="p0280">Tobacco Mosaic Virus</p></dd><dt>TSWV</dt><dd class="u-margin-xxl-left"><p id="p0285">Tomato Spotted Wilt Virus</p></dd><dt>VIs</dt><dd class="u-margin-xxl-left"><p id="p0290">Vegetation Indices</p></dd><dt>VNIR</dt><dd class="u-margin-xxl-left"><p id="p0295">Visible/Near-Infrared</p></dd></dl></section><div><section id="s0005"><h2 id="st020">1. Introduction</h2><p id="p0300">Plant disease has become a major threat to global food security <a name="bb0005" href="#b0005" class="workspace-trigger">[1]</a>. Plant diseases contribute 10–16% losses in the global harvest of crops each year costing an estimated US$220 billion <a name="bb0010" href="#b0010" class="workspace-trigger">[2]</a>. According to a report of the Food and Agriculture Organization (FAO) <a name="bb0015" href="#b0015" class="workspace-trigger">[3]</a>,
 our world population is anticipated to hit 9.1 billion in 2050. 
Therefore, agricultural production needs to be increased up to 70% to 
fulfill the food requirements of a steadily growing population. On the 
other hand, abundant use of chemicals such as bactericides, fungicides, 
and nematicides to control plant diseases has been causing adverse 
effects in the agro-ecosystem. Currently, there is a need for effective 
early disease detection techniques to control plant diseases for food 
security and sustainability of agro-ecosystem.</p><p id="p0305">Plant disease affects the quality of fruits, vegetables, grains, legumes and causes heavy losses in production <a name="bb0020" href="#b0020" class="workspace-trigger">[4]</a>, <a name="bb0025" href="#b0025" class="workspace-trigger">[5]</a>. Lethal plant diseases result in high mortality in plants. For example, cadang-cadang (dying-dying) disease of coconut palm (<em>Cocus nucifera</em>
 L.) causes premature decline and death of coconut palms. It was 
reported to have killed over 40 million coconut palms in the central 
Philippines since first being described in 1914 <a name="bb0030" href="#b0030" class="workspace-trigger">[6]</a>. Typically, plant disease damages the photosynthetic apparatus and affects the growth of plant <a name="bb0035" href="#b0035" class="workspace-trigger">[7]</a>.
 Most plant diseases (around 85%) are caused by fungal or fungal-like 
organisms. Other serious diseases of plants are caused by bacteria, 
viruses, and viroids, and few diseases are caused by certain nematodes <a name="bb0040" href="#b0040" class="workspace-trigger">[8]</a>.</p><p id="p0310">Pathogenic
 microorganisms are ubiquitous in nature. Pathogens characterize the 
symptoms in the plants and produce diseases due to the susceptibility of
 the plant against adverse impacts of the pathogens. The majority of 
pathogens carry out essential activities in nature, obtain nourishment 
from the host, and associate with plants via symbiotic or non-symbiotic 
relationships. Suspected plants are required to be identified by their 
external fruit and foliar symptoms on fruits and leaves prior to 
investigation in the laboratory. In most cases, these visible symptoms 
typically manifest in the middle to later stages of the infection <a name="bb0005" href="#b0005" class="workspace-trigger">[1]</a>.
 However, morphological identification of diseases is not reliable. An 
appropriate method is needed for detection of the causal agent.</p><p id="p0315">Traditionally,
 fungi were identified morphologically followed by isolating and 
culturing. While biochemical tests were employed to detect bacteria, and
 viruses were identified based on genetic material, transmission assays 
and their host range <a name="bb0020" href="#b0020" class="workspace-trigger">[4]</a>.
 Recently, the advancements in the field of biotechnology and molecular 
biology have revolutionized the field of plant disease detection. 
Several invasive diagnostic techniques such as Western blotting, 
Enzyme-Linked Immuno-Sorbent Assay (ELISA), Reverse Transcription 
Polymerase Chain Reaction (RT-PCR) and microarrays have been developed <a name="bb0020" href="#b0020" class="workspace-trigger">[4]</a>.
 A plant disease can be detected with the onset of the symptoms by these
 laboratory techniques. These techniques are also referred to as 
molecular marker or destructive techniques. They involve destructive 
leaf sampling followed by chemical treatment.</p><p id="p0320">Every 
technique has its own advantages and limitations. Researchers prefer to 
adopt invasive techniques because of their speed and accuracy in disease
 detection. However, invasive techniques pose inconsistency and 
insensitivity due to different reasons, including host-pathogen 
interaction and concentration. For example, Coconut cadang-cadang viroid
 (CCCVd) is a causal agent of orange spotting disease of oil palm (<em>Elaeis guineensis</em> Jacq.) which can be detected using RT-PCR <a name="bb0045" href="#b0045" class="workspace-trigger">[9]</a>, <a name="bb0050" href="#b0050" class="workspace-trigger">[10]</a>, Ribonuclease Protection Assay (RPA) <a name="bb0055" href="#b0055" class="workspace-trigger">[11]</a>, and Reverse Transcription Loop-mediated Isothermal Amplification (RT-LAMP) <a name="bb0060" href="#b0060" class="workspace-trigger">[12]</a>.
 But, a recent study found that these techniques were neither consistent
 nor sensitive, and not able to quantify the viroid concentrations <a name="bb0065" href="#b0065" class="workspace-trigger">[13]</a>. Similarity, Sakudo et al. <a name="bb0070" href="#b0070" class="workspace-trigger">[14]</a>
 found that invasive techniques (i.e. ELISA, RT-PCR and Western 
blotting) were effective for diagnosis of viral infections, but none of 
them were ideal in terms of cost-effectiveness, speed, and accuracy. 
Recently, Cui et al. <a name="bb0075" href="#b0075" class="workspace-trigger">[15]</a> have reviewed advantages and disadvantages of invasive and non-invasive techniques.</p><p id="p0325">There
 is a few more techniques which are also frequently used, i.e. 
Polymerase Chain Reaction (PCR) and Fluorescence In-situ Hybridization 
(FISH). The PCR is easy to operate and portable, but has been subjected 
to DNA extraction, and inhibitors and polymerase activity <a name="bb0080" href="#b0080" class="workspace-trigger">[16]</a>, <a name="bb0085" href="#b0085" class="workspace-trigger">[17]</a>.
 FISH is a highly sensitive technique allowing simultaneous 
visualization, identification, enumeration, and localization of 
individual microbial cells, but auto-fluorescence of microorganism is a 
major challenge for this technique <a name="bb0090" href="#b0090" class="workspace-trigger">[18]</a>.</p><p id="p0330">In
 the last decade, a number of non-invasive techniques have been 
developed, which are sensitive, consistent, standard, high throughput, 
rapid and cost-effective. Application of non-invasive techniques has 
been steadily increasing. The most popular non-invasive techniques are: 
fluorescence spectroscopy, Visible/Near-Infrared (VNIR) spectroscopy, 
fluorescence imaging, and hyperspectral imaging <a name="bb0095" href="#b0095" class="workspace-trigger">[19]</a>.</p><p id="p0335">Hyperspectral
 imaging is an important technique in remote sensing. Hyperspectral 
sensors capture the data from the visible through the Near Infra-Red 
(NIR) range of the electromagnetic spectrum, and acquire the spectral 
information from hundreds of narrow spectral bands <a name="bb0100" href="#b0100" class="workspace-trigger">[20]</a>. This paper is intended to review the applications of hyperspectral imaging for plant disease detection.</p><p id="p0340">The
 concept of hyperspectral imaging came into existence in the 1970s as a 
supporting field spectral measurement for Landsat-1. In 1983, Airborne 
Imaging Spectrometer (AIS) was designed by National Aeronautics and 
Space Administration Jet Propulsion Laboratory (NASA/JPL) as an 
alternative to satellite. The Airborne Visible/infrared Imaging 
Spectrometer (AVIRIS) followed in 1987, which is the most important 
hyperspectral data provider <a name="bb0105" href="#b0105" class="workspace-trigger">[21]</a>.
 Currently, development of hyperspectral imaging has reached in its 
blooming stage. The hyperspectral sensors are not only orbiting around 
Earth <a name="bb0110" href="#b0110" class="workspace-trigger">[22]</a>, but also around Mars <a name="bb0115" href="#b0115" class="workspace-trigger">[23]</a>.</p><p id="p0345">Hyperspectral
 imaging is one of the most efficient and fast-developing techniques, 
for extraction of more precise and detailed information about an object <a name="bb0120" href="#b0120" class="workspace-trigger">[24]</a>. For example, hyperspectral sensors as a tool for field spectroscopy have been applied for applications in geology <a name="bb0125" href="#b0125" class="workspace-trigger">[25]</a>, <a name="bb0130" href="#b0130" class="workspace-trigger">[26]</a> and agriculture <a name="bb0135" href="#b0135" class="workspace-trigger">[27]</a>, <a name="bb0140" href="#b0140" class="workspace-trigger">[28]</a>.
 Hyperspectral imaging has been used for various applications such as 
detection, classification, discrimination, identification, and 
characterization <a name="bb0145" href="#b0145" class="workspace-trigger">[29]</a>, <a name="bb0150" href="#b0150" class="workspace-trigger">[30]</a>.</p><p id="p0350">These advantages of hyperspectral imaging has made precision plant protection even more achievable. Several recent studies <a name="bb0155" href="#b0155" class="workspace-trigger">[31]</a>, <a name="bb0160" href="#b0160" class="workspace-trigger">[32]</a>, <a name="bb0165" href="#b0165" class="workspace-trigger">[33]</a>, <a name="bb0170" href="#b0170" class="workspace-trigger">[34]</a>, <a name="bb0175" href="#b0175" class="workspace-trigger">[35]</a>, <a name="bb0180" href="#b0180" class="workspace-trigger">[36]</a>
 have attempted to explain the role of hyperspectral bands in 
discriminating between healthy and diseased plants. The literature 
highlights more thorough and dynamic interpretation of hyperspectral 
data that are geared toward early detection of plant diseases. For 
example, Moghadam et al. <a name="bb0185" href="#b0185" class="workspace-trigger">[37]</a>
 described the importance of full range hyperspectral imaging and 
machine learning techniques in discriminating between healthy and Tomato
 Spotted Wilt Virus (TSWV) infected plants of capsicum. Different 
Vegetation Indices (VIs) and data-driven probabilistic topic models were
 used to train the classifiers for detection of TSWV. Ahmadi et al. <a name="bb0190" href="#b0190" class="workspace-trigger">[38]</a>
 detected Ganoderma basal stem rot disease of oil palm in its early 
stage from spectroscopic and imagery data using artificial neural 
network.</p><p id="p0355">More often than not, spectral signatures of a 
diseased plant could not be analyzed correctly using parametric 
approaches such as simple or multiple regression and functional 
statistics. Therefore, non-parametric approaches such as Principal 
Component Analysis (PCA), Fuzzy logic, Support Vector Machine (SVM), 
Cluster Analysis (CA), Partial Least-Square (PLS), and Neural Networks 
(NNs) have been employed in the area of hyperspectral spectroscopy. For 
example, Fisher’s Linear Discriminant Analysis (LDA) technique is used 
to classify imaging and non-imaging hyperspectral data with two or more 
classes.</p><p id="p0360">Hyperspectral data are basically multivariate 
in nature. PCA is a multivariate statistical method that eliminates 
redundancy in univariate analyses. PCA helps to identify patterns of 
spectral data. Basically, PCA transforms large numbers of correlated 
variables into smaller number of uncorrelated variables, called 
Principal Component (PC) <a name="bb0195" href="#b0195" class="workspace-trigger">[39]</a>.
 The PCA and PLS were recently used for detection of fungal diseases 
(yellow rust and fusarium head blight) of wheat and barley <a name="bb0160" href="#b0160" class="workspace-trigger">[32]</a>, <a name="bb0165" href="#b0165" class="workspace-trigger">[33]</a>. Whetton et al. <a name="bb0160" href="#b0160" class="workspace-trigger">[32]</a>
 conducted PCA on healthy and yellow rust and fusarium infected cereal 
crops at different growth stages and studied their temporal pattern and 
serial autocorrelation. The results suggested to use PLS for each 
growing stage for accurate prediction. In the second part of the study, 
Whetton et al. <a name="bb0165" href="#b0165" class="workspace-trigger">[33]</a>
 used PLS regression with leave-one-out cross-validation for both 
diseases. Results showed that the regression model developed for 
fusarium head blight and yellow rust in wheat can be applied to predict 
these diseases in barley.</p><p id="p0365">Recently, Lu et al. <a name="bb0155" href="#b0155" class="workspace-trigger">[31]</a>
 also conducted PCA to evaluate fifty-seven different VIs and obtained 
six PCs for detecting multi-diseased tomato leaves at different stages. 
The K-nearest neighbor classifier was used for classifying each PC with 
weight coefficients ranking from 1 to 30. Highest classification 
accuracy (100%) was achieved for healthy leaves amongst the tested 
healthy and diseased leaves of tomato. Using the concept of Fuzzy set 
theory, Kole et al. <a name="bb0200" href="#b0200" class="workspace-trigger">[40]</a>
 proposed digital image processing operations with K-means for detection
 of downy mildew disease in grape leaves. A total of 31 digital images 
of diseased and healthy grape plants were processed. An 87% detection 
accuracy was obtained in this study.</p><p id="p0370">The CA is one of 
the most widely used techniques. To organize hyperspectral data, CA 
allows for grouping of pixels within similar spectral values and builds 
the clusters <a name="bb0205" href="#b0205" class="workspace-trigger">[41]</a>. Krezhova et al. <a name="bb0210" href="#b0210" class="workspace-trigger">[42]</a> applied CA and student <em>t</em>-test
 for determination of statistical significance of difference between 
means of reflectance values from control and infected apple trees. The 
SVM is a popular machine learning technique, which is suitable for the 
analysis of high-dimensional spectral data <a name="bb0215" href="#b0215" class="workspace-trigger">[43]</a>. Nagasubramanian et al. <a name="bb0220" href="#b0220" class="workspace-trigger">[44]</a>
 used Genetic Algorithm (GA), an optimizer, with SVM for selection of 
optimal spectral bands for early identification of charcoal rot disease 
in soybean. GA-SVM approach identified charcoal rot disease within three
 days after inoculation with 97% classification accuracy.</p><p id="p0375">The
 machine learning techniques have two major disadvantages. First, they 
are highly dependent on the patterns of variables, as well as on the 
features which are going to be extracted. Second, classifiers are 
required to be trained many times before being applied to real world 
applications <a name="bb0225" href="#b0225" class="workspace-trigger">[45]</a>.</p><p id="p0380">NNs
 are the most promising tools for hyperspectral data analysis. The 
mechanism of NNs is based on the human nervous system. Basically, NNs 
are very useful for pattern recognition, regardless of any explicit 
recognition rules <a name="bb0230" href="#b0230" class="workspace-trigger">[46]</a>. Cui et al. <a name="bb0075" href="#b0075" class="workspace-trigger">[15]</a> reported that NNs require less formal statistics and are able to model complex nonlinear relationships.</p><p id="p0385">There
 is a growing interest in applying NNs to achieve the greater goal of 
precision plant protection using hyperspectral data. Precision plant 
protection offers a holistic means of controlling plant diseases based 
on the concept of spatial-temporal variability. Previously, NNs have 
been used for data mining purposes but its various applications with 
hyperspectral data have shown promise for early disease detection. It 
has unique capabilities such as learning, generalization, and 
imagination to facilitate a reliable diagnosis of plant disease. NNs 
have a higher degree of diagnosability than other machine learning 
techniques.</p><p id="p0390">These days, processing huge data volume of high dimensional hyperspectral imageries is one of the challenging problems <a name="bb0235" href="#b0235" class="workspace-trigger">[47]</a>.
 Data dimensionality reduction is an important and efficient application
 for managing hyperspectral data. It has been reported that high degree 
of data dimensionality reduction could be achieved when good 
classification accuracy is retained in hyperspectral data <a name="bb0240" href="#b0240" class="workspace-trigger">[48]</a>.
 It is well known that hyperspectral data contain the apparent and 
inherent spectral information, so its accomplishments and capabilities 
must be deliberated using NNs.</p><p id="p0395">NNs endorse the most 
powerful discriminating capability for plant diseases because they 
combine the best trainer sets for accurate classification. Marini et al.
 <a name="bb0245" href="#b0245" class="workspace-trigger">[49]</a> 
described a particular type of NN-based pattern recognition technique 
called class-modeling. Class-modeling has a good discriminating 
capability to enable development of plant disease models. The most 
popular class-modeling tools were developed on the basis of Kohonen 
artificial neural network <a name="bb0250" href="#b0250" class="workspace-trigger">[50]</a> and multilayer feed-forward network <a name="bb0255" href="#b0255" class="workspace-trigger">[51]</a>.</p><p id="p0400">Al Bashish et al. <a name="bb0260" href="#b0260" class="workspace-trigger">[52]</a>
 used an image processing based framework for detection of five 
diseases, namely, early scorch, cottony mold, ashen mold, late scorch, 
and tiny whiteness of rice leaves and stems. The K-means was used for 
clustering the diseased leaf images. Then clustered images were passed 
through an NN classifier. The result described that NN classifier 
detected leaf diseases with an accuracy of 93%. This framework 
significantly supports accurate and automatic detection of leaf 
diseases.</p><p id="p0405">Zhu et al. <a name="bb0265" href="#b0265" class="workspace-trigger">[53]</a>
 investigated the potential of hyperspectral imaging as a non-invasive 
fast detection technique. They detected Tobacco Mosaic Virus (TMV) 
disease in a short period of time using hyperspectral imaging combined 
with the variable selection method and machine-learning classifiers. The
 accuracies were up to 95% for Back Propagation Neural Network (BPNN), 
Extreme Learning Machine (ELM), and Least Squares Support Vector Machine
 (LS-SVM) models, and up to 80% for chemometric models with data fusion.
 In a similar study, Zhu et al. <a name="bb0270" href="#b0270" class="workspace-trigger">[54]</a>
 tested BPNN along with SVM, ELM, LS-SVM, Partial Least 
Squares-Discrimination Analysis (PLS-DA), LDA, and Random Forest (RF) to
 process the hyperspectral images for presymptomatic detection and 
classification of TMV in tobacco leaves.</p><p id="p0410">A new approach
 called artificial intelligent nose (electronic nose) is a fast and 
non-invasive technique for diagnosis of plant disease <a name="bb0075" href="#b0075" class="workspace-trigger">[15]</a>.
 Pattern recognition techniques such as RF, CA, SVM, linear regression 
can be applied with electronic nose for pattern recognition. In spite of
 an extended range of NN applications, including data dimensionality 
reduction and classification, NNs ensure unadulterated high-quality 
spectral information for hyperspectral data analysis.</p><p id="p0415">A
 ratio of different wavelengths of pure disease spectra called Spectral 
Disease Index (SDI) also requires such specific machine-learning 
algorithms that could help to simplify and possibly expedite detection 
of plant disease. Ashourloo et al. <a name="bb0275" href="#b0275" class="workspace-trigger">[55]</a>
 described that SDIs are very effective for dimensionality reduction. 
SDIs increase the rate of disease estimation. However, a small number of
 SDIs has so far been developed from imaging and non-imaging 
hyperspectral remote sensing data and not processed using NNs. The 
general objectives of this review are:<dl class="list"><dt class="list-label">1.</dt><dd class="list-description"><p id="p0420">To discuss applicability of NNs to the analysis of hyperspectral data for early disease detection</p></dd><dt class="list-label">2.</dt><dd class="list-description"><p id="p0425">To review new SDIs that could be employed in detecting plant diseases using NN classifiers</p></dd></dl></p></section><section id="s0010"><h2 id="st025">2. Mechanism of neural networks</h2><p id="p0430">NNs
 are mathematical models that have been used in data mining. 
Fundamentally, NNs are an interconnected network of nodes, parallel to 
the vast network of neurons in the human brain. In an Artificial Neural 
Network (ANN), each node assigned to the network represents a neuron. 
Generally, neurons receive the signals from other similar neurons via 
synapse connection. A neuron typically connects to an individual 
processing element, which is called perceptron. In a network, the 
neurons play an important role, they accept and process the inputs and 
create the outputs <a name="bb0280" href="#b0280" class="workspace-trigger">[56]</a>, <a name="bb0285" href="#b0285" class="workspace-trigger">[57]</a>.
 Generally, the connection between two neurons carries the weights in 
which the electrical information is encoded implicitly. Then electrical 
information simulates with specific values stored in those weights that 
enable the networks to have capabilities like learning, generalization, 
imagination and creating the relationship within the network <a name="bb0290" href="#b0290" class="workspace-trigger">[58]</a>.</p><p id="p0435">The first model of ANN was proposed by McCulloch and Pitts in 1943 <a name="bb0295" href="#b0295" class="workspace-trigger">[59]</a>.
 This model was based on a “computing element” also known as 
Mc-Culloch-Pitts neuron. Since then, this model has inspired many 
researchers to design fast computing models that have the functioning 
ability like a human brain; such that they are called ANNs. In the 
contrary, ANNs operate in a feed-forward mode from the input layer 
through the hidden layers to the output layer <a name="bb0300" href="#b0300" class="workspace-trigger">[60]</a>.
 The hidden layer acts somewhat like a ‘black box’ which can sometimes 
pose complexity to the human brain. This drawback in ANNs has remained 
an obstacle to their acceptance.</p><div><p id="p0440">Nevertheless, NNs are a promising tool for feature selection from spectral data <a name="bb0305" href="#b0305" class="workspace-trigger">[61]</a>. Almeida <a name="bb0310" href="#b0310" class="workspace-trigger">[62]</a>
 defined NNs as artificial intelligence tools that identify arbitrary 
non-linear multi parametric discriminant functions directly from 
experimental data. The hyperspectral data are typical example of such 
experimental data. A group of neurons or perceptrons is assembled in an 
interconnected network that forms an ANN model. The ANN model represents
 a non-linear structure combining input, output and hidden layers as 
shown in <a name="bf0005" href="#f0005" class="workspace-trigger">Fig. 1</a>. Marini et al. <a name="bb0245" href="#b0245" class="workspace-trigger">[49]</a> described NNs as interconnecting pathways of neurons organized into a sequence of layers.</p><figure class="figure" id="f0005"><span id="download-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-gr1.jpg" alt="" aria-describedby="cn0005" height="134"><ol class="links-for-figure"><li><a href="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-gr1_lrg.jpg" target="__blank">Download high-res image (78KB)</a></li><li><a href="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-gr1.jpg" target="__blank">Download full-size image</a></li></ol></span><div class="captions"><span id="cn0005"><p id="sp0015"><span class="label">Fig. 1</span>. The multi-layer NN consisting input layer, hidden layer, and output layer.</p></span></div></figure></div><p id="p0445">In
 the context of hyperspectral data analysis, a simple NN model can be 
obtained by defining the neurons, their connections, and outputs. For 
example, in a three-layer NN, the first layer is an input layer with one
 node for each spectral band. The second layer is one or more hidden 
layer(s), in which nodes entail reflectance values of each spectral 
band. The last layer is an output layer consisting the nodes usually 
computed by a non-linear combination of the nodes of input and hidden 
layers. A three-layer NN model is the most dynamic and widely used.</p></section><section id="s0015"><h2 id="st030">3. Major types of NNs</h2><p id="p0450">This
 section provides a brief description of the major types of NNs which 
are Single-Layer Perceptron (SLP), Multi-Layer Perceptron (MLP), 
Radial-Basis Function (RBF) networks, Kohonen's Self-Organising Map 
(SOM) networks, Probabilistic Neural Network (PNN), and Convolutional 
Neural Network (CNN).</p><section id="s0020"><h3 id="st035">3.1. Single-Layer Perceptron (SLP)</h3><p id="p0455">In 1958, Rosenblatt introduced Rosenblatt’s perceptron algorithm and the mechanism of SLP <a name="bb0315" href="#b0315" class="workspace-trigger">[63]</a>.
 Later in 1961, Rosenblatt derived the perceptron rules which yield the 
optimal weight vector to the perceptron instead of the initial weight 
values <a name="bb0320" href="#b0320" class="workspace-trigger">[64]</a>. In the early 1960s, it was also found that SLP can assign the input vectors to one of two classes <a name="bb0325" href="#b0325" class="workspace-trigger">[65]</a>.
 Basically, the concept of SLP is based on an activation function that 
transforms the linear combination into a non-linear function, which is 
also called the simple discriminant. Another extension of this approach 
is called linear discriminant in which input variables transform into 
non-linear functions before forming linear combination. The linear 
discriminants give promise that an SLP with adaptive weight connects the
 input and the output. Linear Discriminant Functions (LDFs), Linear 
separability, Generalized Linear Discriminants (GLD), Fisher’s LDA are 
few techniques that determine the weights for SLP <a name="bb0330" href="#b0330" class="workspace-trigger">[66]</a>. It is possible for the SLP network to comprise one or more artificial neurons <a name="bb0335" href="#b0335" class="workspace-trigger">[67]</a>
 that senses different optimal weight vectors which can be assigned to 
different neurons. Furthermore, the SLP is the key elementary component 
of the multilayer feed-forward network. It is also known as the simplest
 prototype for studying the general non-linear MLPs <a name="bb0340" href="#b0340" class="workspace-trigger">[68]</a>.</p><p id="p0460">Monteiro et al. <a name="bb0345" href="#b0345" class="workspace-trigger">[69]</a>
 implemented SLP and MLP architectures for visual inspection of blood 
covering surgical fields using hyperspectral data. These architectures 
were capable of learning the combinations of reflectance bands of 
various spectral fields. Both the architectures had generated good 
visualization, but SLP produced more noise in output. An SLP 
architecture can provide a simple and comprehensible verification for 
the feasibility of hyperspectral data. This was a significant 
application in diagnostic hyperspectral imaging <a name="bb0350" href="#b0350" class="workspace-trigger">[70]</a>. Monteiro et al. <a name="bb0345" href="#b0345" class="workspace-trigger">[69]</a>
 recommended remote assessment of crop disease may be possible through 
this approach. So far SLP architecture has not been applied anywhere for
 crop disease detection using hyperspectral data.</p></section><section id="s0025"><h3 id="st040">3.2. Multi-Layer Perceptron (MLP)</h3><p id="p0465">MLP
 consists more than one hidden layer of perceptron in a network. A 
common set of layers in an MLP has input, output, and hidden layers. In 
an ANN, the input layer is the first passive layer acts a conduit for 
entering the data. The second layer is a hidden layer. Paola and 
Schowengerdt <a name="bb0355" href="#b0355" class="workspace-trigger">[71]</a>
 emphasized the importance of hidden layer in a network to increase the 
network’s ability and for modeling the complex problems. The last layer 
is the output layer that produces the output signals at the network. 
Since the SLP is not of practical utility these days, the MPL is most 
suitable for analyzing hyperspectral data specifically in the context of
 non-destructive disease detection for high performance classification <a name="bb0360" href="#b0360" class="workspace-trigger">[72]</a>, <a name="bb0365" href="#b0365" class="workspace-trigger">[73]</a></p><p id="p0470">Moshou et al. <a name="bb0365" href="#b0365" class="workspace-trigger">[73]</a>
 used MLP architecture in order to detect yellow rust in wheat crop. The
 MLP architecture was designed for input layer having neurons equal to 
the number of processed spectral bands, one hidden layer with different 
numbers of neurons varying from 5 to 25, and output layer consisting of 
two neurons, each for healthy and diseased crop. They used a handheld 
spectrograph (460–900 nm) for capturing the images in wheat field. In 
this work, four optimal spectral bands were selected. They tested 
different quantities of neurons, then most efficient neurons were 
selected for final MLP architecture. The MLP architecture produced over 
98% classification accuracy for the healthy plants and over 99% 
classification accuracy for diseased plants.</p><p id="p0475">Recent 
researches have demonstrated that the MLP is a highly applicable 
network. Most of the MLP networks are trained with the back-propagation 
algorithms. Therefore MLP is a very popular choice among researchers <a name="bb0370" href="#b0370" class="workspace-trigger">[74]</a>.
 Back-propagation algorithms employ a supervised learning paradigm in 
MPL, which minimizes errors between the desired outputs and the 
calculated outputs driven from the inputs and network learning <a name="bb0375" href="#b0375" class="workspace-trigger">[75]</a>.</p></section><section id="s0030"><h3 id="st045">3.3. Radial-Basis Function (RBF)</h3><p id="p0480">RBF networks were first proposed by Moody and Darken <a name="bb0380" href="#b0380" class="workspace-trigger">[76]</a>.
 In a three-layer network, an RBF network combines a layer of inputting 
neurons, a hidden layer of RBF neurons and a layer of outputting neurons
 <a name="bb0385" href="#b0385" class="workspace-trigger">[77]</a>. Alexandridis et al. <a name="bb0390" href="#b0390" class="workspace-trigger">[78]</a>
 described the importance of hidden layer in the RBF networks. They 
showed that hidden layer linearly connects to the output node and 
calculates the input variables passed via input layer to the hidden 
layer. A process of non-linear transformation is also carried out at the
 hidden layer resulting in a map between the neurons of input and hidden
 layers. Chen et al. <a name="bb0395" href="#b0395" class="workspace-trigger">[79]</a>
 also described that in order to establish the nonlinear relationships 
in the input data, the hidden layer of the RBF network plays an 
important role in data modeling. Yang et al. <a name="bb0400" href="#b0400" class="workspace-trigger">[80]</a>
 focused on its various advantages such as parametric modeling, 
nonlinear interpolation, function approximation, and classification of 
the sensory data (vis-à-vis the hyperspectral remote sensing data).</p><p id="p0485">In a recent study, Abdulridha et al. <a name="bb0360" href="#b0360" class="workspace-trigger">[72]</a>
 used RBF, MLP and stepwise discriminant analysis for detecting Laurel 
wilt (Lw) disease of avocado at early and late stage of infection. They 
found that VNIR range (400–950 nm) was sufficient to show spectral 
differences between Lw, healthy trees, and trees that have other 
stresses such as Phytophthora root rot and salinity-damage. They 
collected reflectance using handheld spectroradiometer and averaged 
total number of spectral bands in two bandwidths i.e. 10 nm and 40 nm. 
Subsequently, the narrower bandwidth (10 nm) did not produce better 
results than wider bandwidth (40 nm). Almost parallel classification 
results were obtained at both the bandwidths. An MLP model registered 
the best classification accuracy (over 98%) than stepwise discriminant 
analysis and RBF models at early and late stages. They further mentioned
 that developing classification model like RBF is useful for disease 
detection at both the early and the late stage but results in lower 
detection accuracy.</p></section><section id="s0035"><h3 id="st050">3.4. Kohonen's Self-Organising Map (SOM)</h3><p id="p0490">SOM <a name="bb0405" href="#b0405" class="workspace-trigger">[81]</a>
 is known as an unsupervised learning network. Fundamentally, SOM 
follows the architecture of a two-layer feed-forward network. These two 
layers are input layer and Kohonen layer. In SOM network, neurons are 
arranged in the grid form, either in hexagonal or rectangular array. 
Input layer is connected to the Kohonen layer where Kohonen map is 
formed. Technically, a map is created at the input space. Kohonen map is
 a discrete representation used for visualizing high-dimensional data at
 the low-dimensional view. This network uses a neighborhood function 
that preserves the topological properties of the map and detects 
regularities of input <a name="bb0410" href="#b0410" class="workspace-trigger">[82]</a>.</p><p id="p0495">Lawrence et al. <a name="bb0415" href="#b0415" class="workspace-trigger">[83]</a> used aerial and handheld hyperspectral sensors for studying infestation of Reniform nematode (<em>Rotylenchulus reniformis</em>)
 in cotton using supervised NN-SOM architecture. Different hyperspectral
 signatures were developed on the basis of nematode colonization and 
level of infection in cotton plants. The NN-SOM architecture predicted 
infection in a range between 83 and 97%. According to Lawrence et al. <a name="bb0415" href="#b0415" class="workspace-trigger">[83]</a>
 evaluation of larger amounts of hyperspectral data needs an advance NN 
model (like NN-SOM) with expanded capacity for data processing in 
computer. In a similar study, Lawrence et al. <a name="bb0420" href="#b0420" class="workspace-trigger">[84]</a> demonstrated spatial distribution of the nematode infestation and established different zones for nematicides applications.</p></section><section id="s0040"><h3 id="st055">3.5. Probabilistic Neural Network (PNN)</h3><p id="p0500">Specht <a name="bb0425" href="#b0425" class="workspace-trigger">[85]</a> introduced the PNN based on the statistical approach called Bayesian classifiers. Specht <a name="bb0430" href="#b0430" class="workspace-trigger">[86]</a>
 showed that Bayesian classifier could improve the predictability by 
taking relative likelihood and priori information into consideration. 
PNN is a feed-forward network comprising input, hidden and output 
layers. The hidden layer is also known as pattern layer. In particular, 
pattern layer consists of Bayesian classifier. The PNN is functioned 
upon utilizing a non-parametric estimator for obtaining multivariate 
probability and estimating density. At present, PNN remains the most 
appropriate neural architecture for solving classification problems.</p><p id="p0505">For detection of rice leaves infected by <em>Aphelenchoides besseyi</em> Christie (at rice booting stage) and by rice leaf roller (at the rice tillering stage), Li et al. <a name="bb0435" href="#b0435" class="workspace-trigger">[87]</a>
 applied PNN architecture over visible (490–670 nm) and Shortwave 
Infrared (SWIR) (1520–1750 nm) spectral bands. PCA was used to transform
 visible and SWIR bands into principal component spectrum. PNN predicted
 both disease and pest infection with an accuracy of 95.65%. The PCA and
 PNN together have been proved to be a reliable predictor of disease and
 pest infection in rice leaves.</p></section><section id="s0045"><h3 id="st060">3.6. Convolutional Neural Network (CNN)</h3><p id="p0510">In
 the recent years, deep learning in NNs has been getting much 
prominences. Unsupervised classification is the most active research 
area in hyperspectral data analysis. CNN is a leading unsupervised deep 
learning architecture that learns ‘filters performing convolutions’ in 
the image domain <a name="bb0440" href="#b0440" class="workspace-trigger">[88]</a>.
 A measure difference between CNN and conventional NNs is that CNN is 
inspired from retinal fields in the vision system. In a simple word, CNN
 is an integration of biological vision and neural system. Lowe et al. <a name="bb0440" href="#b0440" class="workspace-trigger">[88]</a>
 described CNN is a complex architecture which takes considerably more 
time to train the neurons. Nonetheless, it has remarkable classification
 accuracy, and rate of object recognition is very high.</p><p id="p0515">Mohanty et al. <a name="bb0445" href="#b0445" class="workspace-trigger">[89]</a>
 deployed an automated image recognition system in which widespread 
smartphone penetration, HD cameras, and high performance processors were
 used for plant disease detection. This model based on an automated 
image recognition system and CNN achieved an overall accuracy of 99.35% 
on a held-out test data. This classification accuracy demonstrates the 
technical feasibility of CNN approach. They used the CNN to detect 26 
diseases over 14 crop species. A total of 54,306 colour images was 
tested. Sladojevic et al. <a name="bb0450" href="#b0450" class="workspace-trigger">[90]</a>
 also developed a plant disease recognition model based on leaf image 
classification using CNN. They downloaded a large set of online 
available images of 13 crop diseases, including powdery mildew, rust 
(apple), leaf spot (pear), and wilt, mites, downey mildew (grapevine). 
This model achieved an overall detection accuracy of 96.3%.</p><p id="p0520">In
 particular, CNN has proven to be a powerful tool for recognition and 
classification of hyperspectral images, as well as extracting their 
nonlinear, discriminant, and invariant features <a name="bb0455" href="#b0455" class="workspace-trigger">[91]</a>, <a name="bb0460" href="#b0460" class="workspace-trigger">[92]</a>, <a name="bb0465" href="#b0465" class="workspace-trigger">[93]</a>. In a recent study, Langford et al. <a name="bb0470" href="#b0470" class="workspace-trigger">[94]</a>
 implemented the CNN to develop an arctic vegetation map using 
multi-sensor data fusion approach integrating hyperspectral, 
multispectral, radar, and terrain datasets. They found that 
hyperspectral datasets provide highest data content to the CNN model. 
Spectral signatures developed from hyperspectral data played a very 
significant role to the predictability of vegetation. From the 
perspective of multi-sensor data fusion, we believe that such vegetation
 maps will facilitate remote detection of plant diseases that spread 
over large areas.</p><div><p id="p0525">Generally, more than one NNs 
were used for classification of hyperspectral dataset in studying 
prediction accuracy. More than 90% classification accuracy was achieved 
in all the NNs, as shown in <a name="bt0005" href="#t0005" class="workspace-trigger">Table1</a>. However, Monteiro et al. <a name="bb0345" href="#b0345" class="workspace-trigger">[69]</a>
 encountered a nontrivial problem in selecting the optimal spectral 
bands, which can be resolved using a non-linear solution technique.</p><div class="tables frame-topbot rowsep-0 colsep-0" id="t0005"><div class="captions"><span id="cn0015"><p id="sp0025"><span class="label">Table 1</span>. List of major contributions according to different types of NNs for plant disease detection.</p></span></div><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">Authors and year</th><th scope="col" class="align-left">Types of NNs</th><th scope="col" class="align-left">Species</th><th scope="col" class="align-left">Disease/pest</th><th scope="col" class="align-left">Disease recognition (Detection accuracy %)</th><th scope="col" class="align-left">Types of decision regions</th></tr></thead><tbody><tr class="valign-top"><td class="align-left">Monteiro et al. <a name="bb0345" href="#b0345" class="workspace-trigger">[69]</a><br>Towards applying hyperspectral imagery as an intraoperative visual aid tool (2004)</td><td class="align-left">SLP, MLP</td><td class="align-left">–</td><td class="align-left">Recommended for remote assessment of plant disease</td><td class="align-left">–</td><td class="align-left">Half plan bounded by hyperplane</td></tr><tr class="valign-top"><td class="align-left">Moshou et al. <a name="bb0365" href="#b0365" class="workspace-trigger">[73]</a><br>Automatic detection of “yellow rust” in wheat using reflectance measurements and neural networks (2004)</td><td class="align-left">MLP, SOM</td><td class="align-left">Wheat<br>(<em>Triticum</em> sp.)</td><td class="align-left">Yellow rust</td><td class="align-left">99%</td><td class="align-left">Arbitrary<br>(Complexity limited by no. of nodes)</td></tr><tr class="valign-top"><td class="align-left">Abdulridha et al. <a name="bb0360" href="#b0360" class="workspace-trigger">[72]</a><br>Detection
 and differentiation between Laurel wilt disease, phytophthora disease, 
and salinity damage using a hyperspectral sensing technique (2016)</td><td class="align-left">RBF, MLP</td><td class="align-left">Avocado<br>(<em>Persea americana</em>)</td><td class="align-left">Laurel wilt (Lw) disease</td><td class="align-left">98%</td><td class="align-left">Arbitrary</td></tr><tr class="valign-top"><td class="align-left">Lawrence et al. <a name="bb0415" href="#b0415" class="workspace-trigger">[83]</a><br>Remote sensing and precision nematicide applications for <em>Rotylenchulus reniformis</em> management in cotton (2004)</td><td class="align-left">NN-SOM</td><td class="align-left">Cotton (<em>Gossypium</em> sp.)</td><td class="align-left">Reniform nematode</td><td class="align-left">97%</td><td class="align-left">Arbitrary</td></tr><tr class="valign-top"><td class="align-left">Liu et al. <a name="bb0435" href="#b0435" class="workspace-trigger">[87]</a><br>Hyperspectral
 identification of rice diseases and pests based on principal component 
analysis and probabilistic neural network (2009)</td><td class="align-left">PNN</td><td class="align-left">Rice<br>(<em>Oryza sativa</em> L.)</td><td class="align-left"><em>Aphelenchoides besseyi</em>, Rice leaf roller</td><td class="align-left">95%</td><td class="align-left">Arbitrary</td></tr><tr class="valign-top"><td class="align-left">Mohanty et al. <a name="bb0445" href="#b0445" class="workspace-trigger">[89]</a><br>Using deep learning for image-based plant disease detection (2016)</td><td class="align-left">CNN</td><td class="align-left">–</td><td class="align-left">26 crop diseases</td><td class="align-left">99.3%</td><td class="align-left">Arbitrary</td></tr><tr class="valign-top"><td class="align-left">Sladojevic et al. <a name="bb0450" href="#b0450" class="workspace-trigger">[90]</a><br>Deep neural networks based recognition of plant diseases by leaf image classification (2016)</td><td class="align-left">CNN</td><td class="align-left">–</td><td class="align-left">13 crop diseases</td><td class="align-left">96.3%</td><td class="align-left">Arbitrary</td></tr></tbody></table></div></div></div><p id="p0530">In
 NNs, major problems are observed due to its structure itself where 
decision regions pose complexity in making decision. Single layer 
networks are half plan, bound by hyperplane, two-layer networks are 
either open or closed regions, and multi-layer networks are arbitrary 
depending on the number of nodes <a name="bb0475" href="#b0475" class="workspace-trigger">[95]</a>. Stefanowski <a name="bb0475" href="#b0475" class="workspace-trigger">[95]</a>
 described MLPs separate the classes via hyperplans while RBFs separate 
classes via hyperspheres. Additionally, MLPs use distributed learning 
while RBFs use localized learning. There are also many differences in 
terms locality, separation surface, approximation capability, and 
interpretability within the different types of NNs.</p></section></section><section id="s0050"><h2 id="st065">4. NN models</h2><p id="p0535">Different
 types of NNs are implemented on the basis of specific neural 
architectures and learning algorithms which in combination are called NN
 models. The most important NN models are discussed in this following 
section.</p><section id="s0055"><h3 id="st070">4.1. Feed-Forward Neural Network (FFNN)</h3><p id="p0540">Several studies <a name="bb0480" href="#b0480" class="workspace-trigger">[96]</a>, <a name="bb0485" href="#b0485" class="workspace-trigger">[97]</a>, <a name="bb0490" href="#b0490" class="workspace-trigger">[98]</a>
 have attempted to explain FFNN as a transformation network that 
transforms input layers to output layers in the forward direction. FFNN 
is most useful when an end user is interested in input and output layers
 and not in the hidden layers. Therefore, FFNNs have been increasingly 
used in non-parametric data analysis. FFNN is an alternative to classic 
pattern classification and clustering techniques.</p><p id="p0545">Hawkins and Bodén <a name="bb0485" href="#b0485" class="workspace-trigger">[97]</a>
 explored the relationship between input and hidden layers in a standard
 FFNN. They highlighted that one set of connections could be fully 
connected from the input layer to the hidden layer. The network 
consisted of three layers and two mapping functions for hidden and 
output nodes. Such dynamics of the FFNN was described in following 
formula:<span class="display"><div id="e0005" class="formula"><span class="math"><math><mrow is="true"><mi is="true" mathvariant="normal">f</mi><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true" mathvariant="normal">x</mi></mrow></mfenced><mo is="true">=</mo><mi is="true">σ</mi><mrow is="true"><mo stretchy="false" is="true">(</mo><msub is="true"><mi is="true">W</mi><mi is="true">F</mi></msub><mo is="true">∙</mo><mi is="true" mathvariant="normal">x</mi><mo is="true">+</mo><mi is="true" mathvariant="normal">b</mi><mo stretchy="false" is="true">)</mo></mrow></mrow></math></span></div></span>where: <span class="math"><math><msub is="true"><mi is="true">W</mi><mi is="true">F</mi></msub></math></span>
 is the weight matrix, b is the set of biases, σ is a non-linear 
activation function that uses logistic function for hidden nodes and 
softmax function for output nodes.</p><p id="p0550">The FFNN algorithm 
is one of the important standard methods for chemical characterization 
of sediments using hyperspectral data. Udelhoven and Schütt <a name="bb0495" href="#b0495" class="workspace-trigger">[99]</a>
 tested chemical properties including inorganic carbon, iron, sulfur, 
aluminium, silica, calcium, potassium and magnesium. The 214 samples of 
spectral observation were collected from various drilling locations from
 all over the central part of the Iberian Peninsula. They estimated 
chemical properties using spectral data and trained them simultaneously 
in an FFNN model. Bishop <a name="bb0500" href="#b0500" class="workspace-trigger">[100]</a>
 described a variety of different training algorithms for FFNN such as 
gradient descent methods, conjugate gradient methods, and 
Levenberg-Marquardt algorithm. Currently, the ELM learning algorithm has
 been proposed to train single hidden-layer forward network <a name="bb0505" href="#b0505" class="workspace-trigger">[101]</a>, <a name="bb0510" href="#b0510" class="workspace-trigger">[102]</a>, and this concept has been extended to multihidden-layer networks <a name="bb0515" href="#b0515" class="workspace-trigger">[103]</a> and kernel learning <a name="bb0520" href="#b0520" class="workspace-trigger">[104]</a>.</p></section><section id="s0060"><h3 id="st075">4.2. Back-Propagation Neural Network (BPNN)</h3><p id="p0555">BPNN
 is an important and widely used ANN model. Its application is very 
prospective for a variety of purposes for nonlinear data analysis. Paul 
and Munkvold <a name="bb0525" href="#b0525" class="workspace-trigger">[105]</a>
 highlighted relevance of BPNN with FFNN. In FFNN, information is fed 
through the input layer to the output layer (forward) via the hidden 
layer, thus the network is called FFNN. In the BPNN, further processing 
is directed at the output layer. A network-estimated output is generated
 and compared with the actual output. The errors are calculated as a 
difference between the actual output and the estimated output. Then, 
estimated errors are propagated from the output layer to the input 
layer, thus the term back-propagation.</p><p id="p0560">Zhang et al. <a name="bb0530" href="#b0530" class="workspace-trigger">[106]</a> showed how BPNN is used to generate derivatives of performance (i.e. <em>per f</em>)
 with respect to the weight and bias variables associated with the 
neurons. Each variable is adjusted according to gradient descent with a 
momentum. Hence BPNN algorithm is expressed as:<span class="display"><div id="e0010" class="formula"><span class="math"><math><mrow is="true"><mi is="true" mathvariant="italic">dX</mi><mo is="true">=</mo><mi is="true" mathvariant="italic">mc</mi><mo is="true">×</mo><mi is="true" mathvariant="italic">dXprev</mi><mo is="true">+</mo><mi is="true" mathvariant="italic">lr</mi><mo is="true">×</mo><mo stretchy="false" is="true">(</mo><mn is="true">1</mn><mo is="true">-</mo><mi is="true" mathvariant="italic">mc</mi><mo stretchy="false" is="true">)</mo><mo is="true">×</mo><mi is="true" mathvariant="italic">dperf</mi><mo stretchy="false" is="true">/</mo><mi is="true" mathvariant="italic">dX</mi></mrow></math></span></div></span>where: <em>dX</em> is derivatives of <em>per f</em>, <em>mc</em> is the value of momentum, <em>dXprev</em> is the previous change to the weight or bias, and <em>lr</em> is the learning parameters.</p><p id="p0565">BPNN
 can be more robust and operational using the Bayesian decision theory 
which has become more popular over the past decade. Sajda <a name="bb0535" href="#b0535" class="workspace-trigger">[107]</a>
 reported that the Bayesian decision theory may also be applicable to 
other NN models. It helps to design an intelligent system, which 
explicitly represents uncertainty in the data and decision making 
process.</p></section><section id="s0065"><h3 id="st080">4.3. Generalized regression Neural Network (GRNN)</h3><div><p id="p0570">GRNN
 is a very important network having an immense prediction capability. It
 is an adequate model for time series hyperspectral data analysis. GRNN 
can also be a robust model for real-time disease prediction by adding 
weather and vegetation variables with hyperspectral data (<a name="bf0010" href="#f0010" class="workspace-trigger">Fig. 2</a>). Chtioui et al. <a name="bb0540" href="#b0540" class="workspace-trigger">[108]</a>
 predicted leaf wetness based on weather parameters such as temperature,
 relative humidity, wind speed, solar radiation, and precipitation in 
order to forecast the crop disease. GRNN performed statistically better 
than multiple linear regression. GRNN out-performed the multiple linear 
regression in prediction accuracy. However, a substantial computational 
time is required for training the datasets. GRNN is called the realistic
 NN model. Chtioui et al. <a name="bb0540" href="#b0540" class="workspace-trigger">[108]</a> used following algorithm to express GRNN:<span class="display"><div id="e0015" class="formula"><span class="math"><math><mrow is="true"><mi is="true">E</mi><mrow is="true"><mo stretchy="false" is="true">(</mo><mi is="true">y</mi><mo stretchy="false" is="true">/</mo><mi is="true">x</mi><mo stretchy="false" is="true">)</mo></mrow><mo is="true">=</mo><mover accent="true" is="true"><mi is="true">y</mi><mo stretchy="false" is="true">̂</mo></mover><mrow is="true"><mo stretchy="false" is="true">(</mo><mi is="true">x</mi><mo stretchy="false" is="true">)</mo></mrow><mo is="true">=</mo><mfrac is="true"><mrow is="true"><msubsup is="true"><mo is="true">∫</mo><mrow is="true"><mo is="true">-</mo><mi is="true">∞</mi></mrow><mrow is="true"><mo is="true">+</mo><mi is="true">∞</mi></mrow></msubsup><mrow is="true"><mi is="true" mathvariant="italic">yf</mi><mo stretchy="false" is="true">(</mo><mi is="true">x</mi><mo is="true">,</mo><mi is="true">y</mi><mo stretchy="false" is="true">)</mo><mi is="true">d</mi><mi is="true">y</mi></mrow></mrow><mrow is="true"><msubsup is="true"><mo is="true">∫</mo><mrow is="true"><mo is="true">-</mo><mi is="true">∞</mi></mrow><mi is="true">∞</mi></msubsup><mrow is="true"><mi is="true">f</mi><mo stretchy="false" is="true">(</mo><mi is="true">x</mi><mo is="true">,</mo><mi is="true">y</mi><mo stretchy="false" is="true">)</mo><mi is="true">d</mi><mi is="true">y</mi></mrow></mrow></mfrac></mrow></math></span></div></span>where: <em>E</em> (<em>y</em>/<em>x</em>) is the conditional mean of <em>y</em> given <em>x</em>, (<span class="math"><math><mrow is="true"><mover accent="true" is="true"><mi is="true">y</mi><mo stretchy="true" is="true">^</mo></mover><mrow is="true"><mi is="true">x</mi><mo stretchy="false" is="true">)</mo></mrow></mrow></math></span>, or regression of <em>y</em> on <em>x</em>. <span class="math"><math><mrow is="true"><mi is="true">f</mi><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi><mo is="true">,</mo><mi is="true">y</mi></mrow></mfenced></mrow></math></span> is the joint probability density function of a vector random input variable <em>x</em> (independent feature), and a scalar random output variable <em>y</em> (dependent feature). The probability density is estimated from the traning set using the Parzen’s nonparametric estimator <a name="bb0545" href="#b0545" class="workspace-trigger">[109]</a>:<span class="display"><div id="e0020" class="formula"><span class="math"><math><mrow is="true"><mi is="true">f</mi><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi><mo is="true">,</mo><mi is="true">y</mi></mrow></mfenced><mo is="true">=</mo><mfrac is="true"><mn is="true">1</mn><mrow is="true"><msup is="true"><mrow is="true"><mi is="true">n</mi><mfenced open="(" close=")" is="true"><mrow is="true"><mn is="true">2</mn><mi is="true">π</mi></mrow></mfenced></mrow><mfrac is="true"><mrow is="true"><mi is="true">p</mi><mo is="true">+</mo><mn is="true">1</mn></mrow><mn is="true">2</mn></mfrac></msup><msub is="true"><mi is="true">σ</mi><mn is="true">1</mn></msub><msub is="true"><mi is="true">σ</mi><mn is="true">2</mn></msub><msub is="true"><mrow is="true"><mrow is="true"><mo is="true">.</mo><mspace width="0.277778em" is="true"></mspace><mo is="true">.</mo><mspace width="0.277778em" is="true"></mspace><mo is="true">.</mo></mrow><mi is="true">σ</mi></mrow><mi is="true">p</mi></msub><msub is="true"><mi is="true">σ</mi><mi is="true">y</mi></msub></mrow></mfrac><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">i</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">n</mi></munderover><msup is="true"><mrow is="true"><mi is="true">e</mi></mrow><mrow is="true"><mo is="true">-</mo><mi is="true">d</mi><mfenced open="(" close=")" is="true"><mrow is="true"><msub is="true"><mi is="true">x</mi><mo is="true">,</mo></msub><msub is="true"><mi is="true">x</mi><mi is="true">i</mi></msub></mrow></mfenced></mrow></msup><msup is="true"><mrow is="true"><mi is="true">e</mi></mrow><mrow is="true"><mo is="true">-</mo><mi is="true">d</mi><mfenced open="(" close=")" is="true"><mrow is="true"><msub is="true"><mi is="true">y</mi><mo is="true">,</mo></msub><msub is="true"><mi is="true">y</mi><mi is="true">i</mi></msub></mrow></mfenced></mrow></msup></mrow></math></span></div></span>where: <span class="math"><math><mrow is="true"><mi is="true">d</mi><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">x</mi><mo is="true">,</mo><msub is="true"><mi is="true">x</mi><mi is="true">i</mi></msub></mrow></mfenced><mo is="true">=</mo><msubsup is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true" mathvariant="normal">j</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">p</mi></msubsup><msup is="true"><mrow is="true"><mo stretchy="false" is="true">[</mo><mrow is="true"><mo stretchy="false" is="true">(</mo><msub is="true"><mi is="true">x</mi><mi is="true">j</mi></msub><mo is="true">-</mo><msub is="true"><mi is="true">x</mi><mi is="true">i</mi></msub><mo stretchy="false" is="true">)</mo></mrow><mo stretchy="false" is="true">/</mo><mrow is="true"><mo stretchy="false" is="true">(</mo><msub is="true"><mi is="true">σ</mi><mi is="true">j</mi></msub><mo stretchy="false" is="true">)</mo></mrow><mo stretchy="false" is="true">]</mo></mrow><mn is="true">2</mn></msup></mrow></math></span> and <span class="math"><math><mrow is="true"><mi is="true">d</mi><mfenced open="(" close=")" is="true"><mrow is="true"><mi is="true">y</mi><mo is="true">,</mo><msub is="true"><mi is="true">y</mi><mi is="true">i</mi></msub></mrow></mfenced><mo is="true">=</mo><msup is="true"><mrow is="true"><mo stretchy="false" is="true">[</mo><mrow is="true"><mo stretchy="false" is="true">(</mo><mi is="true">y</mi><mo is="true">-</mo><msub is="true"><mi is="true">y</mi><mi is="true">i</mi></msub><mo stretchy="false" is="true">)</mo></mrow><mo stretchy="false" is="true">/</mo><mrow is="true"><mo stretchy="false" is="true">(</mo><msub is="true"><mi is="true">σ</mi><mi is="true">j</mi></msub><mo stretchy="false" is="true">)</mo></mrow><mo stretchy="false" is="true">]</mo></mrow><mn is="true" mathvariant="bold">2</mn></msup><mo is="true">,</mo></mrow></math></span> n is the number of traning patterns, <em>p</em> is the number of independent features.</p><figure class="figure" id="f0010"><span id="download-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-gr2.jpg" alt="" aria-describedby="cn0010" height="270"><ol class="links-for-figure"><li><a href="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-gr2_lrg.jpg" target="__blank">Download high-res image (163KB)</a></li><li><a href="https://ars.els-cdn.com/content/image/1-s2.0-S2214317317301774-gr2.jpg" target="__blank">Download full-size image</a></li></ol></span><div class="captions"><span id="cn0010"><p id="sp0020"><span class="label">Fig. 2</span>. A GRNN that process the time series data for disease diagnosis.</p></span></div></figure></div></section></section><section id="s0070"><h2 id="st085">5. The NN classifiers</h2><p id="p0575">Classifiers
 are basically classification learning systems. NN classifiers are 
non-parametric classifiers that classify non-parametric data. In 
particular, the classifiers make few presumptions for classification 
without any prior knowledge of the pattern of the data. It shows up in 
many different ways, some examples include Back-propagation (BP) 
classifier, Counter-propagation (CP) classifier and Multilayer 
perceptron (MLP) classifier. Wu et al. <a name="bb0550" href="#b0550" class="workspace-trigger">[110]</a>
 reported that NN classifiers are the best classifiers among all 
approaches having the fastest speed and best accuracy for classification
 work.</p><p id="p0580">Currently, BP classifiers are the more prevalent
 classification paradigm. BP classifiers yield better outcomes in terms 
of classification accuracy, simplicity, and robustness. BP classifiers 
can be used as an alternative approach to the large database with 
several advantages in speed, sensitivity and automation <a name="bb0555" href="#b0555" class="workspace-trigger">[111]</a>. Liu and Zhou <a name="bb0560" href="#b0560" class="workspace-trigger">[112]</a>
 have done a significant study on rice brown spot using artificial 
means. They showed that BP classifiers classified the healthy and 
diseased leaves of rice resulting to its ability to identify rice brown 
spots.</p><p id="p0585">CP classifiers usually extract statistical 
properties from the input data. Therefore, on the basis of statistical 
properties, samples of network training become easier and perform 
faster. CP is a supervised learning algorithm, which is closely related 
to the nearest-neighbor classifier <a name="bb0565" href="#b0565" class="workspace-trigger">[113]</a>.</p><p id="p0590">Mostly,
 in order to establish non-linear relationship, multi-layer FFNN such as
 the MLP classifiers have been used. However, the success of any 
non-linear relationship is not only subject to NN classifier, but also 
depends on the quality of the input data <a name="bb0570" href="#b0570" class="workspace-trigger">[114]</a>. Lorente et al. <a name="bb0575" href="#b0575" class="workspace-trigger">[115]</a>
 described the importance of MLP classifiers. MLP classifiers have been 
shown to be relevant to a wide range of non-linear classifiers such as 
regression trees or fuzzy classifiers. Many approaches, however, have 
addressed the importance of MLP classifiers by comparison with other 
classifiers. Liu and Wu <a name="bb0580" href="#b0580" class="workspace-trigger">[116]</a>
 reported that its superior performance compared to regression tree is 
based on four factors: accuracy, model complexity, interpolation ability
 and error distribution.</p></section><section id="s0075"><h2 id="st090">6. Early disease detection</h2><p id="p0595">Early
 detection of crop disease using non-destructive methods can minimize 
direct human intervention in plant protection. Several NN methods have 
been used for early disease detection. Learning capabilities of NNs are 
very helpful in detecting and diagnosing plant diseases. An effective 
disease diagnosis requires an accurate NN model, which is usually 
coupled with a learning function that adjusts all the weights and biases
 to the assigned layers. Rapid and accurate diagnosis of plant disease 
at an early stage is essential for effective disease control. In recent 
years, it has become possible to detect and diagnose plant disease at an
 early stage by employing hyperspectral data and NN models together. 
However, visual scouting is still an initial way of early inspection of 
disease symptoms.</p><p id="p0600">Hyperspectral sensors are promising 
tools for non-destructive disease detection and diagnosis. In order to 
attain reliable early detection and diagnosis of plant diseases, new 
approaches (i.e. imaging and non-imaging spectroscopy) must be 
introduced and incorporated into laboratory scale to compliment 
molecular, serological and microbiological techniques such as ELISA and 
RT-PCR. These techniques have been facing challenges in resource 
consumption in terms of time, cost and skilled labor. On the other hand,
 a highly controlled and contamination-free environment has to be 
maintained in a laboratory. Nonetheless, a wide gap remains between 
destructive and non-destructive diagnosis. Recent literature therefore 
suggests the application of NNs <a name="bb0585" href="#b0585" class="workspace-trigger">[117]</a> with hyperspectral data <a name="bb0185" href="#b0185" class="workspace-trigger">[37]</a>
 as a measure to cover this gap. In particular, NN-hyperspectral 
approach will improve the classification results in non-destructive 
diagnosing of plant diseases.</p><p id="p0605">The various microbial 
pathogens cause a wide range of diseases in the plants such as mottle, 
mosaic, ringspot, and systemic necrosis caused by viruses <a name="bb0590" href="#b0590" class="workspace-trigger">[118]</a>; leaf spot, blight, rot, wilt, steaming, cankers, galls, overgrowths, specks, and scabs caused by bacteria <a name="bb0595" href="#b0595" class="workspace-trigger">[119]</a> and anthracnose, rust, root rot and damping off mostly caused by fungi <a name="bb0600" href="#b0600" class="workspace-trigger">[120]</a>.
 Nevertheless, Some diseases often do not manifest symptoms but remain 
asymptomatic, for example: orange spotting disease in oil palm caused by
 viroids <a name="bb0050" href="#b0050" class="workspace-trigger">[10]</a>.</p><p id="p0610">Hyperspectral
 sensors measure reflectances from infected plants. Then reflectance 
data are used to design an NN model to produce a decision support 
system. Hyperspectral and NN-based models act significantly on early 
disease detection. The basic principle of this approach is modeling of 
crop reflectance data which are measured through hyperspectral imaging 
and/or non-imaging techniques. Then optimal wavelength features (i.e. 
spectral bands) are extracted and processed using the multivariate or NN
 techniques. VIs are developed from these spectral bands, which are very
 helpful for characterizing crop status. In the meantime, though, the NN
 can use either spectral bands or VIs for data modeling.</p><section id="s0080"><h3 id="st095">6.1. Early detection using non-imaging field spectroscopy</h3><p id="p0615">Hyperspectral
 data typically consist of a large number (&gt;100) of narrow and 
contiguous spectral bands. Pre-processing of these spectral bands is 
required for spectral data analysis and modelling. Thenkabail et al. <a name="bb0605" href="#b0605" class="workspace-trigger">[121]</a>
 have mentioned the benefits of using a generous data processing 
approach such as ANN to select the best spectral bands. NN algorithms 
have been successfully implemented in identifying outliers and spectral 
features. Additionally, NN is also a data dimensionality reduction 
method. Using the NN technique, hyperspectral data can be processed much
 faster than other techniques. The NNs transform hyperspectral data into
 a very reasonable data form <a name="bb0610" href="#b0610" class="workspace-trigger">[122]</a>.
 Hyperspectral data offer high diagnostic capability for early disease 
detection. The spectral bands with high absorption are more sensitive to
 several leaf pigments including chlorophyll <em>a</em>, chlorophyll <em>b</em>, violaxanthin, β-carotene, neoxanthin, and carotenoids. Pathogenesis in plants directly affects biochemical concentrations.</p><p id="p0620">Traditionally,
 a wet chemistry method involves leaf extraction with organic solvents 
to estimate chlorophyll content using High Performance Liquid 
Chromatography (HPLC). These days, chlorophyll estimation is carried out
 non-destructively using the non-imaging spectroradiometer and portable 
Soil and Plant Analysis Development (SPAD) meter. Non-destructive 
techniques measure chlorophyll content in real time and render 
worthwhile savings in cost, labor and time. However, further efforts are
 required to estimate other plant pigments using a non-imaging 
spectroradiometer.</p><p id="p0625">During pathogenesis, 
pathogen-specific toxins or enzymes induce plant tissues and influence 
the optical properties of plants. Changes in reflectance pattern due to 
plant-pathogen interaction can be altered by impairments in the leaf 
structure and chemical composition <a name="bb0615" href="#b0615" class="workspace-trigger">[123]</a>. Hyperspectral data can be evaluated with a trained and representative NN <a name="bb0620" href="#b0620" class="workspace-trigger">[124]</a>. VIs can also be classified using NN classifiers. Wu et al. <a name="bb0625" href="#b0625" class="workspace-trigger">[125]</a> detected <em>Botrytis cinerea</em>
 on eggplant leaves using NN-hyperspectral approach. They applied NN 
classifiers and PCA to hyperspectral signatures and accurately 
identified small symptoms of gray mold on eggplants. In another study, 
le Maire et al. <a name="bb0630" href="#b0630" class="workspace-trigger">[126]</a> studied VIs derived from red-edge using NNs.</p><p id="p0630">Recent
 researches have demonstrated great value of using VNIR spectroscopy for
 early disease detection in a wide range of applications. Pydipati et 
al. <a name="bb0635" href="#b0635" class="workspace-trigger">[127]</a> 
found that a multilayer BPNN has the highest correction and 
discriminating capabilities of reflectance wavelength between 460 nm and
 1130 nm, at 10 nm increments. Similarly, Miller et al. <a name="bb0640" href="#b0640" class="workspace-trigger">[128]</a> used multilayer BPNN with a pattern recognition algorithm to classify surface blemishes of various apple varieties.</p><p id="p0635">Hyperspectral
 non-imaging data are most interesting and challenging. Real-time 
spectral measurement using field spectroradiometer produces large amount
 of spectral data which require spectral pre-processing. In spectral 
pre-processing, many spectral bands are reduced, therefore selection of 
optimal wavebands is very important <a name="bb0645" href="#b0645" class="workspace-trigger">[129]</a>.
 It is noted that spectral processing with NN algorithm has increased 
the accessibility of non-imaging data in disease detection. For 
selection of optimal spectral bands, Kohonen’s SOM model can be applied,
 that will be a better option to random selection of wavebands. 
Application of BPNN <a name="bb0635" href="#b0635" class="workspace-trigger">[127]</a>, <a name="bb0640" href="#b0640" class="workspace-trigger">[128]</a>
 for differentiating between healthy and diseased plant spectra has 
become one of the most efficient and fast-developing networks in 
precision plant protection. We recommend other types of NNs (such as 
FFNN, GRNN) for spectral segregation, so that would simplify the disease
 detection process.</p></section><section id="s0085"><h3 id="st100">6.2. Early detection using imaging spectroscopy</h3><p id="p0640">Several
 studies on hyperspectral image processing have been conducted in recent
 years since remote sensing imageries became easier to archive. Highly 
flexible NN techniques have been developed to investigate spectral 
characteristics of crop. Nevertheless, the use of innovative 
hyperspectral imaging systems for early disease detection and disease 
severity assessment are still at the research stage <a name="bb0650" href="#b0650" class="workspace-trigger">[130]</a>, <a name="bb0655" href="#b0655" class="workspace-trigger">[131]</a>.</p><p id="p0645">To
 our knowledge, purely non-parametric NN classifiers have not so far 
been evaluated for early disease detection using hyperspectral 
imageries. Space-born imaging hyperspectral spectroradiometers such as 
Airborne Imaging Spectrometer for Applications (AISA) Eagle system, 
AVIRIS, Hyperion, the Reflective Optics System Imaging Spectrometer 
(ROSIS) and Hyperspectral Mapping Imaging Spectrometer (HyMap) have been
 deployed to detect disease without NN applications.</p><p id="p0650">NNs
 are suitable for classification of hyperspectral imageries. NNs 
generate classifier using training inputs that are employed for 
classification purposes. The NNs are basically used to extract image 
features as their training inputs. NN classifiers enhance the accuracy 
of classification and reduce the overall effects of noise from the 
images.</p><p id="p0655">NNs offer a dynamic range of algorithms for 
hyperspectral image analysis. Mostly, a two-dimensional algorithm is 
used for detecting diseases from hyperspectral image features. The basic
 algorithms are for data reduction, feature extraction, segmentation, 
object recognition and image optimization. The advanced algorithms are 
for abstraction at pixel, feature, structure, object-set levels and 
scene characterization <a name="bb0490" href="#b0490" class="workspace-trigger">[98]</a>, <a name="bb0660" href="#b0660" class="workspace-trigger">[132]</a>, <a name="bb0665" href="#b0665" class="workspace-trigger">[133]</a>.</p><p id="p0660">NNs
 overcome the limitations of hyperspectral data analysis significantly. 
Hyperspectral images contain high-dimensional information in 
multidimensional data cubes. CNN is a new concept for hyperspectral data
 analysis, which has proven to be very effective for classification of 
high-dimensional hyperspectral images <a name="bb0455" href="#b0455" class="workspace-trigger">[91]</a>, <a name="bb0460" href="#b0460" class="workspace-trigger">[92]</a>. CNN is composed by a set of blocks that can be applied both across space and across time <a name="bb0460" href="#b0460" class="workspace-trigger">[92]</a>. Paoletti et al. <a name="bb0460" href="#b0460" class="workspace-trigger">[92]</a>
 developed a new deep 3-D CNN architecture for spatial-spectral 
classification of hyperspectral images. For better classification 
results, a joint consideration of spectral information together with 
spatial information is required in this architecture.</p><div><p id="p0665">Mutanga and Skidmore <a name="bb0670" href="#b0670" class="workspace-trigger">[134]</a>
 integrated spectral features over the full spectral range (400–2500 nm)
 of HyMap data with NNs. It is worth mentioning that AVIRIS 
hyperspectral images are useful in characterizing and estimating various
 fungal and bacterial diseases <a name="bb0675" href="#b0675" class="workspace-trigger">[135]</a>, <a name="bb0680" href="#b0680" class="workspace-trigger">[136]</a>. Thus, NNs are highly recommended for AVIRIS data analysis especially for vegetation disease. <a name="bt0010" href="#t0010" class="workspace-trigger">Table 2</a> summarizes some important studies on early disease detection using hyperspectral data.</p><div class="tables frame-topbot rowsep-0 colsep-0" id="t0010"><div class="captions"><span id="cn0020"><p id="sp0030"><span class="label">Table 2</span>. Use of hyperspectral sensor in detecting and diagnosing crop disease at an early stage.</p></span></div><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">Sensor</th><th scope="col" class="align-left">Crop</th><th scope="col" class="align-left">Disease</th><th scope="col" class="align-left">Reference</th></tr></thead><tbody><tr class="valign-top"><td class="align-left" rowspan="3">ASD field spectroradiometer<br>(350–2500 nm)</td><td class="align-left">Rice</td><td class="align-left">Fungal infections</td><td class="align-left">Liu et al. <a name="bb0685" href="#b0685" class="workspace-trigger">[137]</a></td></tr><tr class="valign-top"><td class="align-left">Rice</td><td class="align-left">Rice brown spot</td><td class="align-left">Liu et al. <a name="bb0690" href="#b0690" class="workspace-trigger">[138]</a></td></tr><tr class="valign-top"><td class="align-left">Eggplant</td><td class="align-left">Gray mould</td><td class="align-left">Wu et al. <a name="bb0625" href="#b0625" class="workspace-trigger">[125]</a></td></tr><tr class="valign-top"><td class="align-left">GER-2600<br>(400–2500 nm)</td><td class="align-left">Tomato</td><td class="align-left">Late blight</td><td class="align-left">Wang et al. <a name="bb0695" href="#b0695" class="workspace-trigger">[139]</a></td></tr><tr class="valign-top"><td class="align-left" rowspan="2">ImSpector V10E<br>(400–1000 nm)</td><td class="align-left">Wheat</td><td class="align-left">Yellow rust</td><td class="align-left">Moshou et al. <a name="bb0365" href="#b0365" class="workspace-trigger">[73]</a></td></tr><tr class="valign-top"><td class="align-left">Oil seed</td><td class="align-left">Fungal infections</td><td class="align-left">Baranowski et al. <a name="bb0700" href="#b0700" class="workspace-trigger">[140]</a></td></tr><tr class="valign-top"><td class="align-left" rowspan="2">AISA</td><td class="align-left">Citrus</td><td class="align-left">Citrus greening</td><td class="align-left">Lee and Ehsani <a name="bb0705" href="#b0705" class="workspace-trigger">[141]</a></td></tr><tr class="valign-top"><td class="align-left">Oil Palm</td><td class="align-left">Ganoderma basal stem rot</td><td class="align-left">Shafri and Hamdan <a name="bb0710" href="#b0710" class="workspace-trigger">[142]</a></td></tr><tr class="valign-top"><td class="align-left">Hyperspectral imaging (HIS)</td><td class="align-left">Sugar beet</td><td class="align-left">Leaf spot, Powdery mildew and leaf rust</td><td class="align-left">Mahlein et al. <a name="bb0715" href="#b0715" class="workspace-trigger">[143]</a></td></tr><tr class="valign-top"><td class="align-left">Hyperion</td><td class="align-left">Sugar beet</td><td class="align-left">Orange rust</td><td class="align-left">Apan et al. <a name="bb0720" href="#b0720" class="workspace-trigger">[144]</a></td></tr><tr class="valign-top"><td class="align-left">Hyperspectral image scanner</td><td class="align-left">Wheat</td><td class="align-left"><em>Fusarium</em> head blight</td><td class="align-left">Bauriegel and Herppich <a name="bb0725" href="#b0725" class="workspace-trigger">[145]</a></td></tr><tr class="valign-top"><td class="align-left">Portable hyperspectral imaging system</td><td class="align-left">Citrus</td><td class="align-left">Citrus canker</td><td class="align-left">Qin et al. <a name="bb0730" href="#b0730" class="workspace-trigger">[146]</a></td></tr><tr class="valign-top"><td class="align-left"></td><td class="align-left">Maize</td><td class="align-left">Fungal infections</td><td class="align-left">Del Fiore et al. <a name="bb0735" href="#b0735" class="workspace-trigger">[147]</a></td></tr><tr class="valign-top"><td class="align-left">Hyper spectrometer<br>(350–1050 nm)</td><td class="align-left">Wheat</td><td class="align-left">Powdery mildew</td><td class="align-left">Shen et al. <a name="bb0740" href="#b0740" class="workspace-trigger">[148]</a></td></tr></tbody></table></div></div></div></section></section><section id="s0090"><h2 id="st105">7. An overview of two studies on rice (<em>Oryza sativa</em> L.) disease detection using NN-hyperspectral approach</h2><p id="p0670">For
 crop disease detection, the spectral data acquired from a non-imaging 
spectroradiometer have been analyzed using PCA for a long time. Almost 
all the NNs have been evaluated using Principal Component Spectra (PCS).
 PCS are achieved after reducing and/or compacting the spectral 
dimension of data into small and finite components called Principle 
Components (PCs) having equal dimensions. In this overview, two case 
studies are thoroughly reviewed in the context of non-destructive 
bacterial and fungal disease detection in rice (<em>Oryza sativa</em> L.) using a full range spectroradiometer. These case studies deliberately and iteratively applied PCS onto the NN framework.</p><section id="s0095"><h3 id="st110">7.1. RBF network with PCA</h3><p id="p0675">The first study on brown spot disease of rice <a name="bb0690" href="#b0690" class="workspace-trigger">[138]</a>
 examined the capability of RBF network and PCA for determining the 
disease severity. The disease severity of brown spot was determined in 
terms of percentage of the infected surface area. Three methods, namely,
 spectral transformation, PCA, and RBF network were employed to gain a 
preliminary understanding of the severity of brown spot disease. The 
spectroradiometer was deployed over healthy and diseased rice leaves 
separated from the rice plant in order to obtain leaf spectra. These 
spectra of rice leaves were transformed through three different 
preprocessing techniques – spectral resampling at an interval of 10 nm, 
first-order derivatives, and second-order derivatives.</p><p id="p0680">Liu et al. <a name="bb0690" href="#b0690" class="workspace-trigger">[138]</a>
 further processed the transformed spectra to attain PCS using PCA. 
Then, preprocessed spectra and PCS were trained as the input vectors in 
an RBF network. The efficient extrapolation capability of RBF has been 
mostly deployed for classifying the data with high operation rate. The 
most surprising aspect of this study was first-order derivative spectra 
yielded the best prediction result using RBF network. Additionally, good
 prediction was recorded by resampling the spectra. They concluded that 
PCA-RBF network was an accurate predictor and superior model for 
estimating disease severity of rice brown spot.</p></section><section id="s0100"><h3 id="st115">7.2. Learning Vector Quantization (LVQ) NN with PCA</h3><p id="p0685">In the second study, glume blight disease of rice panicles was detected using PCA and LVQ NN classifiers by Liu et al.<a name="bb0685" href="#b0685" class="workspace-trigger">[137]</a>.
 PCA is a powerful statistical tool used to analyze the spectra of glume
 blight disease infected panicles while the LVQ NN classifier classified
 these spectra into four infection levels: healthy, light, moderate and 
serious infection levels. The spectral processing methods – raw, inverse
 logarithmic, first and second derivative were chosen to process the 
original spectra to obtain in-depth band information. Then, PCs were 
derived from the different spectral data set of different spectral 
processing methods.</p><p id="p0690">In LVQ network, finding a 
relationship among the PCs of different spectral processing methods was 
the main object of the learning process. For assigning the nodes in the 
layers, those PCs that responded to about 95% proportion of variance at 
each spectral data set were selected to determine the number of nodes in
 the input layer. While the nodes for output layer assigned from the 
classified infection levels. Kappa coefficient was used to evaluate of 
classification accuracy in this study.</p><p id="p0695">Liu et al. <a name="bb0685" href="#b0685" class="workspace-trigger">[137]</a>
 investigated the changes in the spectral behavior of spectrum, 
specifically in the visible and NIR regions. These spectral changes 
occurred due to fungal infection in the panicles of rice. A common 
observation within the spectrum was the visible region received a higher
 reflectance and NIR received a lower reflection in diseased panicle as 
compared to healthy panicle. In SWIR region, healthy rice panicles 
observed a dramatic lower reflectance than the moderately and seriously 
infected panicles. Liu et al. <a name="bb0685" href="#b0685" class="workspace-trigger">[137]</a>
 cautioned that the spectral behavior of rice under fungal infection 
could be different at different atmospheric and edaphic field 
conditions.</p></section></section><section id="s0105"><h2 id="st120">8. Challenges of NN</h2><p id="p0700">The
 main challenge of ANN in hyperspectral data processing is the training 
of large quantity of spectral inputs and defining their targets. This is
 made even more challenging with application of NN classifiers for 
classification of VIs and SDIs. Over all, the Hughes phenomenon or “the 
curse of dimensionality” is the most complex problem for hyperspectral 
data which deals with diversity and distortions in spectral bands. The 
Hughes phenomenon may affect the NN modeling. Generally, it happens 
where the ratio of number of training pixels or the number of spectral 
bands are above the minimum value to achieve statistical fit <a name="bb0745" href="#b0745" class="workspace-trigger">[149]</a>.
 In particular, one of most challenging aspect is the use of NN 
classifiers for analyzing the spectral mixtures. Spectral Mixture 
Analysis (SMA) is good linear model, non-linear NNs are required for 
training a large dataset of plant disease spectra. In addition, ANN is 
often regarded as a black box since it does not contain priori 
information, which itself is complex.</p><p id="p0705">Generally, NN 
classifiers classify different plant diseases on the basis of 
combination of optimal parameters such as texture, colour, and shape in a
 normal camera image <a name="bb0370" href="#b0370" class="workspace-trigger">[74]</a>.
 The optimal parameters could be trained easily as the normal images are
 linearly separable. On the other hand, the hyperspectral image is 
different from a normal camera image. Hyperspectral data cannot be 
trained linearly as long as it contains more than hundred contiguous 
spectral bands. The MLP architectures typically deal with such 
non-linear features. In addition, adjacent spectral bands in different 
spectral regions (such as, visible, NIR, SWIR) are highly redundant in 
extracting information for an ANN. The spectral bands are found to be 
highly interconnected to each other.</p></section><section id="s0110"><h2 id="st125">9. SDi</h2><p id="p0710">The most of common VIs have been computed from red and NIR wavelengths. Normalized Difference Vegetation Index (NDVI) <a name="bb0750" href="#b0750" class="workspace-trigger">[150]</a> is one of the most popular and widely used VIs for monitoring crop health. Balasundram et al. <a name="bb0755" href="#b0755" class="workspace-trigger">[151]</a> used NDVI for preliminary screening of red tip disease in pineapple (<em>Ananas comosus</em>).
 They demonstrated and inferred NDVI as a reliable disease predictor for
 predicting disease severity. Nevertheless, NDVI has not been shown to 
be suitable for identifying the causal agent of crop disease. Peñuelas 
et al. <a name="bb0760" href="#b0760" class="workspace-trigger">[152]</a>
 found that NDVI does not follow specific wavebands that represent 
physiological changes caused by pathogens. Therefore, disease sensitive 
spectral features must be extracted to develop an SDI. Generally, SDI is
 a ratio of the different disease sensitive spectral bands which are 
extracted on the basis of spectral responses from diseased vegetation.</p><p id="p0715">Early
 detection of disease based on hyperspectral remote sensing is more 
precise and significant. Therefore, new SDIs are being developed based 
on general interest for detecting disease in an early stage using 
hyperspectral data. Different SDI values represent specificity, 
sensitivity and severity of the vegetation at different stages of 
infection. SDIs have been used to provide a unique, scientific and 
detailed understanding of pathogenesis. In contrast to common VIs, SDIs 
have the potential to discriminate and differentiate one plant disease 
from another. However, each disease may affect the leaf reflectance 
spectrum in a specific way <a name="bb0765" href="#b0765" class="workspace-trigger">[153]</a>.</p><div><p id="p0720">It is important to develop disease-specific indices based on the progression of disease symptoms. Ashourloo et al. <a name="bb0770" href="#b0770" class="workspace-trigger">[154]</a> have developed two SDIs on the basis of disease progression for detection of wheat leaf rust using hyperspectral data. Rumpf <a name="bb0775" href="#b0775" class="workspace-trigger">[155]</a>
 showed via comparative studies that SDIs are superior to common VIs for
 early disease detection. SDIs developed from imaging spectroradiometer 
can be correlated to SDIs developed from non-imaging field 
spectroradiometers. The generalization ability of the developed SDIs 
could be improved by correlation and cross-validation. Generally, 
non-imaging field spectroradiometers calculate SDIs within a very short 
period. Whereas imaging spectroradiometers can take comparatively longer
 time in selecting sensitive end members (pixels) from hyperspectral 
imageries. Hyperspectral data can detect diseases at various scales, 
ranging from an individual plant to fields. <a name="bt0015" href="#t0015" class="workspace-trigger">Table 3</a> summarizes different SDIs applied for early disease detection using hyperspectral data.</p><div class="tables frame-topbot rowsep-0 colsep-0" id="t0015"><div class="captions"><span id="cn0025"><p id="sp0035"><span class="label">Table 3</span>. Well-established SDIs for early disease detection using hyperspectral data.</p></span></div><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">Device</th><th scope="col" class="align-left">SDI</th><th scope="col" class="align-left">Formula</th><th scope="col" class="align-left">References</th></tr></thead><tbody><tr class="valign-top"><td class="align-left" rowspan="5">Hyperion</td><td class="align-left">Disease-Water stress Index 1(DSWI-1)</td><td class="align-left">R800/R1660</td><td class="align-left" rowspan="5">Apan et al. <a name="bb0720" href="#b0720" class="workspace-trigger">[144]</a></td></tr><tr class="valign-top"><td class="align-left">DSWI-2</td><td class="align-left">R1660/ R550</td></tr><tr class="valign-top"><td class="align-left">DSWI-3</td><td class="align-left">R1660/R 680</td></tr><tr class="valign-top"><td class="align-left">DSWI-4</td><td class="align-left">R550/R 680</td></tr><tr class="valign-top"><td class="align-left">DSWI-5</td><td class="align-left">(R800 + R550)/(R1660 + R680)</td></tr><tr class="valign-top"><td class="align-left" rowspan="4">ASD field spec<br>Spectroradiometer</td><td class="align-left">Healthy- Index (HI)</td><td class="align-left"><span class="math"><math><mrow is="true"><mfrac is="true"><mrow is="true"><mi is="true" mathvariant="normal">R</mi><mn is="true">534</mn><mo is="true">-</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">698</mn></mrow><mrow is="true"><mi is="true" mathvariant="normal">R</mi><mn is="true">534</mn><mo is="true">+</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">698</mn></mrow></mfrac><mo is="true">-</mo><mfrac is="true"><mn is="true">1</mn><mrow is="true"><mn is="true">2</mn></mrow></mfrac><mo is="true">∙</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">704</mn></mrow></math></span></td><td class="align-left" rowspan="4">Mahlein et al. <a name="bb0765" href="#b0765" class="workspace-trigger">[153]</a></td></tr><tr class="valign-top"><td class="align-left">Cersopora Leaf Spot- Index (CLSI)</td><td class="align-left"><span class="math"><math><mrow is="true"><mfrac is="true"><mrow is="true"><mi is="true" mathvariant="normal">R</mi><mn is="true">698</mn><mo is="true">-</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">570</mn></mrow><mrow is="true"><mi is="true" mathvariant="normal">R</mi><mn is="true">698</mn><mo is="true">+</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">570</mn></mrow></mfrac><mo is="true">-</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">734</mn></mrow></math></span></td></tr><tr class="valign-top"><td class="align-left">Sugar Beet Rust-Index (SBRI)</td><td class="align-left"><span class="math"><math><mrow is="true"><mfrac is="true"><mrow is="true"><mi is="true" mathvariant="normal">R</mi><mn is="true">520</mn><mo is="true">-</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">513</mn></mrow><mrow is="true"><mi is="true" mathvariant="normal">R</mi><mn is="true">570</mn><mo is="true">+</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">513</mn></mrow></mfrac><mo is="true">-</mo><mfrac is="true"><mn is="true">1</mn><mrow is="true"><mn is="true">2</mn></mrow></mfrac><mo is="true">∙</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">704</mn></mrow></math></span></td></tr><tr class="valign-top"><td class="align-left">Powdery Mildew –Index (PMI)</td><td class="align-left"><span class="math"><math><mrow is="true"><mfrac is="true"><mrow is="true"><mi is="true" mathvariant="normal">R</mi><mn is="true">520</mn><mo is="true">-</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">584</mn></mrow><mrow is="true"><mi is="true" mathvariant="normal">R</mi><mn is="true">520</mn><mo is="true">+</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">584</mn></mrow></mfrac><mo is="true">-</mo><mi is="true" mathvariant="normal">R</mi><mn is="true">724</mn></mrow></math></span></td></tr><tr class="valign-top"><td class="align-left" rowspan="2">ASD field spec<br>Spectroradiometer</td><td class="align-left">Leaf Rust Disease Severity Index 1 (LRDSI_1)</td><td class="align-left"><span class="math"><math><mrow is="true"><mn is="true">6.9</mn><mfrac is="true"><mrow is="true"><mi is="true">ρ</mi><mn is="true">605</mn></mrow><mrow is="true"><mi is="true">ρ</mi><mn is="true">455</mn></mrow></mfrac><mo is="true">-</mo><mn is="true">1.2</mn></mrow></math></span></td><td class="align-left" rowspan="2">Ashourloo et al. <a name="bb0770" href="#b0770" class="workspace-trigger">[154]</a></td></tr><tr class="valign-top"><td class="align-left">Leaf Rust Disease Severity Index 2 (LRDSI_2)</td><td class="align-left"><span class="math"><math><mrow is="true"><mn is="true">4.2</mn><mfrac is="true"><mrow is="true"><mi is="true">ρ</mi><mn is="true">695</mn></mrow><mrow is="true"><mi is="true">ρ</mi><mn is="true">455</mn></mrow></mfrac><mo is="true">-</mo><mn is="true">0.38</mn></mrow></math></span></td></tr><tr class="valign-top"><td class="align-left">ASD field spec<br>Spectroradiometer</td><td class="align-left">Normalized Leaf Rust Healthy Index (NLRHI)</td><td class="align-left"><span class="math"><math><mfrac is="true"><mrow is="true"><mi is="true" mathvariant="normal">DS</mi><mo is="true">-</mo><mfenced open="(" close=")" is="true"><mrow is="true"><mfrac is="true"><mrow is="true"><mi is="true">ρ</mi><mn is="true">675</mn></mrow><mrow is="true"><mi is="true">ρ</mi><mn is="true">775</mn></mrow></mfrac></mrow></mfenced></mrow><mrow is="true"><mi is="true" mathvariant="normal">DS</mi><mo is="true">+</mo><mfenced open="(" close=")" is="true"><mrow is="true"><mfrac is="true"><mrow is="true"><mi is="true">ρ</mi><mn is="true">675</mn></mrow><mrow is="true"><mi is="true">ρ</mi><mn is="true">775</mn></mrow></mfrac></mrow></mfenced></mrow></mfrac></math></span></td><td class="align-left">Ashourloo et al. <a name="bb0275" href="#b0275" class="workspace-trigger">[55]</a></td></tr></tbody></table></div></div></div></section><section id="s0115"><h2 id="st130">10. Future trends: deep learning of hyperspectral data</h2><p id="p0725">Deep
 learning is an advance technique for big data analysis. A deep learning
 model contains many layers (typically deeper than three layer model). 
Neurons of its each layer intensely are connected with features of the 
data, thereby more complex information can be obtained. Deep learning 
models learn features of input data through a hierarchically organized 
network of neurons <a name="bb0440" href="#b0440" class="workspace-trigger">[88]</a>. Recent literature <a name="bb0450" href="#b0450" class="workspace-trigger">[90]</a>, <a name="bb0780" href="#b0780" class="workspace-trigger">[156]</a>, <a name="bb0785" href="#b0785" class="workspace-trigger">[157]</a>
 is available on evaluation of deep learning models with digital 
photography, image analysis and hyperspectral imaging for plant disease 
detection.</p><p id="p0730">It is believed that deep learning is a 
future of hyperspectral remote sensing. CNN is a most popular deep model
 that works on an image domain. CNN can utilize for hyperspectral image 
in order to detect and classify plant disease at an early onset. 
Currently, multimedia <a name="bb0780" href="#b0780" class="workspace-trigger">[156]</a> and computer vision and natural language processing <a name="bb0100" href="#b0100" class="workspace-trigger">[20]</a> are most promising areas of deep learning application <a name="bb0450" href="#b0450" class="workspace-trigger">[90]</a>.</p><p id="p0735">Cloud computing architecture that have been identified in the recent literature <a name="bb0790" href="#b0790" class="workspace-trigger">[158]</a>, <a name="bb0795" href="#b0795" class="workspace-trigger">[159]</a>, were reviewed, along with future scope for NN-hyperspectral approach. Haut et al. <a name="bb0790" href="#b0790" class="workspace-trigger">[158]</a>
 explored for the first time the possibility of using a distributed 
framework for clustering of huge volume of hyperspectral images based on
 cloud computing architecture. Quirita et al. <a name="bb0795" href="#b0795" class="workspace-trigger">[159]</a>
 proposed an architecture, called InterCloud Data Mining Architecture, 
for cloud computing environments. InterCloud will allow users to 
allocate processing power and storage space in order to manage very 
large datasets, such as hyperspectral imagery.</p></section><section id="s0120"><h2 id="st135">11. Conclusion</h2><p id="p0740">Previously,
 NNs have been used for data mining purposes only but its various 
applications with hyperspectral data are now showing significant promise
 for disease detection. More often than not, like many other 
technologies, researchers have been confronted with emerging challenges 
in NN applications. For example, detection of three different categories
 of diseases manifestation viz. pre-symptomatic, symptomatic and 
asymptomatic diseases from a single plant requires best trainer sets for
 accurate classification. NNs have shown incredible capabilities in 
adapting new challenges of disease detection using hyperspectral data. 
NNs have been used for a variety of purposes, such as reduction of data 
dimensionality, training of image pixels or spectra as the input sets, 
generalization of the input sets and classification of wavebands or 
SDIs.</p><p id="p0745">This paper has extensively reviewed the available
 literature on SDIs. To the best of our knowledge, there is no report on
 the application of NNs to analyze SDIs. In the near future, SDIs will 
be processed with NNs to achieve more reliable results. Since NNs have 
not been evaluated for SDIs elsewhere, there is a possibility to 
exemplify some directions for possible development in the future, such 
as data pre-processing, reduction of data dimensionality, and efficient 
data analysis. These processes can be carried out using NNs before the 
development of an SDI. After the development of an SDI, NNs can also 
play a major role to accelerate the performance of SDIs in order to 
obtain pertinent information for disease diagnosis. As long as SDIs are 
gaining high traction in precision plant protection, they should be 
tested on various hyperspectral sensors at the canopy and leaf scale.</p></section></div><section id="s0125"><h2 id="st140">Acknowledgement</h2><p id="p0750">We thank the research group on interdisciplinary study of precision plant protection at <span id="gp005">Universiti Putra Malaysia, Serdang, Selangor, Malaysia</span>. We acknowledge the valuable comments and suggestions given by the reviewers of this paper.</p></section><section id="s0130"><h2 id="st145">Conflict of interest</h2><p id="p0755">All authors contributed to the writing of the paper. None of the authors had a conflict of interest.</p></section></div><div class="related-content-links u-hide-from-md"><button class="button button-anchor" type="button"><span class="button-text">Recommended articles</span></button><button class="button button-anchor" disabled="disabled" type="button"><span class="button-text">Citing articles (<!-- -->0<!-- -->)</span></button></div><div class="Tail"></div><section class="bibliography" id="bi005"><h2 class="section-title">References</h2><section class="bibliography-sec" id="bs005"><dl class="references"><dt class="label"><a href="#bb0005" id="ref-id-b0005">[1]</a></dt><dd class="reference" id="h0005"><div class="contribution">R.N. Strange, P.R. Scott<strong class="title">Plant disease: a threat to global food security</strong></div><div class="host">Annu Rev Phytopathol, 43 (1) (2005), pp. 83-116</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0010" id="ref-id-b0010">[2]</a></dt><dd class="reference" id="h0010"><span>Society for General Microbiology. Combating plant diseases is key for sustainable crops. Link: &lt;<a href="http://www.sciencedaily.com/releases/2011/04/110411194819.htm" target="_blank">http://www.sciencedaily.com/releases/2011/04/110411194819.htm</a>&gt;; 2013.</span></dd><dt class="label"><a href="#bb0015" id="ref-id-b0015">[3]</a></dt><dd class="reference" id="h0015"><div class="contribution">Food and Agriculture Organization (FAO)<strong class="title">Declaration of the World Summit on Food Security</strong></div><div class="host">Food and Agriculture Organization, Rome (2009)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0020" id="ref-id-b0020">[4]</a></dt><dd class="reference" id="h0020"><div class="contribution">P. Sharma, S. Sharma<strong class="title">Paradigm shift in plant disease diagnostics: a journey from conventional diagnostics to nano-diagnostics</strong></div><div class="host">P. Kumar, K.V. Gupta, K.A. Tiwari, M. Kamle (Eds.), Current trends in plant disease diagnostics and management practices, Springer International Publishing AG, Switzerland (2016), pp. 237-264</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0025" id="ref-id-b0025">[5]</a></dt><dd class="reference" id="h0025"><div class="contribution">M. Desai, A.K. Jain, N.K. Jain, K. Jethwa<strong class="title">Detection and classification of fruit disease: a review</strong></div><div class="host">Int Res J Eng Technol, 3 (3) (2016), pp. 727-729</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0030" id="ref-id-b0030">[6]</a></dt><dd class="reference" id="h0030"><div class="contribution">D. Hanold, J.W. Randles<strong class="title">Coconut cadang-cadang disease and its viroid agent</strong></div><div class="host">Plant Dis, 75 (4) (1991), pp. 330-335</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0035" id="ref-id-b0035">[7]</a></dt><dd class="reference" id="h0035"><div class="contribution">H.K. Lichtenthaler<strong class="title">Vegetation stress: an introduction to the stress concept in plants</strong></div><div class="host">J Plant Physiol, 148 (1–2) (1996), pp. 4-14</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0040" id="ref-id-b0040">[8]</a></dt><dd class="reference" id="h0040"><span>Michigan State Univ Ext. Signs and symptoms of plant disease: Is it fungal, viral or bacterial. Link: &lt;<a href="http://msue.anr.msu.edu/news/signs_and_symptoms_of_plant_disease_is_it_fungal_viral_or_bacterial" target="_blank">http://msue.anr.msu.edu/news/signs_and_symptoms_of_plant_disease_is_it_fungal_viral_or_bacterial</a>&gt;; 2012.</span></dd><dt class="label"><a href="#bb0045" id="ref-id-b0045">[9]</a></dt><dd class="reference" id="h0045"><div class="contribution">Y.H. Wu, L.C. Cheong, S. Meon, W.H. Lau, L.L. Kong, H. Joseph, <em> et al.</em><strong class="title">Characterization of Coconut cadang-cadang viroid variants from oil palm affected by orange spotting disease in Malaysia</strong></div><div class="host">Arch Virol, 158 (6) (2013), pp. 1407-1410</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0050" id="ref-id-b0050">[10]</a></dt><dd class="reference" id="h0050"><div class="contribution">G. Vadamalai, D. Hanold, M.A. Rezaian, J.W. Randles<strong class="title">Variants of Coconut cadang-cadang viroid isolated from an African oil palm (<em>Elaies guineensis</em> Jacq.) in Malaysia</strong></div><div class="host">Arch Virol, 151 (7) (2006), pp. 1447-1456</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0055" id="ref-id-b0055">[11]</a></dt><dd class="reference" id="h0055"><div class="contribution">G. Vadamalai, A. Perera, D. Hanold, M.A. Rezaian, J.W. Randles<strong class="title">Detection of Coconut cadang-cadang viroid sequences in oil and coconut palm by ribonuclease protection assay</strong></div><div class="host">Ann Appl Biol, 154 (10) (2009), pp. 117-125</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0060" id="ref-id-b0060">[12]</a></dt><dd class="reference" id="h0060"><div class="contribution">S.S. Thanarajoo, L.L. Kong, J. Kadir, W.H. Lau, G. Vadamalai<strong class="title">Detection
 of Coconut cadang-cadang viroid (CCCVd) in oil palm by reverse 
transcription loop-mediated isothermal amplification (RT-LAMP)</strong></div><div class="host">J Virol Methods, 202 (2014), pp. 19-23</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0065" id="ref-id-b0065">[13]</a></dt><dd class="reference" id="h0065"><div class="contribution">S.S. Thanarajoo<strong class="title">Rapid detection, accumulation and translocation of Coconut cadang-cadang viroid variants in oil palm</strong></div><div class="comment">[Doctor thesis]</div><div class="host">Universiti Putra Malaysia, Serdang, Malaysia (2014)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0070" id="ref-id-b0070">[14]</a></dt><dd class="reference" id="h0070"><div class="contribution">A. Sakudo, Y. Suganuma, T. Kobayashi, T. Onodera, K. Ikuta<strong class="title">Near-infrared spectroscopy: promising diagnostic tool for viral infections</strong></div><div class="host">Biochem Biophys Res Commun, 341 (2) (2006), pp. 279-284</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0075" id="ref-id-b0075">[15]</a></dt><dd class="reference" id="h0075"><div class="contribution">S. Cui, P. Ling, H. Zhu, H. Keener<strong class="title">Plant pest detection using an artificial nose system: a review</strong></div><div class="host">Sensors, 18 (2) (2018), p. 378</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0080" id="ref-id-b0080">[16]</a></dt><dd class="reference" id="h0080"><div class="contribution">A.J.C. Eun, L. Huang, F.T. Chew, S. Fong-Yau Li, S.M. Wong<strong class="title">Detection of two orchid viruses using quartz crystal microbalance-based DNA biosensors</strong></div><div class="host">Phytopathology, 92 (6) (2002), pp. 654-658</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0085" id="ref-id-b0085">[17]</a></dt><dd class="reference" id="h0085"><div class="contribution">A.J.C. Eun, L. Huang, F.T. Chew, S.F.Y. Li, S.M. Wong<strong class="title">Detection of two orchid viruses using quartz crystal microbalance (QCM) immunosensors</strong></div><div class="host">J Virol Methods, 99 (1–2) (2002), pp. 71-79</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0090" id="ref-id-b0090">[18]</a></dt><dd class="reference" id="h0090"><div class="contribution">R.M.M. Perera, P.J. Marriott, I.E. Galbally<strong class="title">Headspace
 solid-phase microextraction-comprehensive two-dimensional gas 
chromatography of wound induced plant volatile organic compound 
emissions</strong></div><div class="host">Analyst, 127 (12) (2002), pp. 1601-1607</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0095" id="ref-id-b0095">[19]</a></dt><dd class="reference" id="h0095"><div class="contribution">S. Sankaran, A. Mishra, R. Ehsani, C. Davis<strong class="title">A review of advanced techniques for detecting plant diseases</strong></div><div class="host">Comput Electron Agric, 72 (1) (2010), pp. 1-13</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0100" id="ref-id-b0100">[20]</a></dt><dd class="reference" id="h0100"><div class="contribution">P. Ghamisi, J. Plaza, Y. Chen, J. Li, A.J. Plaza<strong class="title">Advanced spectral classifiers for hyperspectral images: a review</strong></div><div class="host">IEEE Geosci Remote Sens Mag, 5 (1) (2017), pp. 8-32</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0105" id="ref-id-b0105">[21]</a></dt><dd class="reference" id="h0105"><div class="contribution">A.F.H. Goetz<strong class="title">Three decades of hyperspectral remote sensing of the earth: a personal view</strong></div><div class="host">Remote Sens Environ, 113 (2009), pp. S5-S16</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0110" id="ref-id-b0110">[22]</a></dt><dd class="reference" id="h0110"><div class="contribution">J.S. Pearlman, P.S. Barry, C.C. Segal, J. Shepanski, D. Beiso, S.L. Carman<strong class="title">Hyperion, a space-based imaging spectrometer</strong></div><div class="host">IEEE Trans Geosci Remote Sens, 41 (6) (2003), pp. 1160-1173</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0115" id="ref-id-b0115">[23]</a></dt><dd class="reference" id="h0115"><div class="contribution">J. Bell<strong class="title">The martian surface: composition, mineralogy and physical properties</strong></div><div class="host">Cambridge University Press, UK (2008)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0120" id="ref-id-b0120">[24]</a></dt><dd class="reference" id="h0120"><div class="contribution">F. Ortenberg, P.S. Thenkabail, J.G. Lyon, A. Huete<strong class="title">Hyperspectral
 sensor characteristics: airborne, spaceborne, hand-held, and 
truck-mounted; Integration of hyperspectral data with Lidar</strong></div><div class="host">P.S. Thenkabail, J.G. Lyon, A. Huete (Eds.), Hyperspectral remote sensing of vegetation, CRC Press, USA (2011), pp. 39-67</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0125" id="ref-id-b0125">[25]</a></dt><dd class="reference" id="h0125"><div class="contribution">A.F.H. Goetz, B. Curtiss, D.A. Shiley<strong class="title">Rapid gangue mineral concentration measurement over conveyors by NIR reflectance spectroscopy</strong></div><div class="host">Miner Eng, 22 (5) (2009), pp. 490-499</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0130" id="ref-id-b0130">[26]</a></dt><dd class="reference" id="h0130"><div class="contribution">A.J.B. Thompson, P.L. Hauff, A.J. Robitaille<strong class="title">Alteration mapping in exploration: application of short wave infrared (SWIR) spectroscopy</strong></div><div class="host">Soc Econ Geol Newsl, 39 (1999), pp. 16-27</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0135" id="ref-id-b0135">[27]</a></dt><dd class="reference" id="h0135"><div class="contribution">J. Liu, Z. Dong, X. Chen<strong class="title">Study on hyperspectral estimation model of total nitrogen content in soil of shaanxi province</strong></div><div class="host">IOP Conf Ser Earth Environ Sci, 108 (4) (2018), p. 42025</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0140" id="ref-id-b0140">[28]</a></dt><dd class="reference" id="h0140"><div class="contribution">V. Silva-Perez, G. Molero, S.P. Serbin, A.G. Condon, M.P. Reynolds, R.T. Furbank, <em> et al.</em><strong class="title">Hyperspectral reflectance as a tool to measure biochemical and physiological traits in wheat</strong></div><div class="host">J Exp Bot, 69 (3) (2017), pp. 483-496</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0145" id="ref-id-b0145">[29]</a></dt><dd class="reference" id="h0145"><div class="contribution">C.I. Chang<strong class="title">Hyperspectral data exploitation: theory and applications</strong></div><div class="host">John Wiley &amp; Sons (2007)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0150" id="ref-id-b0150">[30]</a></dt><dd class="reference" id="h0150"><div class="contribution">C.I. Chang<strong class="title">Hyperspectral imaging: techniques for spectral detection and classification</strong></div><div class="host">Kluwer Academic Publishers, New York (2003)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0155" id="ref-id-b0155">[31]</a></dt><dd class="reference" id="h0155"><div class="contribution">J. Lu, R. Ehsani, Y. Shi, A.I. de Castro, S. Wang<strong class="title">Detection
 of multi-tomato leaf diseases (late blight, target and bacterial spots)
 in different stages by using a spectral-based sensor</strong></div><div class="host">Sci Rep, 8 (2018), p. 2793</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0160" id="ref-id-b0160">[32]</a></dt><dd class="reference" id="h0160"><div class="contribution">R.L. Whetton, K.L. Hassall, T.W. Waine, A.M. Mouazen<strong class="title">Hyperspectral measurements of yellow rust and fusarium head blight in cereal crops: Part 1: laboratory study</strong></div><div class="host">Biosyst Eng, 166 (2018), pp. 101-115</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0165" id="ref-id-b0165">[33]</a></dt><dd class="reference" id="h0165"><div class="contribution">R.L. Whetton, T.W. Waine, A.M. Mouazen<strong class="title">Hyperspectral measurements of yellow rust and fusarium head blight in cereal crops: Part 2: on-line field measurement</strong></div><div class="host">Biosyst Eng, 167 (2018), pp. 144-158</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0170" id="ref-id-b0170">[34]</a></dt><dd class="reference" id="h0170"><div class="contribution">R.H.J. Heim, I.J. Wright, H.C. Chang, A.J. Carnegie, G.S. Pegg, E.K. Lancaster, <em> et al.</em><strong class="title">Detecting myrtle rust (<em>Austropuccinia psidii</em>) on lemon myrtle trees using spectral signatures and machine learning</strong></div><div class="host">Plant Pathol (2018)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0175" id="ref-id-b0175">[35]</a></dt><dd class="reference" id="h0175"><div class="contribution">I. Dhau, E. Adam, O. Mutanga, K.K. Ayisi<strong class="title">Detecting the severity of maize streak virus infestations in maize crop using in situ hyperspectral data</strong></div><div class="host">Trans R Soc S Afr, 73 (2018), pp. 8-15</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0180" id="ref-id-b0180">[36]</a></dt><dd class="reference" id="h0180"><div class="contribution">W. Kong, C. Zhang, W. Huang, F. Liu, Y. He<strong class="title">Application of hyperspectral imaging to detect <em>Sclerotinia sclerotiorum</em> on oilseed rape stems</strong></div><div class="host">Sensors, 18 (1) (2018), p. 123</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0185" id="ref-id-b0185">[37]</a></dt><dd class="reference" id="h0185"><div class="contribution">P. Moghadam, D. Ward, E. Goan, S. Jayawardena, P. Sikka, E. Hernandez<strong class="title">Plant disease detection using hyperspectral imaging</strong></div><div class="host">International conference on digital image computing: techniques and applications, IEEE, Sydney, NSW, Australia (2017), pp. 1-8</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0190" id="ref-id-b0190">[38]</a></dt><dd class="reference" id="h0190"><div class="contribution">P. Ahmadi, F.M. Muharam, K. Ahmad, S. Mansor, Seman I. Abu<strong class="title">Early detection of ganoderma basal stem rot of oil palms using artificial neural network spectral analysis</strong></div><div class="host">Plant Dis, 101 (6) (2017), pp. 1009-1016</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0195" id="ref-id-b0195">[39]</a></dt><dd class="reference" id="h0195"><div class="contribution">Y. Zhao, P. Chen, L. Lin, J.M. Harnly, L. Yu, Z. Li<strong class="title">Tentative
 identification, quantitation, and principal component analysis of green
 pu-erh, green, and white teas using UPLC/DAD/MS</strong></div><div class="host">Food Chem, 126 (3) (2011), pp. 1269-1277</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0200" id="ref-id-b0200">[40]</a></dt><dd class="reference" id="h0200"><div class="contribution">D.K. Kole, A. Ghosh, S. Mitra<strong class="title">Detection of downy mildew disease present in the grape leaves based on fuzzy set theory</strong></div><div class="host">M.K. Kundu, D.P. Mohapatra, A. Konar, A. Chakraborty (Eds.), Advanced computing, networking and informatics, Springer, Switzerland (2014), pp. 377-384</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0205" id="ref-id-b0205">[41]</a></dt><dd class="reference" id="h0205"><div class="contribution">M.E. Leeser, P. Belanovic, M. Estlick, M. Gokhale, J.J. Szymanski, J.P. Theiler<strong class="title">Applying reconfigurable hardware to the analysis of multispectral and hyperspectral imagery</strong></div><div class="host">Proc. SPIE 4480, Imaging Spectrometry VII (2002), pp. 100-108</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0210" id="ref-id-b0210">[42]</a></dt><dd class="reference" id="h0210"><div class="contribution">D. Krezhova, A. Stoev, S. Maneva<strong class="title">Detection of biotic stress caused by apple stem grooving virus in apple trees using hyperspectral reflectance analysis</strong></div><div class="host">Comptes Rendus l’Académie Bulg Des Sci, 68 (2) (2015), pp. 175-182</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0215" id="ref-id-b0215">[43]</a></dt><dd class="reference" id="h0215"><div class="contribution">T. Zou, Y. Dou, H. Mi, J. Zou, Y. Ren<strong class="title">Support vector regression for determination of component of compound oxytetracycline powder on near-infrared spectroscopy</strong></div><div class="host">Anal Biochem, 355 (2006), pp. 1-7</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0220" id="ref-id-b0220">[44]</a></dt><dd class="reference" id="h0220"><div class="contribution">K. Nagasubramanian, S. Jones, S. Sarkar, A.K. Singh, A. Singh, B. Ganapathysubramanian<strong class="title">Hyperspectral
 band selection using genetic algorithm and support vector machines for 
early identification of charcoal rot disease in soybean</strong></div><div class="host">arXiv preprint arXiv, 1710 (04681) (2017), pp. 1-20</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0225" id="ref-id-b0225">[45]</a></dt><dd class="reference" id="h0225"><div class="contribution">B. Zhang, W. Huang, C. Wang, L. Gong, C. Zhao, C. Liu, <em> et al.</em><strong class="title">Computer vision recognition of stem and calyx in apples using near-infrared linear-array structured light and 3D reconstruction</strong></div><div class="host">Biosyst Eng, 139 (2015), pp. 25-34</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0230" id="ref-id-b0230">[46]</a></dt><dd class="reference" id="h0230"><div class="contribution">C.M. Bishop<strong class="title">Neural networks for pattern recognition</strong></div><div class="host">Oxford University Press, USA (1995)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0235" id="ref-id-b0235">[47]</a></dt><dd class="reference" id="h0235"><div class="contribution">K.S. Ettabaa, Salem M Ben<strong class="title">Adaptive progressive band selection for dimensionality reduction in hyperspectral images</strong></div><div class="host">J Indian Soc Remote Sens, 46 (2) (2018), pp. 157-167</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0240" id="ref-id-b0240">[48]</a></dt><dd class="reference" id="h0240"><div class="contribution">A.F.H. Goetz, G. Vane, J.E. Solomon, B.N. Rock<strong class="title">Imaging spectrometry for earth remote sensing</strong></div><div class="host">Science, 228 (4704) (1985), pp. 1147-1153</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0245" id="ref-id-b0245">[49]</a></dt><dd class="reference" id="h0245"><div class="contribution">F. Marini, R. Bucci, A.L. Magrì, A.D. Magrì<strong class="title">Artificial neural networks in chemometrics: history, examples and perspectives</strong></div><div class="host">Microchem J, 88 (2) (2008), pp. 178-185</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0250" id="ref-id-b0250">[50]</a></dt><dd class="reference" id="h0250"><div class="contribution">F. Marini, J. Zupan, A.L. Magrì<strong class="title">Class-modeling using kohonen artificial neural networks</strong></div><div class="host">Anal Chim Acta, 544 (1–2) (2005), pp. 306-314</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0255" id="ref-id-b0255">[51]</a></dt><dd class="reference" id="h0255"><div class="contribution">F. Marini, A.L. Magrì, R. Bucci<strong class="title">Multilayer feed-forward artificial neural networks for class modeling</strong></div><div class="host">Chemom Intell Lab Syst, 88 (1) (2007), pp. 118-124</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0260" id="ref-id-b0260">[52]</a></dt><dd class="reference" id="h0260"><div class="contribution">D. Al Bashish, M. Braik, S. Bani-Ahmad</div><div class="host">A framework for detection and classification of plant leaf and stem diseases, IEEE, Chennai, India (2010), pp. 113-118</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0265" id="ref-id-b0265">[53]</a></dt><dd class="reference" id="h0265"><div class="contribution">H. Zhu, B. Chu, C. Zhang, F. Liu, L. Jiang, Y. He<strong class="title">Hyperspectral
 imaging for presymptomatic detection of tobacco disease with successive
 projections algorithm and machine-learning Classifiers</strong></div><div class="host">Sci Rep, 7 (1) (2017), p. 4125</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0270" id="ref-id-b0270">[54]</a></dt><dd class="reference" id="h0270"><div class="contribution">H. Zhu, H. Cen, C. Zhang, Y. He<strong class="title">Early
 detection and classification of tobacco leaves inoculated with tobacco 
mosaic virus based on hyperspectral imaging technique</strong></div><div class="host">ASABE Annual Internation Meeting (2016), p. 1</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0275" id="ref-id-b0275">[55]</a></dt><dd class="reference" id="h0275"><div class="contribution">D. Ashourloo, A.A. Matkan, A. Huete, H. Aghighi, M.R. Mobasheri<strong class="title">Developing an index for detection and identification of disease stages</strong></div><div class="host">IEEE Geosci Remote Sens Lett, 13 (6) (2016), pp. 851-855</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0280" id="ref-id-b0280">[56]</a></dt><dd class="reference" id="h0280"><span>Shiffman D. Neural networks. The nature of code: simulating natural systems with processing (Online). Link: &lt;<a href="http://natureofcode.com/book/chapter-10-neural-networks/" target="_blank">http://natureofcode.com/book/chapter-10-neural-networks/</a>&gt;; 2012.</span></dd><dt class="label"><a href="#bb0285" id="ref-id-b0285">[57]</a></dt><dd class="reference" id="h0285"><div class="contribution">F.O. Karray, C.W. De Silva<strong class="title">Soft computing and intelligent systems design: theory, tools, and applications</strong></div><div class="host">Pearson Education, London (2004)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0290" id="ref-id-b0290">[58]</a></dt><dd class="reference" id="h0290"><div class="contribution">L. Tarassenko<strong class="title">Neural computing hardware and software</strong></div><div class="host">Guide to neural computing applications, Butterworth-Heinemann (1998), pp. 59-66</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0295" id="ref-id-b0295">[59]</a></dt><dd class="reference" id="h0295"><div class="contribution">W.S. McCulloch, W. Pitts<strong class="title">A logical calculus of the ideas immanent in nervous activity</strong></div><div class="host">Bull Math Biophys, 5 (4) (1943), pp. 115-133</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0300" id="ref-id-b0300">[60]</a></dt><dd class="reference" id="h0300"><div class="contribution">G. Caocci, R. Baccoli, G. La<strong class="title">The usefulness of artificial neural networks in predicting the outcome of hematopoietic stem cell transplantation</strong></div><div class="host">K. Suzuki (Ed.), Artificial neural networks – methodological advances and biomedical applications, InTech, Rijeka, Croatia (2011), pp. 217-232</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0305" id="ref-id-b0305">[61]</a></dt><dd class="reference" id="h0305"><div class="contribution">H. Demuth, M. Beale, M. Hagan<strong class="title">Neural network toolbox™</strong></div><div class="host"> (2008)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0310" id="ref-id-b0310">[62]</a></dt><dd class="reference" id="h0310"><div class="contribution">J.S. Almeida<strong class="title">Predictive non-linear modeling of complex data by artificial neural networks</strong></div><div class="host">Curr Opin Biotechnol, 13 (1) (2002), pp. 72-76</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0315" id="ref-id-b0315">[63]</a></dt><dd class="reference" id="h0315"><div class="contribution">F. Rosenblatt<strong class="title">The perceptron: a probabilistic model for information storage and organization in the brain</strong></div><div class="host">Psychol Rev, 65 (6) (1958), pp. 386-408</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0320" id="ref-id-b0320">[64]</a></dt><dd class="reference" id="h0320"><div class="contribution">F. Rosenblatt<strong class="title">Physiological and psychological consideration</strong></div><div class="host">Principles of neurodynamics: perceptrons and theory of brain mechanisms, Cornell Aeronautical Laboratory, Inc., USA (1961), p. 32</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0325" id="ref-id-b0325">[65]</a></dt><dd class="reference" id="h0325"><div class="contribution">L. Tarassenko<strong class="title">Mathematical background for neural computing</strong></div><div class="host">L. Tarassenko (Ed.), Guide to neural computing applications, Butterworth-Heinemann (1998), pp. 5-35</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0330" id="ref-id-b0330">[66]</a></dt><dd class="reference" id="h0330"><div class="contribution">C.M. Bishop<strong class="title">Single layer networks</strong></div><div class="host">Neural networks for pattern recognition, Oxford University Press, USA (1995), pp. 77-112</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0335" id="ref-id-b0335">[67]</a></dt><dd class="reference" id="h0335"><span>Baehni S. Single-layer perceptron neural networks. Link: &lt;<a href="http://lcn.epfl.ch/tutorial/english/perceptron/html/intro.html" target="_blank">http://lcn.epfl.ch/tutorial/english/perceptron/html/intro.html</a>&gt;; 2000.</span></dd><dt class="label"><a href="#bb0340" id="ref-id-b0340">[68]</a></dt><dd class="reference" id="h0340"><div class="contribution">Š. Raudys<strong class="title">Evolution and generalization of a single neurone: I. Single-layer perceptron as seven statistical classifier</strong></div><div class="host">Neural Netw, 11 (2) (1998), pp. 283-296</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0345" id="ref-id-b0345">[69]</a></dt><dd class="reference" id="h0345"><div class="contribution">S.T. Monteiro, Y. Kosugi, K. Uto, E. Watanabe<strong class="title">Towards applying hyperspectral imagery as an intraoperative visual aid tool</strong></div><div class="host">Proceeding of the Fourth IASTED International Conference on Visualization, Imaging and Image Processing. Marbella, Spain (2004), pp. 483-488</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0350" id="ref-id-b0350">[70]</a></dt><dd class="reference" id="h0350"><div class="contribution">G. Lu, G. Lu, B. Fei<strong class="title">Medical hyperspectral imaging : a review</strong></div><div class="host">J Biomed Opt, 19 (1) (2014), p. 10901</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0355" id="ref-id-b0355">[71]</a></dt><dd class="reference" id="h0355"><div class="contribution">J.D. Paola, R.A. Schowengerdt<strong class="title">A review and analysis of backpropagation neural networks for classification of remotely-sensed multi-spectral imagery</strong></div><div class="host">Int J Remote Sens, 16 (16) (1995), pp. 3033-3058</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0360" id="ref-id-b0360">[72]</a></dt><dd class="reference" id="h0360"><div class="contribution">J. Abdulridha, R. Ehsani, A. de Castro<strong class="title">Detection
 and differentiation between Laurel wilt disease, phytophthora disease, 
and salinity damage using a hyperspectral sensing technique</strong></div><div class="host">Agriculture, 6 (4) (2016), p. 56</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0365" id="ref-id-b0365">[73]</a></dt><dd class="reference" id="h0365"><div class="contribution">D. Moshou, C. Bravo, J. West, S. Wahlen, A. McCartney, H. Ramon<strong class="title">Automatic detection of “yellow rust” in wheat using reflectance measurements and neural networks</strong></div><div class="host">Comput Electron Agric, 44 (3) (2004), pp. 173-188</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0370" id="ref-id-b0370">[74]</a></dt><dd class="reference" id="h0370"><div class="contribution">S.N. Ghaiwat, P. Arora<strong class="title">Detection and classification of plant leaf diseases using image processing techniques: a review</strong></div><div class="host">Int J Recent Adv Eng Technol, 2 (2014), pp. 2347-2812</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0375" id="ref-id-b0375">[75]</a></dt><dd class="reference" id="h0375"><div class="contribution">Y. Huang<strong class="title">Advances in artificial neural networks – methodological development and application</strong></div><div class="host">Algorithms, 2 (3) (2009), pp. 973-1007</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0380" id="ref-id-b0380">[76]</a></dt><dd class="reference" id="h0380"><div class="contribution">J. Moody, C.J. Darken<strong class="title">Fast learning in networks of locally-tuned processing units</strong></div><div class="host">Neural Comput, 1 (2) (1989), pp. 281-294</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0385" id="ref-id-b0385">[77]</a></dt><dd class="reference" id="h0385"><div class="contribution">D.S. Broomhead, D. Lowe<strong class="title">Multivariable functional interpolation and adaptive networks</strong></div><div class="host">Comp Syst (1988), p. 21</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0390" id="ref-id-b0390">[78]</a></dt><dd class="reference" id="h0390"><div class="contribution">A. Alexandridis, E. Chondrodima, H. Sarimveis<strong class="title">Cooperative learning for radial basis function networks using particle swarm optimization</strong></div><div class="host">Appl Soft Comput, 49 (2016), pp. 485-497</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0395" id="ref-id-b0395">[79]</a></dt><dd class="reference" id="h0395"><div class="contribution">Y. Chen, M. Xie, H. Zhang, Y. Wang, S. Nie, C. Li<strong class="title">Quantification of total polysaccharides and triterpenoids in <em>Ganoderma lucidum</em> and <em>Ganoderma atrum</em> by near infrared spectroscopy and chemometrics</strong></div><div class="host">Food Chem, 135 (2012), pp. 268-275</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0400" id="ref-id-b0400">[80]</a></dt><dd class="reference" id="h0400"><div class="contribution">R. Yang, P.V. Er, Z. Wang, K.K. Tan<strong class="title">An RBF neural network approach towards precision motion system with selective sensor fusion</strong></div><div class="host">Neurocomputing, 199 (2016), pp. 31-39</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0405" id="ref-id-b0405">[81]</a></dt><dd class="reference" id="h0405"><div class="contribution">T. Kohonen<strong class="title">Self-organized formation of topologically correct feature maps</strong></div><div class="host">Biol Cybern, 43 (1) (1982), pp. 59-69</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0410" id="ref-id-b0410">[82]</a></dt><dd class="reference" id="h0410"><div class="contribution">A. Krenker, J. Bešter, A. Kos<strong class="title">Introduction to the artificial neural networks</strong></div><div class="host">K. Suzuki (Ed.), Artificial neural networks – methodological advances and biomedical applications, InTech, Rijeka, Croatia (2011), pp. 3-18</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0415" id="ref-id-b0415">[83]</a></dt><dd class="reference" id="h0415"><div class="contribution">G.W. Lawrence, A.T. Kelley, R.L. King, J. Vickery, H.K. Lee, K.S. McLean<strong class="title">Remote sensing and precision nematicide applications for <em>Rotylenchulus reniformis</em> management in cotton</strong></div><div class="host">R. Cook, D.J. Hunt (Eds.), Nematology monographs and perspectives (2004)</div><div class="comment">Brill, Leiden and Boston</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0420" id="ref-id-b0420">[84]</a></dt><dd class="reference" id="h0420"><div class="contribution">G.W. Lawrence, R.A. Doshi, R.L. King, K.S. Lawrence, J. Caceres<strong class="title">Nematode management using remote sensing technology, self-organized maps and variable rate nematicide applications</strong></div><div class="host">World Cotton Research Conference.Texas USA (2007)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0425" id="ref-id-b0425">[85]</a></dt><dd class="reference" id="h0425"><div class="contribution">D.F. Specht<strong class="title">Probabilistic neural networks</strong></div><div class="host">Neural Netw, 3 (1) (1990), pp. 109-118</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0430" id="ref-id-b0430">[86]</a></dt><dd class="reference" id="h0430"><div class="contribution">D.F. Specht<strong class="title">Probabilistic neural networks and general regression neural networks</strong></div><div class="host">C.H. Chen (Ed.), Fuzzy logic and neural network handbook, McGraw-Hill, USA (1996), pp. 3.1-3.44</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0435" id="ref-id-b0435">[87]</a></dt><dd class="reference" id="h0435"><div class="contribution">B. Li, Z. Liu, J. Huang, L. Zhang, W. Zhou, J. Shi<strong class="title">Hyperspectral identification of rice diseases and pests based on principal component analysis and probabilistic neural network</strong></div><div class="host">Trans Chinese Soc Agric Eng, 25 (9) (2009), pp. 143-147</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0440" id="ref-id-b0440">[88]</a></dt><dd class="reference" id="h0440"><div class="contribution">A. Lowe, N. Harrison, A.P. French<strong class="title">Hyperspectral image analysis techniques for the detection and classification of the early onset of plant disease and stress</strong></div><div class="host">Plant Methods, 13 (1) (2017), p. 80</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0445" id="ref-id-b0445">[89]</a></dt><dd class="reference" id="h0445"><div class="contribution">S.P. Mohanty, D.P. Hughes, M. Salathé<strong class="title">Using deep learning for image-based plant disease detection. Front</strong></div><div class="host">Plant Sci (2016;7.)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0450" id="ref-id-b0450">[90]</a></dt><dd class="reference" id="h0450"><div class="contribution">S. Sladojevic, M. Arsenovic, A. Anderla, D. Culibrk, D. Stefanovic<strong class="title">Deep neural networks based recognition of plant diseases by leaf image classification</strong></div><div class="host">Comput Intell Neurosci, 2016 (2016), pp. 1-11</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0455" id="ref-id-b0455">[91]</a></dt><dd class="reference" id="h0455"><div class="contribution">Y. Chen, H. Jiang, C. Li, X. Jia, S. Member<strong class="title">Deep feature extraction and classification of hyperspectral images based on convolutional neural networks</strong></div><div class="host">IEEE Trans Geosci Remote Sens, 54 (10) (2016), pp. 6232-6251</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0460" id="ref-id-b0460">[92]</a></dt><dd class="reference" id="h0460"><div class="contribution">M.E. Paoletti, J.M. Haut, J. Plaza, A. Plaza<strong class="title">A new deep convolutional neural network for fast hyperspectral image classification</strong></div><div class="host">ISPRS J Photogramm Remote Sens (2017)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0465" id="ref-id-b0465">[93]</a></dt><dd class="reference" id="h0465"><div class="contribution">Y. Lu, S. Yi, N. Zeng, Y. Liu, Y. Zhang<strong class="title">Identification of rice diseases using deep convolutional neural networks</strong></div><div class="host">Neurocomputing, 267 (2017), pp. 378-384</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0470" id="ref-id-b0470">[94]</a></dt><dd class="reference" id="h0470"><div class="contribution">Z.L. Langford, J. Kumar, F.M. Hoffman<strong class="title">Convolutional neural network approach for mapping arctic vegetation using multi-sensor remote sensing fusion</strong></div><div class="host">International Conference on Data Mining Workshops IEEE (2017), pp. 322-331</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0475" id="ref-id-b0475">[95]</a></dt><dd class="reference" id="h0475"><span>Stefanowski,
 J. Artificial neural networks – basics of MLP, RBF and Kohonen 
networks. Institute of computing science lecture 13 in data mining for 
M. Sc. course of SE version for 2010. Link: &lt;<a href="http://www.cs.put.poznan.pl/jstefanowski/sed/DM13neuralnetworks.pdf" target="_blank">http://www.cs.put.poznan.pl/jstefanowski/sed/DM13neuralnetworks.pdf</a>&gt;; 2010.</span></dd><dt class="label"><a href="#bb0480" id="ref-id-b0480">[96]</a></dt><dd class="reference" id="h0480"><div class="contribution">T.A. Plate, J. Bert, J. Grace, P. Band<strong class="title">Visualizing the function computed by a feedforward neural network</strong></div><div class="host">Neural Comput, 12 (6) (2000), pp. 1337-1353</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0485" id="ref-id-b0485">[97]</a></dt><dd class="reference" id="h0485"><div class="contribution">J. Hawkins, M. Boden<strong class="title">The applicability of recurrent neural networks for biological sequence analysis</strong></div><div class="host">IEEE/ACM Trans Comput Biol Bioinform, 2 (3) (2005), pp. 243-253</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0490" id="ref-id-b0490">[98]</a></dt><dd class="reference" id="h0490"><div class="contribution">M. Egmont-Petersen, D. de Ridder, H. Handels<strong class="title">Image processing with neural networks – a review</strong></div><div class="host">Pattern Recognit, 35 (10) (2002), pp. 2279-2301</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0495" id="ref-id-b0495">[99]</a></dt><dd class="reference" id="h0495"><div class="contribution">T. Udelhoven, B. Schütt<strong class="title">Capability of feed-forward neural networks for a chemical evaluation of sediments with diffuse reflectance spectroscopy</strong></div><div class="host">Chemom Intell Lab Syst, 51 (1) (2000), pp. 9-22</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0500" id="ref-id-b0500">[100]</a></dt><dd class="reference" id="h0500"><div class="contribution">C.M. Bishop<strong class="title">The multi-layer perceptron</strong></div><div class="host">Neural networks for pattern recognition, Oxford University Press, USA (1995), pp. 116-120</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0505" id="ref-id-b0505">[101]</a></dt><dd class="reference" id="h0505"><div class="contribution">G.-B. Huang, Q.-Y. Zhu, C.-K. Siew<strong class="title">Extreme learning machine: theory and applications</strong></div><div class="host">Neurocomputing, 70 (1–3) (2006), pp. 489-501</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0510" id="ref-id-b0510">[102]</a></dt><dd class="reference" id="h0510"><div class="contribution">G. Huang, G.-B. Huang, S. Song, K. You<strong class="title">Trends in extreme learning machines: a review</strong></div><div class="host">Neural Netw, 61 (2015), pp. 32-48</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0515" id="ref-id-b0515">[103]</a></dt><dd class="reference" id="h0515"><div class="contribution">J. Tang, C. Deng, G.-B. Huang<strong class="title">Extreme learning machine for multilayer perceptron</strong></div><div class="host">IEEE Trans Neural Networks Learn Syst, 27 (4) (2016), pp. 809-821</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0520" id="ref-id-b0520">[104]</a></dt><dd class="reference" id="h0520"><div class="contribution">G.-B. Huang<strong class="title">An insight into extreme learning machines: random neurons, random features and kernels</strong></div><div class="host">Cognit Comput, 6 (3) (2014), pp. 376-390</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0525" id="ref-id-b0525">[105]</a></dt><dd class="reference" id="h0525"><div class="contribution">P.A. Paul, G.P. Munkvold<strong class="title">Regression and artificial neural network modeling for the prediction of gray leaf spot of maize</strong></div><div class="host">Phytopathology, 95 (4) (2005), pp. 388-396</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0530" id="ref-id-b0530">[106]</a></dt><dd class="reference" id="h0530"><div class="contribution">A.B. Zhang, D.S. Sikes, C. Muster, S.Q. Li<strong class="title">Inferring species membership using DNA sequences with back-propagation neural networks</strong></div><div class="host">Syst Biol, 57 (2008), pp. 202-215</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0535" id="ref-id-b0535">[107]</a></dt><dd class="reference" id="h0535"><div class="contribution">P. Sajda<strong class="title">Machine learning for detection and diagnosis of disease</strong></div><div class="host">Annu Rev Biomed Eng, 8 (1) (2006), pp. 537-565</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0540" id="ref-id-b0540">[108]</a></dt><dd class="reference" id="h0540"><div class="contribution">Y. Chtioui, S. Panigrahi, L. Francl<strong class="title">A generalized regression neural network and its application for leaf wetness prediction to forecast plant disease</strong></div><div class="host">Chemom Intell Lab Syst., 48 (1) (1999), pp. 47-58</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0545" id="ref-id-b0545">[109]</a></dt><dd class="reference" id="h0545"><div class="contribution">E. Parzen<strong class="title">On estimation of a probability density function and mode</strong></div><div class="host">Ann Math Stat, 33 (3) (1962), pp. 1065-1076</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0550" id="ref-id-b0550">[110]</a></dt><dd class="reference" id="h0550"><div class="contribution">S.G. Wu, F.S. Bao, E.Y. Xu, Y.X. Wang, Y.F. Chang, Q.L. Xiang<strong class="title">A leaf recognition algorithm for plant classification using probabilistic neural network</strong></div><div class="host">International Symposium on Signal Processing and Information Technology IEEE. Giza, Egypt (2007), pp. 11-16</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0555" id="ref-id-b0555">[111]</a></dt><dd class="reference" id="h0555"><div class="contribution">C. Wu, M. Berry, Y.S. Fung, J. McLarty<strong class="title">Neural networks for molecular sequence classification</strong></div><div class="host">International conference on intelligent systems for molecular biology (1993), pp. 429-437</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0560" id="ref-id-b0560">[112]</a></dt><dd class="reference" id="h0560"><div class="contribution">L. Liu, G. Zhou<strong class="title">Extraction of the rice leaf disease image based on BP neural network</strong></div><div class="host">International Conference on Computational Intelligence and Software Engineering IEEE. Wuhan, China (2009), pp. 1-3</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0565" id="ref-id-b0565">[113]</a></dt><dd class="reference" id="h0565"><div class="contribution">C. Wu, S. Shivakumar<strong class="title">Back-propagation and counter-propagation neural networks for phylogenetic classification of ribosomal RNA sequences</strong></div><div class="host">Nucl Acids Res, 22 (20) (1994), pp. 4291-4299</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0570" id="ref-id-b0570">[114]</a></dt><dd class="reference" id="h0570"><div class="contribution">A. Camargo, J.S. Smith<strong class="title">Image pattern classification for the identification of disease causing agents in plants</strong></div><div class="host">Comput Electron Agric, 66 (2) (2009), pp. 121-125</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0575" id="ref-id-b0575">[115]</a></dt><dd class="reference" id="h0575"><div class="contribution">D. Lorente, N. Aleixos, J. Gómez-Sanchis, S. Cubero, J. Blasco<strong class="title">Selection of optimal wavelength features for decay detection in citrus fruit using the ROC curve and neural networks</strong></div><div class="host">Food Bioprocess Technol, 6 (2) (2013), pp. 530-541</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0580" id="ref-id-b0580">[116]</a></dt><dd class="reference" id="h0580"><div class="contribution">W. Liu, E.Y. Wu<strong class="title">Comparison of non-linear mixture models: sub-pixel classification</strong></div><div class="host">Remote Sens Environ., 94 (2) (2005), pp. 145-154</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0585" id="ref-id-b0585">[117]</a></dt><dd class="reference" id="h0585"><div class="contribution">R. Pu<strong class="title">Hyperspectral remote sensing: fundamentals and practices</strong></div><div class="host">CRC Press, USA (2017)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0590" id="ref-id-b0590">[118]</a></dt><dd class="reference" id="h0590"><div class="contribution">K.R. Wood<strong class="title">Nepovirus isolation and RNA extraction</strong></div><div class="host">G.D. Foster, S.C. Taylor (Eds.), Plant virology protocols, Humana Press, USA (1998)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0595" id="ref-id-b0595">[119]</a></dt><dd class="reference" id="h0595"><span>Raid
 R. Specific symptoms &amp; signs of bacterial diseases. Plant pathology
 guidelines for master gardeners. University Florida. Link: &lt;<a href="http://erec.ifas.ufl.edu/plant_pathology_guidelines/module_03.shtml" target="_blank">http://erec.ifas.ufl.edu/plant_pathology_guidelines/module_03.shtml</a>&gt;; 2011.</span></dd><dt class="label"><a href="#bb0600" id="ref-id-b0600">[120]</a></dt><dd class="reference" id="h0600"><div class="contribution">S.T. Koike, P. Gladders, A.O. Paulus<strong class="title">Causes of disease</strong></div><div class="host">Vegetable diseases: a color handbook, Manson Publishing Ltd, London (2007), pp. 22-24</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0605" id="ref-id-b0605">[121]</a></dt><dd class="reference" id="h0605"><div class="contribution">P.S. Thenkabail, R.B. Smith, E. De Pauw<strong class="title">Evaluation
 of narrowband and broadband vegetation indices for determining optimal 
hyperspectral wavebands for agricultural crop characterization</strong></div><div class="host">Photogramm Eng Remote Sens, 68 (6) (2002), pp. 607-622</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0610" id="ref-id-b0610">[122]</a></dt><dd class="reference" id="h0610"><div class="contribution">J. Qi, Y. Inoue, N. Wiangwang<strong class="title">Hyperspectral remote sensing in global change studies</strong></div><div class="host">P.S. Thenkabail, J.G. Lyon, A. Huete (Eds.), Hyperspectral remote sensing of vegetation, CRC Press, USA (2011), pp. 69-90</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0615" id="ref-id-b0615">[123]</a></dt><dd class="reference" id="h0615"><div class="contribution">A.K. Mahlein<strong class="title">Plant disease detection by imaging sensors – parallels and specific demands for precision agriculture and plant phenotyping</strong></div><div class="host">Plant Dis, 100 (2) (2016), pp. 241-251</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0620" id="ref-id-b0620">[124]</a></dt><dd class="reference" id="h0620"><div class="contribution">J. Hill, T. Udelhoven, M. Vohland, A. Stevens<strong class="title">The use of laboratory spectroscopy and optical remote sensing for estimating soil properties</strong></div><div class="host">E.-.C. Oerke, R. Gerhards, G. Menz, R.A. Sikora (Eds.), Precision crop protection – the challenge and use of heterogeneity, Springer, Netherlands, Dordrecht (2010), pp. 67-85</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0625" id="ref-id-b0625">[125]</a></dt><dd class="reference" id="h0625"><div class="contribution">D. Wu, L. Feng, C. Zhang, Y. He<strong class="title">Early detection of <em>Botrytis cinerea</em> on eggplant leaves based on visible and near-infrared spectroscopy</strong></div><div class="host">Trans ASABE, 51 (2008), pp. 1133-1139</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0630" id="ref-id-b0630">[126]</a></dt><dd class="reference" id="h0630"><div class="contribution">G. le Maire, C. Francois, K. Soudani, D. Berveiller, J.-Y. Pontailler, N. Bréda, <em> et al.</em><strong class="title">Calibration
 and validation of hyperspectral indices for the estimation of 
broadleaved forest leaf chlorophyll content, leaf mass per area, leaf 
area index and leaf canopy biomass</strong></div><div class="host">Remote Sens Environ, 112 (2008), pp. 3846-3864</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0635" id="ref-id-b0635">[127]</a></dt><dd class="reference" id="h0635"><div class="contribution">R. Pydipati, T.F. Burks, W.S. Lee<strong class="title">Identification of citrus disease using color texture features and discriminant analysis</strong></div><div class="host">Comput Electron Agric, 52 (1–2) (2006), pp. 49-59</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0640" id="ref-id-b0640">[128]</a></dt><dd class="reference" id="h0640"><div class="contribution">W.M. Miller, J.A. Throop, B.L. Upchurch<strong class="title">Pattern recognition models for spectral reflectance evaluation of apple blemishes</strong></div><div class="host">Postharvest Biol Technol, 14 (1) (1998), pp. 11-20</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0645" id="ref-id-b0645">[129]</a></dt><dd class="reference" id="h0645"><div class="contribution">D.M. Bulanon, T.F. Burks, D.G. Kim, M.A. Ritenour<strong class="title">Citrus black spot detection using hyperspectral image analysis</strong></div><div class="host">Agric Eng Int CIGR J, 15 (3) (2013), pp. 171-180</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0650" id="ref-id-b0650">[130]</a></dt><dd class="reference" id="h0650"><div class="contribution">S.G. Bajwa, P. Bajcsy, P. Groves, L.F. Tian<strong class="title">Hyperspectral image data mining for band selection in agricultural applications</strong></div><div class="host">Trans ASAE., 47 (3) (2004), pp. 895-907</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0655" id="ref-id-b0655">[131]</a></dt><dd class="reference" id="h0655"><div class="contribution">S. Delalieux, J. van Aardt, W. Keulemans, E. Schrevens, P. Coppin<strong class="title">Detection of biotic stress (<em>Venturia inaequalis</em>) in apple trees using hyperspectral data: Non-parametric statistical approaches and physiological implications</strong></div><div class="host">Eur J Agron., 27 (1) (2007), pp. 130-143</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0660" id="ref-id-b0660">[132]</a></dt><dd class="reference" id="h0660"><div class="contribution">R.K. Gautam, S. Panigrahi<strong class="title">Image processing techniques and neural network models for predicting plant nitrate using aerial images</strong></div><div class="host">International Joint Conference on Neural Networks IEEE. Portland, OR, USA (2003), pp. 1031-1036</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0665" id="ref-id-b0665">[133]</a></dt><dd class="reference" id="h0665"><div class="contribution">Min Han, Lei Cheng, Hua Meng<strong class="title">Classification of aerial photograph using neural network</strong></div><div class="host">International Conference on Systems, Man and Cybernetics IEEE. Yasmine Hammamet, Tunisia (2012), p. 6</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0670" id="ref-id-b0670">[134]</a></dt><dd class="reference" id="h0670"><div class="contribution">O. Mutanga, A.K. Skidmore<strong class="title">Narrow band vegetation indices overcome the saturation problem in biomass estimation</strong></div><div class="host">Int J Remote Sens, 25 (19) (2004), pp. 3999-4014</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0675" id="ref-id-b0675">[135]</a></dt><dd class="reference" id="h0675"><div class="contribution">H.H. Muhammed<strong class="title">Hyperspectral crop reflectance data for characterising and estimating fungal disease severity in wheat</strong></div><div class="host">Biosyst Eng, 91 (1) (2005), pp. 9-20</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0680" id="ref-id-b0680">[136]</a></dt><dd class="reference" id="h0680"><div class="contribution">C.D. Jones, J.B. Jones, W.S. Lee<strong class="title">Diagnosis of bacterial spot of tomato using spectral signatures</strong></div><div class="host">Comput Electron Agric, 74 (2) (2010), pp. 329-335</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0685" id="ref-id-b0685">[137]</a></dt><dd class="reference" id="h0685"><div class="contribution">Z.-Y. Liu, H.-F. Wu, J.-F. Huang<strong class="title">Application
 of neural networks to discriminate fungal infection levels in rice 
panicles using hyperspectral reflectance and principal components 
analysis</strong></div><div class="host">Comput Electron Agric, 72 (2) (2010), pp. 99-106</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0690" id="ref-id-b0690">[138]</a></dt><dd class="reference" id="h0690"><div class="contribution">Z. Liu, J. Huang, R. Tao, H. Zhang<strong class="title">Estimating
 the severity of rice brown spot disease based on principal component 
analysis and radial basis function neural network</strong></div><div class="host">Spectrosc Spectr Anal., 28 (9) (2008), pp. 2156-2160</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0695" id="ref-id-b0695">[139]</a></dt><dd class="reference" id="h0695"><div class="contribution">X. Wang, M. Zhang, J. Zhu, S. Geng<strong class="title">Spectral prediction of Phytophthora infestans infection on tomatoes using artificial neural network (ANN)</strong></div><div class="host">Int J Remote Sens, 29 (6) (2008), pp. 1693-1706</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0700" id="ref-id-b0700">[140]</a></dt><dd class="reference" id="h0700"><div class="contribution">P. Baranowski, M. Jedryczka, W. Mazurek, D. Babula-Skowronska, A. Siedliska, J. Kaczmarek<strong class="title">Hyperspectral and thermal imaging of oilseed rape (<em>Brassica napus</em>) response to fungal species of the genus alternaria</strong></div><div class="host">PLoS One, 10 (3) (2015), Article e0122913</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0705" id="ref-id-b0705">[141]</a></dt><dd class="reference" id="h0705"><div class="contribution">W.S. Lee, R. Ehsani<strong class="title">Sensing systems for precision agriculture in Florida</strong></div><div class="host">Comput Electron Agric, 112 (2015), pp. 2-9</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0710" id="ref-id-b0710">[142]</a></dt><dd class="reference" id="h0710"><div class="contribution">H.Z.M. Shafri, N. Hamdan<strong class="title">Hyperspectral imagery for mapping disease infection in oil palm plantation using vegetation indices and red edge techniques</strong></div><div class="host">Am J Appl Sci, 6 (6) (2009), pp. 1031-1035</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0715" id="ref-id-b0715">[143]</a></dt><dd class="reference" id="h0715"><div class="contribution">A.K. Mahlein, U. Steiner, C. Hillnhütter, H.W. Dehne, E.C. Oerke<strong class="title">Hyperspectral imaging for small-scale analysis of symptoms caused by different sugar beet diseases</strong></div><div class="host">Plant Methods, 8 (1) (2012), p. 3</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0720" id="ref-id-b0720">[144]</a></dt><dd class="reference" id="h0720"><div class="contribution">A. Apan, A. Held, S. Phinn, J. Markley<strong class="title">Detecting sugarcane “orange rust” disease using EO-1 hyperion hyperspectral imagery</strong></div><div class="host">Int J Remote Sens., 25 (2) (2004), pp. 489-498</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0725" id="ref-id-b0725">[145]</a></dt><dd class="reference" id="h0725"><div class="contribution">E. Bauriegel, W. Herppich<strong class="title">Hyperspectral and chlorophyll fluorescence imaging for early detection of plant diseases, with special reference to <em>fusarium</em> spec. infections on wheat</strong></div><div class="host">Agriculture, 4 (1) (2014), pp. 32-57</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0730" id="ref-id-b0730">[146]</a></dt><dd class="reference" id="h0730"><div class="contribution">J. Qin, T.F. Burks, M.A. Ritenour, W.G. Bonn<strong class="title">Detection of citrus canker using hyperspectral reflectance imaging with spectral information divergence</strong></div><div class="host">J Food Eng, 93 (2) (2009), pp. 183-191</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0735" id="ref-id-b0735">[147]</a></dt><dd class="reference" id="h0735"><div class="contribution">A. Del Fiore, M. Reverberi, A. Ricelli, F. Pinzari, S. Serranti, A.A. Fabbri, <em> et al.</em><strong class="title">Early detection of toxigenic fungi on maize by hyperspectral imaging analysis</strong></div><div class="host">Int J Food Microbiol, 144 (1) (2010), pp. 64-71</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0740" id="ref-id-b0740">[148]</a></dt><dd class="reference" id="h0740"><div class="contribution">W. Shen, Y. Li, W. Feng, H. Zhang, Y. Zhang, Y. Xie, <em> et al.</em><strong class="title">Inversion model for severity of powdery mildew in wheat leaves based on factor analysis-BP neural network</strong></div><div class="host">Trans Chinese Soc Agric Eng., 31 (22) (2015), pp. 183-190</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0745" id="ref-id-b0745">[149]</a></dt><dd class="reference" id="h0745"><div class="contribution">G. Camps-Valls, L. Bruzzone<strong class="title">Kernel-based methods for hyperspectral image classification</strong></div><div class="host">IEEE Trans Geosci Remote Sens., 43 (6) (2005), pp. 1351-1362</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0750" id="ref-id-b0750">[150]</a></dt><dd class="reference" id="h0750"><span>Rouse
 Jr JW, Haas RH, Deering DW, Harlan JC. Monitoring the vernal 
advancement and retrogradation (green wave effect) of natural 
vegetation. Link: &lt;<a href="https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19730016613.pdf" target="_blank">https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19730016613.pdf</a>&gt;; 1973</span></dd><dt class="label"><a href="#bb0755" id="ref-id-b0755">[151]</a></dt><dd class="reference" id="h0755"><div class="contribution">S.K. Balasundram, F.A. Kassim, G. Vadamalai, A.H.M. Hanif<strong class="title">Estimation of red tip disease severity in pineapple using a non-contact sensor approach</strong></div><div class="host">Agric Sci, 4 (4) (2013), pp. 206-208</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0760" id="ref-id-b0760">[152]</a></dt><dd class="reference" id="h0760"><div class="contribution">J. Peñuelas, J.A. Gamon, A.L. Fredeen, J. Merino, C.B. Field<strong class="title">Reflectance indices associated with physiological changes in nitrogen- and water-limited sunflower leaves</strong></div><div class="host">Remote Sens Environ, 48 (2) (1994), pp. 135-146</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0765" id="ref-id-b0765">[153]</a></dt><dd class="reference" id="h0765"><div class="contribution">A.K. Mahlein, T. Rumpf, P. Welke, H.W. Dehne, L. Plümer, U. Steiner, <em> et al.</em><strong class="title">Development of spectral indices for detecting and identifying plant diseases</strong></div><div class="host">Remote Sens Environ, 128 (2013), pp. 21-30</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0770" id="ref-id-b0770">[154]</a></dt><dd class="reference" id="h0770"><div class="contribution">D. Ashourloo, M. Mobasheri, A. Huete<strong class="title">Developing two spectral disease indices for detection of wheat leaf rust (<em>Pucciniatriticin</em>a)</strong></div><div class="host">Remote Sens, 6 (6) (2014), pp. 4723-4740</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0775" id="ref-id-b0775">[155]</a></dt><dd class="reference" id="h0775"><div class="contribution">T. Rumpf<strong class="title">Finding spectral features for the early identication of biotic stress in plants</strong></div><div class="comment">[Doctor thesis]</div><div class="host">Rheinische Friedrich-Wilhelms-Universität Bonn (2012)</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0780" id="ref-id-b0780">[156]</a></dt><dd class="reference" id="h0780"><div class="contribution">L. Gómez-Chova, D. Tuia, G. Moser, G. Camps-Valls<strong class="title">Multimodal classification of remote sensing images: a review and future directions</strong></div><div class="host">Proc IEEE, 103 (9) (2015), pp. 1560-1584</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0785" id="ref-id-b0785">[157]</a></dt><dd class="reference" id="h0785"><div class="contribution">G. Wang, Y. Sun, J. Wang<strong class="title">Automatic image-based plant disease severity estimation using deep learning</strong></div><div class="host">Comput Intell Neurosci, 2017 (2917536) (2017), pp. 1-8</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0790" id="ref-id-b0790">[158]</a></dt><dd class="reference" id="h0790"><div class="contribution">J.M. Haut, M. Paoletti, J. Plaza, A. Plaza<strong class="title">Cloud implementation of the K-means algorithm for hyperspectral image analysis</strong></div><div class="host">J Supercomput, 73 (1) (2017), pp. 514-529</div><div class="ReferenceLinks" id="reference-links"></div></dd><dt class="label"><a href="#bb0795" id="ref-id-b0795">[159]</a></dt><dd class="reference" id="h0795"><div class="contribution">V.A.A. Quirita, G.A.O.P. da Costa, P.N. Happ, R.Q. Feitosa, R.Q. d.S. Ferreira, D.A.B. Oliveira, <em> et al.</em><strong class="title">A new cloud computing architecture for the classification of remote sensing data</strong></div><div class="host">IEEE J Sel Topics Appl Earth Observ Remote Sens, 10 (2) (2017), pp. 409-416</div><div class="ReferenceLinks" id="reference-links"></div></dd></dl></section></section><div class="Footnotes"><dl class="footnote"><dt class="footnote-label"></dt><dd class="u-margin-xxl-left"><p id="np005">Peer review under responsibility of China Agricultural University.</p></dd></dl></div><div class="Copyright"><span class="copyright-line">© 2018 China Agricultural University. Publishing services by Elsevier B.V.</span></div></article><div class="u-show-from-md col-lg-6 col-md-8 pad-right"><aside class="RelatedContent" aria-label="Related content"><section class="SidePanel"><header id="recommended-articles-header" class="side-panel-header"><button class="button-link side-panel-toggle is-up button-link-primary" aria-expanded="true" type="button"><span class="button-link-text"><h2 class="section-title">Recommended articles</h2></span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="recommended-articles-header"><div id="recommended-articles"><ul><li class="SidePanelItem"><div class="sub-heading"><a href="https://www.sciencedirect.com/science/article/pii/S2214317316300154"><h3 class="article-title ellipsis" id="recommended-articles-article0-title" title="Detection of plant leaf diseases using image segmentation and soft computing techniques"><span>Detection of plant leaf diseases using image segmentation and soft computing techniques</span></h3></a><div class="article-source ellipsis"><div class="source">Information Processing in Agriculture, Volume 4, Issue 1, 2017, pp. 41-49</div></div></div><div class="buttons"><a class="anchor side-panel-pdf-link" href="https://www.sciencedirect.com/science/article/pii/S2214317316300154/pdfft?md5=cd6335eb96f87c4e603df5867364aa62&amp;pid=1-s2.0-S2214317316300154-main.pdf" target="_blank" rel="nofollow"><svg focusable="false" viewBox="0 0 32 32" width="24" height="24" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" stroke="#aaa" stroke-width=".315" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text">Download PDF</span></a><button class="button-link button-link-secondary side-panel-details-toggle" aria-describedby="recommended-articles-article0-title" aria-controls="recommended-articles-article0" aria-expanded="false" type="button"><span class="button-link-text">View details</span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div id="recommended-articles-article0" aria-hidden="true"></div></li><li class="SidePanelItem"><div class="sub-heading"><a href="https://www.sciencedirect.com/science/article/pii/S0924271618300327"><h3 class="article-title ellipsis" id="recommended-articles-article1-title" title="Close-range hyperspectral image analysis for the early detection of stress responses in individual plants in a high-throughput phenotyping platform"><span>Close-range
 hyperspectral image analysis for the early detection of stress 
responses in individual plants in a high-throughput phenotyping platform</span></h3></a><div class="article-source ellipsis"><div class="source">ISPRS Journal of Photogrammetry and Remote Sensing, Volume 138, 2018, pp. 121-138</div></div></div><div class="buttons"><a class="anchor side-panel-pdf-link" href="https://www.sciencedirect.com/science/article/pii/S0924271618300327/pdfft?md5=2f0a58b29078bd67e747c6a3677a9b32&amp;pid=1-s2.0-S0924271618300327-main.pdf" target="_blank" rel="nofollow"><svg focusable="false" viewBox="0 0 32 32" width="24" height="24" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" stroke="#aaa" stroke-width=".315" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text">Download PDF</span></a><button class="button-link button-link-secondary side-panel-details-toggle" aria-describedby="recommended-articles-article1-title" aria-controls="recommended-articles-article1" aria-expanded="false" type="button"><span class="button-link-text">View details</span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div id="recommended-articles-article1" aria-hidden="true"></div></li><li class="SidePanelItem"><div class="sub-heading"><a href="https://www.sciencedirect.com/science/article/pii/S0168169910001262"><h3 class="article-title ellipsis" id="recommended-articles-article2-title" title="Early detection and classification of plant diseases with Support Vector Machines based on hyperspectral reflectance"><span>Early detection and classification of plant diseases with Support Vector Machines based on hyperspectral reflectance</span></h3></a><div class="article-source ellipsis"><div class="source">Computers and Electronics in Agriculture, Volume 74, Issue 1, 2010, pp. 91-99</div></div></div><div class="buttons"><a class="anchor side-panel-pdf-link" href="https://www.sciencedirect.com/science/article/pii/S0168169910001262/pdfft?md5=6fa2836244873ccebe21d9f9afe579e2&amp;pid=1-s2.0-S0168169910001262-main.pdf" target="_blank" rel="nofollow"><svg focusable="false" viewBox="0 0 32 32" width="24" height="24" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" stroke="#aaa" stroke-width=".315" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text">Purchase PDF</span></a><button class="button-link button-link-secondary side-panel-details-toggle" aria-describedby="recommended-articles-article2-title" aria-controls="recommended-articles-article2" aria-expanded="false" type="button"><span class="button-link-text">View details</span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div id="recommended-articles-article2" aria-hidden="true"></div></li></ul></div><div class="pagination u-position-relative u-padding-xs-bottom"><span class="u-position-absolute"></span><span class="pagination-pages-label"><span class="pagination-nav u-margin-xs-hor pagination-current underline-page-number">1</span><span class="pagination-nav u-margin-xs-hor">2</span></span><span class="u-position-absolute"><button class="button-link button-link-secondary next-button" type="button"><span class="button-link-text">Next</span><svg focusable="false" viewBox="0 0 54 128" width="10.125" height="24" class="icon icon-navigate-right"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg></button></span></div></div></section><section class="SidePanel"><header id="citing-articles-header" class="side-panel-header"><h2 class="section-title">Citing articles (0)</h2></header><div class="u-display-none" aria-hidden="true" aria-describedby="citing-articles-header"></div></section><section class="SidePanel hidden"><header id="metrics-header" class="side-panel-header"><button class="button-link side-panel-toggle is-up button-link-primary" aria-expanded="true" type="button"><span class="button-link-text"><h2 class="section-title">Article Metrics</h2></span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="metrics-header"><a href="https://plu.mx/plum/a/?doi=10.1016/j.inpa.2018.05.002" class="plumx-summary plum-sciencedirect-theme" data-pass-hidden-categories="true" data-hide-usage="true" data-orientation="vertical" data-hide-print="true" data-site="plum" data-on-success="onMetricsWidgetSuccess">View article metrics</a></div></section></aside></div></div><div></div></div><div id="footer"><div class="hor-line" style="border-color:#e9711c"></div><div class="panel-s u-padding-l-bottom u-bg-white u-clr-grey7" role="contentinfo"><a class="anchor move-left els-footer-elsevier anchor-has-inherit-color" href="https://www.elsevier.com/" rel="nofollow" target="_blank" style="white-space:nowrap"><span class="anchor-text"><svg viewBox="-3345 3440.027 140.01 24.333" style="width:104px;height:30px"><title>Elsevier</title><path id="E" style="fill:#E9711C" d="M-3343.999,3461.698c2.24,0,3.026-0.473,3.026-2.892v-13.393c0-2.42-0.785-2.89-3.026-2.891v-0.59 h16.787l0.252,4.455h-0.56c-0.308-2.48-1.513-3.216-3.84-3.216h-5.325c-1.26,0-1.26,0.355-1.26,2.066v5.693h5.913 c1.934,0,2.522-0.826,2.718-2.803h0.56v6.844h-0.56c-0.168-1.946-0.813-2.802-2.718-2.802h-5.913v6.401 c0,1.858,0.11,2.476,1.4,2.476h5.914c2.522,0,4.092-1.62,4.82-3.952l0.532,0.207l-1.513,4.985H-3344L-3343.999,3461.698"></path><path style="fill:#E9711C" d="M-3325.448,3461.698c2.074-0.118,2.83-0.502,2.83-2.832v-13.511c0-2.33-0.757-2.715-2.83-2.832v-0.591h8.884 v0.591c-2.243,0-3.027,0.472-3.027,2.891v13.009c0,1.652,0.056,2.625,1.71,2.625h4.008c3,0,4.4-2,5.576-4.1l0.673,0.118 l-1.71,5.222h-16.114V3461.698"></path><path style="fill:#E9711C" d="M-3307.122,3456.27h0.561c1.12,2.596,2.886,5.4,5.94,5.4c2,0,3.672-1.3,3.672-3.334 c0-1.652-1.626-3.1-4.176-4.927c-3.28-2.36-5.41-3.746-5.41-6.43c0-3.422,2.55-5.517,5.633-5.517c2.214,0,3,0.944,4.204,0.944 c0.476,0,0.56-0.266,0.476-0.737h0.561l0.645,6.076h-0.561c-0.785-2.625-2.523-5.19-5.354-5.19c-1.737,0-3.138,1.356-3.138,3.185 c0,1.918,1.933,3.157,5.016,5.016c2.523,1.504,5,3.362,5,6.254c0,3.245-2.608,5.752-5.97,5.752c-2.02,0-4.148-0.855-4.68-0.855 c-0.336,0-0.7,0.207-0.756,0.649h-0.56l-1.094-6.282"></path><path style="fill:#E9711C" d="M-3293.999,3461.698c2.24,0,3.026-0.473,3.026-2.892v-13.393c0-2.42-0.785-2.89-3.026-2.891v-0.59 h16.787l0.252,4.455h-0.56c-0.308-2.48-1.513-3.216-3.84-3.216h-5.325c-1.26,0-1.26,0.355-1.26,2.066v5.693h5.913 c1.934,0,2.522-0.826,2.718-2.803h0.56v6.844h-0.56c-0.168-1.946-0.813-2.802-2.718-2.802h-5.913v6.401 c0,1.858,0.11,2.476,1.4,2.476h5.914c2.522,0,4.092-1.62,4.82-3.952l0.532,0.207l-1.513,4.985H-3294L-3293.999,3461.698"></path><path style="fill:#E9711C" d="M-3265.839,3462.524h-0.42l-5.41-12.538c-0.896-2.065-1.71-4.16-2.83-6.136 c-0.478-0.826-1.346-1.327-2.3-1.327v-0.591h8.323v0.591c-0.785,0-2.354,0-2.354,1.15c0,0.384,0.87,2.45,1.653,4.308l4.063,9.676 l4.877-11.359c0.588-1.356,0.757-2.094,0.757-2.713c0-0.618-0.673-0.974-2.13-1.062v-0.59h5.941v0.591 c-0.337,0.06-0.7,0.117-1.037,0.295c-1.066,0.56-2.13,3.57-2.635,4.749l-6.5,14.957"></path><path style="fill:#E9711C" d="M-3255.472,3461.698c2.24,0,3.025-0.473,3.025-2.892v-13.393c0-2.42-0.784-2.89-3.025-2.891v-0.59h9.078v0.591 c-2.24,0-3.025,0.472-3.025,2.891v13.393c0,2.42,0.784,2.892,3.025,2.892v0.59h-9.08v-0.59"></path><path id="E_2_" style="fill:#E9711C" d="M-3244.999,3461.698c2.24,0,3.026-0.473,3.026-2.892v-13.393c0-2.42-0.785-2.89-3.026-2.891v-0.59 h16.787l0.252,4.455h-0.56c-0.308-2.48-1.513-3.216-3.84-3.216h-5.325c-1.26,0-1.26,0.355-1.26,2.066v5.693h5.913 c1.934,0,2.522-0.826,2.718-2.803h0.56v6.844h-0.56c-0.168-1.946-0.813-2.802-2.718-2.802h-5.913v6.401 c0,1.858,0.11,2.476,1.4,2.476h5.914c2.522,0,4.092-1.62,4.82-3.952l0.532,0.207l-1.513,4.985H-3245L-3244.999,3461.698"></path><path style="fill:#E9711C" d="M-3206,3461.698c-1.26-0.354-1.71-0.68-2.466-1.623l-6.166-7.609c3.027-0.65,5.13-2.185,5.13-5.547 c0-4.75-4.26-4.986-7.764-4.986h-9.191v0.591c2.24,0,3.026,0.472,3.026,2.891v13.393c0,2.42-0.785,2.892-3.026,2.892v0.59h9.08 v-0.59c-2.242,0-3.027-0.473-3.027-2.892v-5.604h2.551l7.314,9.086h4.54L-3206,3461.698 M-3220.399,3444.499 c0-1.387,0.337-1.476,2.186-1.476c2.774,0,5.3,0.974,5.3,4.308c0,3.6-2.887,4.63-5.914,4.631h-1.569v-7.463H-3220.399z"></path></svg></span></a><div class="panel-s u-bg-white u-padding-0-hor-from-xs u-padding-s-hor-from-md u-padding-xs-ver text-xs u-clear-both-from-xs u-clear-none-from-md"><p class="u-margin-xs-bottom"><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://www.elsevier.com/solutions/sciencedirect" rel="nofollow" target="_blank" style="white-space:nowrap"><span class="anchor-text">About ScienceDirect</span></a><wbr><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://www.sciencedirect.com/science/activateaccess" rel="nofollow" target="_blank" style="white-space:nowrap"><span class="anchor-text">Remote access</span></a><wbr><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://www.sciencedirect.com/science?_ob=ShoppingCartURL&amp;_method=display&amp;md5=3ff44acb300f01481824c54a2973d019" rel="nofollow" target="_blank" style="white-space:nowrap"><span class="anchor-text">Shopping cart</span></a><wbr><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://service.elsevier.com/app/contact/supporthub/sciencedirect/" rel="nofollow" target="_blank" style="white-space:nowrap"><span class="anchor-text">Contact and support</span></a><wbr><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://www.elsevier.com/legal/elsevier-website-terms-and-conditions" rel="nofollow" target="_blank" style="white-space:nowrap"><span class="anchor-text">Terms and conditions</span></a><wbr><a class="anchor u-margin-xs-right u-margin-s-right-from-sm u-margin-l-right-from-md anchor-has-inherit-color" href="https://www.elsevier.com/legal/privacy-policy" rel="nofollow" target="_blank" style="white-space:nowrap"><span class="anchor-text">Privacy policy</span></a></p><p id="els-footer-cookie-message">Cookies are used by this site. For more information, visit the<!-- --> <a class="anchor u-margin-0-right" href="https://www.elsevier.com/solutions/sciencedirect/support/cookies" rel="nofollow" target="_blank" style="white-space:nowrap"><span class="anchor-text">cookies page</span></a>.</p><p id="els-footer-copyright">Copyright © <!-- -->2018<!-- --> Elsevier B.V. or its licensors or contributors. ScienceDirect ® is a registered trademark of Elsevier B.V.</p></div><div><span style="margin-top:-10px" class="u-position-relative move-bottom u-float-left-from-xs u-float-right-from-md move-right u-padding-0-hor"><a class="anchor els-footer-relx anchor-has-inherit-color" href="https://www.relx.com/" rel="nofollow" target="_blank" style="white-space:nowrap"><span class="anchor-text"><svg style="width:118px;height:28px" viewBox="-3248 3424.938 334.44 53.422"><title>RELX Group</title><path style="fill:#E9711C" d="M-3227.285,3448.329c10.948,0,24.15-2.576,24.15-13.124c0-7.474-7.63-10.267-14.6-10.267 c-10.647,0-30.265,5.926-30.265,26.96c0,10.555,8.034,16.643,20.778,16.643c13.474,0,23.266-8.768,26.26-20.535 c-7.912,13.648-17.972,17.896-26.18,17.896c-10.19,0-14.077-7.568-14.077-14.05c0-18.56,14.406-24.798,23.494-24.798 c6.135,0,9.727,3.936,9.727,8.253c0,11.918-17.17,11.578-25.008,11.578c-0.803,0-3.274,0.02-3.76-0.003l-1.654,1.714 c3.59,0.508,8.554,1.497,13.944,4.223c11.204,5.656,21.745,20.59,35.7,20.59c5.062,0,6.38-1.543,7.335-2.893 c-6.834,4.354-18.286-3.197-24.46-9.04c-5.082-4.806-9.57-10.26-21.387-13.146"></path><g><path style="fill:#666666" d="M-3158.73,3468.502c-0.423,0-0.636-0.164-0.794-0.547l-6.885-14.511h-6.197c-0.21,0-0.316,0.11-0.316,0.33 v14.182c0,0.328-0.213,0.547-0.532,0.547h-5.189c-0.32,0-0.53-0.22-0.53-0.547v-36.139c0-0.33,0.21-0.55,0.53-0.549h13.928 c6.62,0,11.492,4.545,11.492,11.117c0,4.873-2.7,8.65-6.833,10.238l7.575,15.167c0.21,0.385,0,0.713-0.37,0.713L-3158.73,3468.502 L-3158.73,3468.502z M-3159.42,3442.384c0-3.232-2.223-5.31-5.506-5.311h-7.68c-0.21,0-0.316,0.108-0.316,0.328v9.912 c0,0.217,0.104,0.328,0.316,0.328h7.68C-3161.644,3447.641-3159.42,3445.561-3159.42,3442.384"></path><path style="fill:#666666" d="M-3146.95,3431.817c0-0.33,0.21-0.55,0.53-0.549h21.865c0.317,0,0.53,0.22,0.53,0.549v4.709 c0,0.33-0.212,0.548-0.53,0.548h-15.827c-0.212,0-0.318,0.108-0.318,0.328v9.089c0,0.22,0.106,0.328,0.318,0.328h12.726 c0.317,0,0.53,0.22,0.53,0.547v4.709c0,0.33-0.213,0.548-0.53,0.548h-12.726c-0.212,0-0.318,0.11-0.318,0.329v9.418 c0,0.22,0.106,0.328,0.318,0.328h15.827c0.317,0,0.53,0.22,0.53,0.549v4.709c0,0.328-0.212,0.547-0.53,0.547h-21.865 c-0.32,0-0.53-0.22-0.53-0.547C-3146.95,3467.956-3146.95,3431.817-3146.95,3431.817z"></path><path style="fill:#666666" d="M-3118.2,3431.817c0-0.33,0.212-0.55,0.53-0.549h5.191c0.317,0,0.53,0.22,0.53,0.549v30.553 c0,0.22,0.106,0.328,0.317,0.328h14.722c0.318,0,0.53,0.22,0.53,0.549v4.709c0,0.328-0.213,0.547-0.53,0.547h-20.76 c-0.317,0-0.53-0.22-0.53-0.547C-3118.2,3467.956-3118.2,3431.817-3118.2,3431.817z"></path><path style="fill:#666666" d="M-3052.46,3449.885c0-6.46,0.423-8.926,1.006-10.787c1.747-5.53,5.878-8.377,11.758-8.377 c5.88,0,9.532,3.012,11.28,6.9c0.107,0.274,0.107,0.548-0.21,0.712l-1.695,0.876c-0.265,0.11-0.53,0.055-0.688-0.22 c-1.802-3.396-4.45-5.312-8.74-5.312c-4.45,0-7.468,2.192-8.792,6.3c-0.475,1.422-0.845,3.722-0.845,9.909s0.37,8.486,0.845,9.91 c1.324,4.107,4.343,6.3,8.792,6.3c4.342,0,7.468-2.137,8.79-6.19c0.477-1.422,0.85-3.56,0.85-7.117c0-0.22-0.106-0.328-0.318-0.328 h-8.155c-0.318,0-0.53-0.22-0.53-0.548v-1.807c0-0.33,0.212-0.548,0.53-0.548h10.962c0.317,0,0.53,0.22,0.53,0.548v2.243 c0,3.725-0.423,6.572-0.954,8.27c-1.694,5.53-5.88,8.432-11.65,8.432c-5.88,0-10.01-2.848-11.758-8.38 C-3052.036,3458.811-3052.459,3456.345-3052.46,3449.885"></path><path style="fill:#666666" d="M-3021.43,3468.502c-0.317,0-0.53-0.22-0.53-0.547v-25.023c0-0.33,0.213-0.548,0.53-0.548h1.801 c0.316,0,0.53,0.22,0.53,0.548v3.338h0.052c0.953-2.572,3.23-4.434,6.78-4.434c2.013,0,3.866,0.712,5.084,1.807 c0.265,0.164,0.317,0.438,0.107,0.713l-1.06,1.531c-0.212,0.274-0.48,0.274-0.795,0.11c-1.164-0.767-2.436-1.313-4.024-1.313 c-4.45,0-6.144,3.996-6.144,8.815v14.456c0,0.328-0.213,0.547-0.53,0.547H-3021.43L-3021.43,3468.502z"></path><path style="fill:#666666" d="M-3004.54,3462.26c-0.53-1.752-0.847-3.668-0.847-6.844c0-3.12,0.316-5.037,0.847-6.79 c1.378-4.327,4.818-6.79,9.426-6.79c4.662,0,8.104,2.464,9.48,6.79c0.53,1.752,0.848,3.668,0.848,6.79 c0,3.176-0.317,5.092-0.848,6.844c-1.377,4.326-4.818,6.79-9.48,6.79C-2999.722,3469.05-3003.162,3466.585-3004.54,3462.26 M-2988.387,3461.33c0.475-1.48,0.688-3.066,0.688-5.914c0-2.794-0.213-4.38-0.688-5.86c-1.007-3.12-3.442-4.873-6.728-4.873 c-3.23,0-5.666,1.752-6.672,4.873c-0.477,1.48-0.688,3.065-0.688,5.86c0,2.848,0.212,4.436,0.688,5.914 c1.006,3.12,3.442,4.873,6.672,4.873C-2991.829,3466.203-2989.395,3464.451-2988.387,3461.33"></path><path style="fill:#666666" d="M-2963.66,3468.502c-0.317,0-0.528-0.22-0.528-0.547v-3.066h-0.053c-1.272,2.574-3.92,4.162-7.36,4.162 c-5.615,0-8.74-3.616-8.74-9.913v-16.206c0-0.33,0.213-0.548,0.53-0.548h1.801c0.317,0,0.53,0.22,0.53,0.548v15.44 c0,5.257,2.118,7.83,6.515,7.83c3.812,0,6.78-2.74,6.78-7.284v-15.987c0-0.33,0.21-0.548,0.528-0.548h1.802 c0.317,0,0.53,0.22,0.53,0.548v25.023c0,0.328-0.213,0.547-0.53,0.547h-1.802L-2963.66,3468.502z"></path><path style="fill:#666666" d="M-2955.29,3478.36c-0.317,0-0.53-0.22-0.53-0.549v-34.879c0-0.33,0.213-0.548,0.53-0.548h1.8 c0.317,0,0.53,0.22,0.53,0.548v3.176h0.053c1.218-2.465,3.496-4.272,7.68-4.272c4.45,0,7.256,2.08,8.58,6.242 c0.638,2.137,0.9,4.435,0.9,7.393c0,2.9-0.264,5.2-0.9,7.336c-1.323,4.164-4.13,6.242-8.58,6.242c-4.183,0-6.46-1.807-7.68-4.27 h-0.053v13.031c0,0.33-0.213,0.55-0.53,0.549L-2955.29,3478.36L-2955.29,3478.36z M-2939.35,3461.602 c0.53-1.643,0.688-3.832,0.688-6.13c0-2.355-0.158-4.545-0.688-6.188c-0.952-2.957-3.124-4.6-6.46-4.6 c-3.178,0-5.507,1.533-6.46,4.6c-0.477,1.423-0.69,3.34-0.69,6.188c0,2.847,0.212,4.71,0.69,6.13 c0.954,3.067,3.283,4.602,6.46,4.602C-2942.473,3466.204-2940.3,3464.561-2939.35,3461.602"></path><path style="fill:#666666" d="M-3070.48,3468.545c-0.424,0-0.634-0.164-0.85-0.547l-7.254-12.649h-0.106l-7.307,12.649 c-0.213,0.383-0.424,0.547-0.85,0.547h-5.72c-0.37,0-0.528-0.328-0.318-0.711l10.76-18.562l-9.96-17.248 c-0.21-0.385-0.05-0.712,0.32-0.712h5.721c0.424,0,0.636,0.163,0.847,0.548l6.513,11.278h0.106l6.513-11.278 c0.213-0.385,0.425-0.548,0.85-0.548h5.72c0.37,0,0.53,0.327,0.317,0.712l-9.956,17.248l10.75,18.562 c0.21,0.383,0.052,0.71-0.32,0.711h-5.771H-3070.48z"></path><path style="fill:#666666" d="M-2932.08,3443.951c-0.108,0-0.18-0.075-0.18-0.189v-10.385c0-0.075-0.036-0.113-0.11-0.113h-3.202 c-0.11,0-0.184-0.073-0.184-0.186v-1.6c0-0.11,0.074-0.186,0.184-0.186h8.746c0.11,0,0.183,0.075,0.183,0.186v1.6 c0,0.113-0.07,0.186-0.183,0.186h-3.201c-0.073,0-0.11,0.038-0.11,0.113v10.385c0,0.113-0.07,0.19-0.18,0.189H-2932.08 L-2932.08,3443.951z"></path><path style="fill:#666666" d="M-2924.47,3431.478c0-0.112,0.07-0.186,0.178-0.186h1.604c0.163,0,0.252,0.056,0.307,0.186l3.367,7.8h0.07 l3.315-7.8c0.052-0.13,0.144-0.186,0.305-0.186h1.583c0.11,0,0.182,0.074,0.182,0.186v12.286c0,0.11-0.07,0.186-0.182,0.186h-1.564 c-0.11,0-0.18-0.075-0.18-0.186v-7.744h-0.073l-2.593,5.957c-0.07,0.168-0.18,0.242-0.343,0.242h-1.044 c-0.16,0-0.27-0.074-0.343-0.242l-2.59-5.957h-0.072v7.744c0,0.11-0.072,0.186-0.18,0.186h-1.567c-0.106,0-0.178-0.075-0.178-0.186 v-12.286H-2924.47z"></path></g></svg></span></a></span></div></div></div></section></div></div></div>
<script type="application/json" data-iso-key="_0">{"userAgent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/67.0.3396.99 Chrome/67.0.3396.99 Safari/537.36 Zotero/5.0","abstracts":{"content":[{"#name":"abstract","$":{"xmlns:ce":true,"class":"graphical","lang":"en","id":"ab005","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st005"},"_":"Graphical abstract"},{"#name":"abstract-sec","$":{"id":"as005","view":"all"},"$$":[{"#name":"simple-para","$":{"id":"sp0005","view":"all"},"$$":[{"#name":"display","$$":[{"#name":"figure","$":{"id":"f0015"},"$$":[{"#name":"link","$":{"xmlns:xlink":true,"locator":"fx1","id":"lk00015","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","href":"pii:S2214317317301774/fx1"}}]}]}]}]}]},{"#name":"abstract","$":{"xmlns:ce":true,"class":"author","lang":"en","id":"ab010","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st010"},"_":"Abstract"},{"#name":"abstract-sec","$":{"id":"as010","view":"all"},"$$":[{"#name":"simple-para","$":{"id":"sp0010","view":"all"},"_":"This paper reviews advanced Neural Network (NN) techniques available to process hyperspectral data, with a special emphasis on plant disease detection. Firstly, we provide a review on NN mechanism, types, models, and classifiers that use different algorithms to process hyperspectral data. Then we highlight the current state of imaging and non-imaging hyperspectral data for early disease detection. The hybridization of NN-hyperspectral approach has emerged as a powerful tool for disease detection and diagnosis. Spectral Disease Index (SDI) is the ratio of different spectral bands of pure disease spectra. Subsequently, we introduce NN techniques for rapid development of SDI. We also highlight current challenges and future trends of hyperspectral data."}]}]}],"floats":[],"footnotes":[],"attachments":[{"attachment-eid":"1-s2.0-S2214317317301774-fx1.sml","ucs-locator":"https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2214317317301774/fx1/THUMBNAIL/image/gif/8610961637190b78e38041d61e704478/fx1.sml","file-basename":"fx1","abstract-attachment":"true","filename":"fx1.sml","extension":"sml","filesize":"15894","pixel-height":"92","pixel-width":"219","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S2214317317301774-fx1.jpg","ucs-locator":"https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2214317317301774/fx1/DOWNSAMPLED/image/jpeg/8d116b07b1b562fc31fcaa6ad21972ac/fx1.jpg","file-basename":"fx1","abstract-attachment":"true","filename":"fx1.jpg","extension":"jpg","filesize":"38856","pixel-height":"200","pixel-width":"476","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S2214317317301774-fx1_lrg.jpg","ucs-locator":"https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2214317317301774/fx1/HIGHRES/image/jpeg/7ace279ed45659121218aed8de5c3991/fx1_lrg.jpg","file-basename":"fx1","abstract-attachment":"true","filename":"fx1_lrg.jpg","extension":"jpg","filesize":"111148","pixel-height":"531","pixel-width":"1266","attachment-type":"IMAGE-HIGH-RES"}]},"biographies":{},"combinedContentItems":{},"experiments":{},"rawtext":"","authors":{"content":[{"#name":"author-group","$":{"xmlns:ce":true,"id":"ag005"},"$$":[{"#name":"author","$":{"id":"au005","author-id":"S2214317317301774-a17dfef0e99826281f52f170f039d18e"},"$$":[{"#name":"given-name","_":"Kamlesh"},{"#name":"surname","_":"Golhani"},{"#name":"cross-ref","$":{"refid":"af005","id":"c0130"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"orcid":"0000-0001-5664-6618","id":"au010","author-id":"S2214317317301774-ab510511ed1f6b2a3d87e99eb459133b"},"$$":[{"#name":"given-name","_":"Siva K."},{"#name":"surname","_":"Balasundram"},{"#name":"cross-ref","$":{"refid":"af005","id":"c0135"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"refid":"cor1","id":"c0140"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:siva@upm.edu.my","id":"em005"},"_":"siva@upm.edu.my"}]},{"#name":"author","$":{"id":"au015","author-id":"S2214317317301774-65e325c2bcfd0161ea68559281e0e3ff"},"$$":[{"#name":"given-name","_":"Ganesan"},{"#name":"surname","_":"Vadamalai"},{"#name":"cross-ref","$":{"refid":"af010","id":"c0145"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]},{"#name":"author","$":{"orcid":"0000-0001-9863-2054","id":"au020","author-id":"S2214317317301774-2e728b33bfd7e62c6a478c0689c22cdf"},"$$":[{"#name":"given-name","_":"Biswajeet"},{"#name":"surname","_":"Pradhan"},{"#name":"cross-ref","$":{"refid":"af015","id":"c0150"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"c"}]}]},{"#name":"affiliation","$":{"id":"af005","affiliation-id":"S2214317317301774-4ee616e3f0f6e291adc26557f8a1db66"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","_":"Department of Agriculture Technology, Faculty of Agriculture, Universiti Putra Malaysia, 43400 Serdang, Selangor, Malaysia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Agriculture Technology"},{"#name":"organization","_":"Faculty of Agriculture"},{"#name":"organization","_":"Universiti Putra Malaysia"},{"#name":"city","_":"43400 Serdang"},{"#name":"state","_":"Selangor"},{"#name":"country","_":"Malaysia"}]}]},{"#name":"affiliation","$":{"id":"af010","affiliation-id":"S2214317317301774-d660ab6f0929d6f4184a34a90eca56a6"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","_":"Department of Plant Protection, Faculty of Agriculture, Universiti Putra Malaysia, 43400 Serdang, Selangor, Malaysia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Plant Protection"},{"#name":"organization","_":"Faculty of Agriculture"},{"#name":"organization","_":"Universiti Putra Malaysia"},{"#name":"city","_":"43400 Serdang"},{"#name":"state","_":"Selangor"},{"#name":"country","_":"Malaysia"}]}]},{"#name":"affiliation","$":{"id":"af015","affiliation-id":"S2214317317301774-7cb5e46902f3b40f8ee94dc7f31071dc"},"$$":[{"#name":"label","_":"c"},{"#name":"textfn","_":"School of Systems, Management and Leadership, Faculty of Engineering and IT, University of Technology Sydney, Broadway, NSW 2007, Australia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Systems, Management and Leadership"},{"#name":"organization","_":"Faculty of Engineering and IT"},{"#name":"organization","_":"University of Technology Sydney"},{"#name":"city","_":"Broadway"},{"#name":"state","_":"NSW"},{"#name":"postal-code","_":"2007"},{"#name":"country","_":"Australia"}]}]},{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author at: Department of Agriculture Technology, Faculty of Agriculture, Universiti Putra Malaysia, 3400 Serdang, Selangor, Malaysia."},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Agriculture Technology"},{"#name":"organization","_":"Faculty of Agriculture"},{"#name":"organization","_":"Universiti Putra Malaysia"},{"#name":"city","_":"3400 Serdang"},{"#name":"state","_":"Selangor"},{"#name":"country","_":"Malaysia"}]}]}]}],"floats":[],"footnotes":[],"affiliations":{"af005":{"#name":"affiliation","$":{"id":"af005","affiliation-id":"S2214317317301774-4ee616e3f0f6e291adc26557f8a1db66"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","_":"Department of Agriculture Technology, Faculty of Agriculture, Universiti Putra Malaysia, 43400 Serdang, Selangor, Malaysia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Agriculture Technology"},{"#name":"organization","_":"Faculty of Agriculture"},{"#name":"organization","_":"Universiti Putra Malaysia"},{"#name":"city","_":"43400 Serdang"},{"#name":"state","_":"Selangor"},{"#name":"country","_":"Malaysia"}]}]},"af010":{"#name":"affiliation","$":{"id":"af010","affiliation-id":"S2214317317301774-d660ab6f0929d6f4184a34a90eca56a6"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","_":"Department of Plant Protection, Faculty of Agriculture, Universiti Putra Malaysia, 43400 Serdang, Selangor, Malaysia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Plant Protection"},{"#name":"organization","_":"Faculty of Agriculture"},{"#name":"organization","_":"Universiti Putra Malaysia"},{"#name":"city","_":"43400 Serdang"},{"#name":"state","_":"Selangor"},{"#name":"country","_":"Malaysia"}]}]},"af015":{"#name":"affiliation","$":{"id":"af015","affiliation-id":"S2214317317301774-7cb5e46902f3b40f8ee94dc7f31071dc"},"$$":[{"#name":"label","_":"c"},{"#name":"textfn","_":"School of Systems, Management and Leadership, Faculty of Engineering and IT, University of Technology Sydney, Broadway, NSW 2007, Australia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Systems, Management and Leadership"},{"#name":"organization","_":"Faculty of Engineering and IT"},{"#name":"organization","_":"University of Technology Sydney"},{"#name":"city","_":"Broadway"},{"#name":"state","_":"NSW"},{"#name":"postal-code","_":"2007"},{"#name":"country","_":"Australia"}]}]}},"correspondences":{"cor1":{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author at: Department of Agriculture Technology, Faculty of Agriculture, Universiti Putra Malaysia, 3400 Serdang, Selangor, Malaysia."},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Agriculture Technology"},{"#name":"organization","_":"Faculty of Agriculture"},{"#name":"organization","_":"Universiti Putra Malaysia"},{"#name":"city","_":"3400 Serdang"},{"#name":"state","_":"Selangor"},{"#name":"country","_":"Malaysia"}]}]}},"attachments":[],"scopusAuthorIds":{},"articles":{}},"body":{},"exam":{},"article":{"publication-content":{"noElsevierLogo":false,"imprintPublisher":{"displayName":"Elsevier","id":"47"},"isSampleIssue":false,"transactionsBlocked":true,"publicationOpenAccess":{"oaStatus":"Full","oaArticleCount":161,"openArchiveStatus":false,"openArchiveArticleCount":0,"openAccessStartDate":"","oaAllowsAuthorPaid":false},"smallCoverUrl":"https://ars.els-cdn.com/content/image/S22143173.gif","serialCoverPgUrl":"https://ars.els-cdn.com/content/image/D22143173.gif","sourceOpenAccess":true,"publicationCoverImageUrl":"https://ars.els-cdn.com/content/image/S22143173.gif"},"pii":"S2214317317301774","dates":{"Available online":"9 May 2018","Received":"3 October 2017","Revised":["20 April 2018"],"Accepted":"2 May 2018","Publication date":"9 May 2018"},"access":{"openAccess":true,"sponsorName":"China Agricultural University","sponsorType":"FundingBody","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"},"crawlerInformation":{"canCrawlPDFContent":false,"isCrawler":false},"aip-text":"In Press, Corrected Proof","analyticsMetadata":{"accountId":"228598","accountName":"ScienceDirect Guests","loginStatus":"anonymous","userId":"12975512"},"cid":"287278","content-family":"serial","copyright-line":"© 2018 China Agricultural University. Publishing services by Elsevier B.V.","cover-date-years":["2018"],"cover-date-start":"2018-05-09","cover-date-text":"Available online 9 May 2018","document-subtype":"rev","document-type":"article","entitledToken":"DAEC502ACACD2EA6487F3EFAA8AC72F96D86D89CCB2996C50C382F4DF89F24D7CFE0A2DD37EA125A","eid":"1-s2.0-S2214317317301774","doi":"10.1016/j.inpa.2018.05.002","item-weight":"FULL-TEXT","language":"en","last-author":{"#name":"last-author","$":{"xmlns:dm":true},"$$":[{"#name":"author","$":{"xmlns:ce":true,"orcid":"0000-0001-9863-2054","id":"au020","author-id":"S2214317317301774-2e728b33bfd7e62c6a478c0689c22cdf"},"$$":[{"#name":"given-name","_":"Biswajeet"},{"#name":"surname","_":"Pradhan"},{"#name":"cross-ref","$":{"refid":"af015","id":"c0150"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"c"}]}]}]},"normalized-first-auth-initial":"K","normalized-first-auth-surname":"GOLHANI","srctitle":"Information Processing in Agriculture","timestamp":"2018-07-20T02:06:36.195484Z","title":{"content":[{"#name":"article-footnote","$":{"xmlns:ce":true,"id":"aep-article-footnote-id1"},"$$":[{"#name":"note-para","$":{"id":"np005","view":"all"},"_":"Peer review under responsibility of China Agricultural University."}]},{"#name":"title","$":{"xmlns:ce":true,"id":"tm005"},"_":"A review of neural networks in plant disease detection using hyperspectral data"}],"floats":[],"footnotes":[{"#name":"article-footnote","$":{"xmlns:ce":true,"id":"aep-article-footnote-id1"},"$$":[{"#name":"note-para","$":{"id":"np005","view":"all"},"_":"Peer review under responsibility of China Agricultural University."}]}],"attachments":[]},"userSettings":{"forceAbstract":false,"creditCardPurchaseAllowed":true,"disableWholeIssueDownload":false,"preventTransactionalAccess":false,"preventDocumentDelivery":true},"contentType":"JL","crossmark":false,"issn":"22143173","issn-primary-formatted":"2214-3173","useEnhancedReader":true,"isCorpReq":false,"pdfDownload":{"linkType":"DOWNLOAD","linkToPdf":"/science/article/pii/S2214317317301774/pdfft?md5=a65a106233555127a7633d17d131e1e7&pid=1-s2.0-S2214317317301774-main.pdf","isPdfFullText":false,"fileName":"1-s2.0-S2214317317301774-main.pdf"},"pdfUrlForCrawlers":"https://www.sciencedirect.com/science/article/pii/S2214317317301774/pdfft?md5=a65a106233555127a7633d17d131e1e7&pid=1-s2.0-S2214317317301774-main.pdf","indexTag":true,"volRange":"","issRange":"","userProfile":{"departmentName":"ScienceDirect Guests","accessType":"GUEST","accountId":"228598","webUserId":"12975512","accountName":"ScienceDirect Guests","departmentId":"291352","userType":"NORMAL","hasMultipleOrganizations":false},"entitlementReason":"openaccess","articleEntitlement":{"entitled":true},"aipType":"corrected_proof","downloadFullIssue":false,"headerConfig":{"helpUrl":"https://service.elsevier.com/app/home/supporthub/sciencedirect/","contactUrl":"https://service.elsevier.com/app/contact/supporthub/sciencedirect/","userName":"","orgName":"","webUserId":"12975512","libraryBanner":{},"shib_regUrl":"","tick_regUrl":"","recentInstitutions":[],"canActivatePersonalization":false,"hasMultiOrg":false,"userType":"GUEST","allowCart":true},"open-research":{},"titleString":"A review of neural networks in plant disease detection using hyperspectral data","isAbstract":false,"onAbstractWhitelist":false,"isContentVisible":false,"ajaxLinks":{"citingArticles":true,"references":true,"referredToBy":true,"toc":true,"body":true,"recommendations":true}},"specialIssueArticles":{},"recommendations":{},"entitledRecommendations":{"isOpen":false,"articles":[],"selected":[],"currentPage":1,"totalPages":1},"citingArticles":{},"workspace":{"isOpen":false},"crossMark":{"isOpen":false},"userIdentity":{},"refersTo":{},"referredToBy":{},"downloadIssue":{"isOpen":false,"articles":[],"selected":[]},"references":{},"referenceLinks":{"internal":{},"external":{}},"glossary":{},"relatedContent":{"isModal":false,"isOpenSpecialIssueArticles":false,"isOpenRecommendations":true,"isOpenCitingArticles":false,"citingArticles":[false,false,false],"recommendations":[false,false,false,false,false,false],"specialIssueArticles":[false,false,false]},"banner":{"expanded":false},"transientError":{"isOpen":false},"pdfDropdown":{},"exportCitation":{"isOpen":false},"tableOfContents":{"showEntitledTocLinks":true},"chapters":{"toc":[],"isLoading":false},"enrichedContent":{"tableOfContents":false,"researchData":{"hasResearchData":false,"dataProfile":{},"openData":{},"mendeleyData":{},"databaseLinking":{}},"geospatialData":{"attachments":[]},"interactiveCaseInsights":{},"virtualMicroscope":{}},"metrics":{"isOpen":true},"signOut":{"isOpen":false},"issueNavigation":{"previous":{},"next":{}},"tail":{},"linkingHubLinks":[]}</script>
      
      <script src="satelliteLib-b7cfe8df39a4e5eec5536bba80e13f4b6fa0dd7c.js"></script><script src="satellite-565e008964746d4385002642.js"></script>
      <script src="babel-polyfill.js"></script>
      <script src="react.js"></script>
      <script src="react-dom.js"></script>
      <script src="arp.js" async=""></script>
      <!-- begin usabilla live embed code -->
      <script type="text/javascript">
        window.lightningjs||function(c){function g(b,d){d&&(d+=(/\?/.test(d)?"&":"?")+"lv=1");c[b]||function(){var i=window,h=document,j=b,g=h.location.protocol,l="load",k=0;(function(){function b(){a.P(l);a.w=1;c[j]("_load")}c[j]=function(){function m(){m.id=e;return c[j].apply(m,arguments)}var b,e=++k;b=this&&this!=i?this.id||0:0;(a.s=a.s||[]).push([e,b,arguments]);m.then=function(b,c,h){var d=a.fh[e]=a.fh[e]||[],j=a.eh[e]=a.eh[e]||[],f=a.ph[e]=a.ph[e]||[];b&&d.push(b);c&&j.push(c);h&&f.push(h);return m};return m};var a=c[j]._={};a.fh={};a.eh={};a.ph={};a.l=d?d.replace(/^\/\//,(g=="https:"?g:"http:")+"//"):d;a.p={0:+new Date};a.P=function(b){a.p[b]=new Date-a.p[0]};a.w&&b();i.addEventListener?i.addEventListener(l,b,!1):i.attachEvent("on"+l,b);var q=function(){function b(){return["<head></head><",c,' onload="var d=',n,";d.getElementsByTagName('head')[0].",d,"(d.",g,"('script')).",i,"='",a.l,"'\"></",c,">"].join("")}var c="body",e=h[c];if(!e)return setTimeout(q,100);a.P(1);var d="appendChild",g="createElement",i="src",k=h[g]("div"),l=k[d](h[g]("div")),f=h[g]("iframe"),n="document",p;k.style.display="none";e.insertBefore(k,e.firstChild).id=o+"-"+j;f.frameBorder="0";f.id=o+"-frame-"+j;/MSIE[ ]+6/.test(navigator.userAgent)&&(f[i]="javascript:false");f.allowTransparency="true";l[d](f);try{f.contentWindow[n].open()}catch(s){a.domain=h.domain,p="javascript:var d="+n+".open();d.domain='"+h.domain+"';",f[i]=p+"void(0);"}try{var r=f.contentWindow[n];r.write(b());r.close()}catch(t){f[i]=p+'d.write("'+b().replace(/"/g,String.fromCharCode(92)+'"')+'");d.close();'}a.P(2)};a.l&&setTimeout(q,0)})()}();c[b].lv="1";return c[b]}var o="lightningjs",k=window[o]=g(o);k.require=g;k.modules=c}({});
        window.usabilla_live = lightningjs.require("usabilla_live", "https://w.usabilla.com/eb1c14a91932.js");
        var customData = {};

        if(window.pageData && pageData.content && pageData.content[0]) {
          customData.entitlementType = pageData.content[0].entitlementType;
        }
        if(window.pageData && pageData.visitor) {
          customData.accessType = pageData.visitor.accessType;
          customData.accountId = pageData.visitor.accountId;
          customData.loginStatus = pageData.visitor.loginStatus;
        }
        usabilla_live("data", {"custom": customData });
      </script>
      <!-- end usabilla live embed code -->
      <script type="text/x-mathjax-config;executed=true">
        MathJax.Hub.Config({
          displayAlign: 'left',
          "fast-preview": {
            disabled: true
          },
          CommonHTML: { linebreaks: { automatic: true } },
          PreviewHTML: { linebreaks: { automatic: true } },
          'HTML-CSS': { linebreaks: { automatic: true } },
          SVG: {
            scale: 90,
            linebreaks: { automatic: true }
          }
        });
      </script>
      <script async="" src="MathJax.js"></script>
      <script async="" src="gpt.js"></script>
    
  <div class="js-react-modal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><script src="widget-summary.js" async=""></script></body></html>